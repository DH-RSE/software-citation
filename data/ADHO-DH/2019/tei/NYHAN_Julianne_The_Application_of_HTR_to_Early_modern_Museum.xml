<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title>The Application of HTR to Early-modern Museum Collections: a Case Study of Sir Hans Sloane's Miscellanies Catalogue</title>
                <author>
                    <persName>
                        <surname>Humbel</surname>
                        <forename>Marco</forename>
                    </persName>
                    <affiliation>University College London, United Kingdom</affiliation>
                    <email>marco.humbel.17@ucl.ac.uk</email>
                </author>
                <author>
                    <persName>
                        <surname>Nyhan</surname>
                        <forename>Julianne</forename>
                    </persName>
                    <affiliation>University College London, United Kingdom</affiliation>
                    <email>julianne.nyhan@gmail.com</email>
                </author>
            </titleStmt>
            <editionStmt>
                <edition>
                    <date>2019-04-04T13:45:00Z</date>
                </edition>
            </editionStmt>
            <publicationStmt>
                <publisher>Name, Institution</publisher>
                <address>
                    <addrLine>Street</addrLine>
                    <addrLine>City</addrLine>
                    <addrLine>Country</addrLine>
                    <addrLine>Name</addrLine>
                </address>
            </publicationStmt>
            <sourceDesc>
                <p>Converted from a Word document</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <appInfo>
                <application ident="DHCONVALIDATOR" version="1.22">
                    <label>DHConvalidator</label>
                </application>
            </appInfo>
        </encodingDesc>
        <profileDesc>
            <textClass>
                <keywords scheme="ConfTool" n="category">
                    <term>Paper</term>
                </keywords>
                <keywords scheme="ConfTool" n="subcategory">
                    <term>Long Paper</term>
                </keywords>
                <keywords scheme="ConfTool" n="keywords">
                    <term>HTR; Sloane; manuscript; catalogue; model</term>
                </keywords>
                <keywords scheme="ConfTool" n="topics">
                    <term>GLAM: galleries</term>
                    <term>libraries</term>
                    <term>archives</term>
                    <term>museums</term>
                    <term>English</term>
                    <term>library &amp; information science</term>
                    <term>OCR and hand-written recognition</term>
                </keywords>
            </textClass>
        </profileDesc>
    </teiHeader>
    <text>
        <body>
            <p>Research context</p>
            <p>
                <hi rend="background(white)" xml:space="preserve">Handwritten Text Recognition (HTR) is “the ability of a computer to transform handwritten input represented in its spatial form of graphical marks into an equivalent symbolic representation as ASCII text.” </hi>(Romero et al., 2012: 5)
                <hi rend="background(white)" xml:space="preserve"> What is the state of the art of the application of HTR to early modern manuscripts? With what level of accuracy </hi>
                <hi rend="italic">
                    <hi rend="italic background(white)" xml:space="preserve">can HTR models automate their transcription? What is known about how HTR currently accommodates manuscript text that shows changing writing styles, hands and text in multiple languages? We will explore these questions with reference to the wider literature and a case study of the first HTR model to be created for the hand of </hi>
                </hi>
                <hi rend="italic background(white)">Sir Hans Sloane (1660-1753).</hi>
            </p>
            <p>
                <hi rend="background(white)" xml:space="preserve">	Optical Character Recognition on documents with perfectly machine-printed characters can reach an accuracy level of more than 99% (Cao and Natarajan, 2014: 336–37). However OCR is often problematic for historical documents </hi>(Smith and Cordell, 2019: 5)
                <hi rend="background(white)" xml:space="preserve">. It also cannot be used for handwritten documents, since the space between characters and words is inconsistent. </hi>
                <hi rend="italic background(white)" xml:space="preserve">Holistic segmentation-free off-line </hi>
                <hi rend="background(white)">HTR technology works at a line level and can deal with cursive characters, slanted words and irregular calligraphy, but it must be trained for a specific handwritin</hi>g 
                <hi rend="background(white)">(Alabau and Leiva, 2012: 2274; S</hi>ánchez et al., 2014: 111–12)
                <hi rend="background(white)">. HTR is not accurate enough to replace human expertise, however it holds the potential to bolster the transcription process</hi> (Toselli et al., 2018: 174;176)
                <hi rend="background(white)" xml:space="preserve">. </hi>
            </p>
            <p>
                <hi rend="background(white)"> ‘</hi>
                <hi rend="italic">
                    <hi rend="background(white)" xml:space="preserve">Enlightenment Architectures: Sir Hans Sloane’s Catalogues of his Collections is a Leverhulme-funded collaboration between the British Museum and UCL. </hi>
                    <hi rend="italic background(white)">It studies 5 of the manuscript catalogues of</hi>
                </hi>
                <hi rend="background(white)">Sloane,</hi>
                <note place="foot" xml:id="ftn1" n="1">
                    <p rend="footnote text"> The catalogue of Miscellanies, two of his Natural History catalogues (Fossils vol. I and vol. V) and two of his library catalogues (Sloane MS 3972C vol. VI and Sloane MS 3972B).</p>
                </note>
                <hi rend="background(white)" xml:space="preserve"> and is encoding them in TEI to understand the information architectures they use. In 2017, selected catalogues were transcribed to a high level of accuracy by the company AEL Data Service in Chennai, India. We thus had high quality transcriptions of Sloane’s manuscript materials, in addition to images of his catalogues, available for use in the training of an HTR model for Sloane’s hand.</hi>
            </p>
            <p>
                <hi rend="background(white)" xml:space="preserve">	The HTR model discussed here was trained using the software Transkribus. The aim of the e-Infrastructure project READ (Recognition and Enrichment of Archival Documents) is to make archival sources more accessible through technological development. The centrepiece of READ is the service platform and application Transkribus, which enables the automatic recognition and transcription of handwritten documents and the ability to search within them </hi>(READ project, 2018a; READ project, 2018b)
                <hi rend="background(white)" xml:space="preserve">. </hi>
            </p>
            <p>Methodology </p>
            <p>
                <hi rend="background(white)" xml:space="preserve">To train an HTR model with Transkribus, one has to provide it with training data (digital surrogates of the original folios and their transcriptions). This is known as </hi>
                <hi rend="italic background(white)" xml:space="preserve">ground truth </hi>
                <hi rend="background(white)">or</hi>
                <hi rend="italic background(white)" xml:space="preserve"> reference data. </hi>
                <hi rend="background(white)">The segmentation of the document into its elements, in particular the baselines, and the actual transcription is crucial for creating an adequate HTR model. The ground truth data must consist of a representative sample of a collection’s documents and also respect the original appearance of the script, e.g. special characters, as closely as possible. With Transkribus, this serves the purpose of training the HTR model, and also the evaluation of its accuracy. Between 75 and 100 pages (around 15,000 to 20,000 words) of training data are necessary for an effective HTR model.</hi>
                <hi rend="italic" xml:space="preserve"> </hi>
                <hi rend="background(white)">A randomized selection of documents is recommende</hi>d (
                <hi rend="background(white)">READ project, 2018c: 3</hi>–4; READ project, 2017: 10)
                <hi rend="background(white)">.</hi>
                <hi rend="WW-Default_Paragraph_Font1" xml:space="preserve"> </hi>
                <hi rend="background(white)" xml:space="preserve">We determined that the </hi>
                <hi rend="italic">
                    <hi rend="italic background(white)">first sub-section of the Miscellanies catalogue (folio 2-152v) would give enough training and test data to evaluate the model because it contains important characteristics of the whole collection of catalogues, such as annotations and a complex layout.</hi>
                </hi>
                <note place="foot" xml:id="ftn2" n="2">
                    <p rend="footnote text">We wish to thank the members of the Enlightenment Architectures team for their assistance in making this selection and for their wider advice about this case study. </p>
                </note>
                <hi rend="italic" xml:space="preserve"> </hi>
            </p>
            <p>For this research, five different HTR models were created to allow a comparison between their changing accuracy. This includes one pre-test model. Training started with 75 folios and was then increased to 100 and 125 folios. For the last model, in addition to the 125 folios of training data, a base model was added.</p>
            <p>Results</p>
            <p>
                <hi rend="italic">
                    <hi rend="italic background(white)">The quality of an HTR transcription can be evaluated according to a Word Error Rate (WER) and Character Error Rate (CER</hi>
                    <hi rend="italic">) (Romero et al., 2012: 93). Transkribus allows both measures (READ project, 2018c: 5).</hi>
                    <hi rend="italic background(white)" xml:space="preserve"> WER is […] “the minimum number of words that need to be substituted, deleted or inserted to convert a sentence recognized by the system into the corresponding reference transcription, divided by the total number of words in the reference transcription […]” </hi>
                    <hi rend="italic">(Romero et al., 2012: 55). C</hi>
                    <hi rend="italic background(white)">ER is the minimum number of single characters which need to be corrected, divided by the total number of characters in the reference text</hi>
                    <hi rend="italic" xml:space="preserve"> (Romero et al., 2012: 55)</hi>
                    <hi rend="italic background(white)">. Transkribus also allows the evaluation of the general accuracy of a model with a learning curve visualisation and the accuracy of a model on the page level to be specified via the compute accuracy function (READ project, 2018d: 9–12). According to READ</hi>
                    <hi rend="italic" xml:space="preserve"> (2018d: 10),</hi>
                    <hi rend="italic background(white)" xml:space="preserve"> a model with an accuracy rate of 90% can be regarded as an effective automated transcription.</hi>
                </hi>
            </p>
            <p> The evaluation showed that our current model of 20,803 words reached a CER of 12.73% without the base model. The transcription has not reached a level of accuracy that is sufficient for academic research without further human input. The model has problems transcribing names (persons and places), abbreviations, double letters (e.g. ee), punctuation, Latin text and the numbers in the margins correctly. </p>
            <p>Conclusion </p>
            <p>
                <hi rend="background(white)">In the paper we will reflect on how our methodology and model might be refined in order to improve the CER, in line with the experiences of other projects (for example Hodel, 2017 or</hi>
                <hi rend="italic" xml:space="preserve"> </hi>Prell, 2018). We will give particular attention to questions like ‘
                <hi rend="italic">
                    <hi rend="italic">Where in particular does recognition fail?’. ‘</hi>
                    <hi rend="italic" xml:space="preserve">How much training data is necessary to create a model with an accuracy of at least 90%?’ and ‘how might external resources like gazetteers and name authority lists be integrated into Transkribus and used in conjunction with the HTR model in order to increase the accuracy of the transcription of named entities? </hi>
                    <hi rend="italic" xml:space="preserve"> Our responses to questions like this are likely to be transferable to other projects who seek to build HTR models for the transcription of early-modern manuscript materials. </hi>
                </hi>
            </p>
            <p>
                <hi rend="italic">
                    <hi rend="italic">Although our model reached a relative high level of accuracy, is it not good enough to be used for scholarly work. We will therefore also reflect on scenarios where the model could still be used, such as Authorship Attribution (Franzini et al.,</hi>
                </hi>
                <hi rend="endnote_reference" xml:space="preserve"> </hi>
                <hi rend="italic">
                    <hi rend="italic">or Named Entity Recognition (Carbonell et al., 2018; Toledo et al., 2019).</hi>
                </hi>
            </p>
        </body>
        <back>
            <div type="bibliogr">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl rend="Bibliography 1">
                        <hi rend="bold" style="font-size:11pt">Alabau, V. and Leiva, L.</hi>
                        <hi style="font-size:11pt" xml:space="preserve"> (2012). Transcribing handwritten text images with a word soup game. </hi>
                        <hi rend="italic" style="font-size:11pt">CHI ’12 Extended Abstracts on Human Factors in Computing Systems</hi>
                        <hi style="font-size:11pt">. Austin, Texas: ACM Press, pp. 2273–78 doi:10.1145/2212776.2223788.</hi>
                    </bibl>
                    <bibl rend="Bibliography 1">
                        <hi rend="bold" style="font-size:11pt">Cao, H. and Natarajan, P.</hi>
                        <hi style="font-size:11pt" xml:space="preserve"> (2014). Machine-Printed Character Recognition. In Doermann, D. and Tombre, K. (eds), </hi>
                        <hi rend="italic" style="font-size:11pt">Handbook of Document Image Processing and Recognition</hi>
                        <hi style="font-size:11pt">. London: Springer London, pp. 331–58 doi:https://doi.org/10.1007/978-0-85729-859-1_44.</hi>
                    </bibl>
                    <bibl rend="Bibliography 1">
                        <hi rend="bold" style="font-size:11pt">Carbonell, M., Villegas, M., Fornes, A. and Llados, J.</hi>
                        <hi style="font-size:11pt" xml:space="preserve"> (2018). Joint Recognition of Handwritten Text and Named Entities with a Neural End-to-End Model. </hi>
                        <hi rend="italic" style="font-size:11pt">2018 13th IAPR International Workshop on Document Analysis Systems (DAS)</hi>
                        <hi style="font-size:11pt">. Vienna: IEEE, pp. 399–404 doi:10.1109/DAS.2018.52.</hi>
                    </bibl>
                    <bibl rend="Bibliography 1">
                        <hi rend="bold" style="font-size:11pt">Franzini, G., Kestemont, M., Rotari, G., Jander, M., Ochab, J. K., Franzini, E., Byszuk, J. and Rybicki, J.</hi>
                        <hi style="font-size:11pt" xml:space="preserve"> (2018). Attributing Authorship in the Noisy Digitized Correspondence of Jacob and Wilhelm Grimm. </hi>
                        <hi rend="italic" style="font-size:11pt">Frontiers in Digital Humanities</hi>
                        <hi style="font-size:11pt" xml:space="preserve">, </hi>
                        <hi rend="bold" style="font-size:11pt">5</hi>
                        <hi style="font-size:11pt">(4) doi:10.3389/fdigh.2018.00004.</hi>
                    </bibl>
                    <bibl rend="Bibliography 1">
                        <hi rend="bold" style="font-size:11pt">Hodel, T.</hi>
                        <hi style="font-size:11pt" xml:space="preserve"> (2017). Sending 15th-Century Missives through Algorithms: Testing and Evaluating HTR with 2,200 Documents </hi>
                        <hi rend="italic" style="font-size:11pt">Schrift Im Kloster</hi>
                        <hi style="font-size:11pt" xml:space="preserve"> https://solascriptum.wordpress.com/2017/07/11/imc-leeds-paper-sending-15th-century-missives-through-algorithms-testing-and-evaluating-htr-with-2200-documents/ (accessed 27 March 2019).</hi>
                    </bibl>
                    <bibl rend="Bibliography 1">
                        <hi rend="bold" style="font-size:11pt">Prell, M.</hi>
                        <hi style="font-size:11pt" xml:space="preserve"> (2018). Frühneuzeitliche Briefe als Herausforderung automatisierter Handschriftenerkennung: Ein Transkribus-Projektbericht. doi:10.22032/dbt.34849. https://www.db-thueringen.de/servlets/MCRFileNodeServlet/dbt_derivate_00041045/Transkribusbericht_2018_06_02.pdf (accessed 27 March 2019).</hi>
                    </bibl>
                    <bibl rend="Bibliography 1">
                        <hi rend="bold" style="font-size:11pt">READ project</hi>
                        <hi style="font-size:11pt" xml:space="preserve"> (2017). How To Transcribe Documents with Transkribus: Simple Mode https://transkribus.eu/wiki/images/a/ad/HowToTranscribe_SimpleMode.pdf (accessed 27 March 2019).</hi>
                    </bibl>
                    <bibl rend="Bibliography 1">
                        <hi rend="bold" style="font-size:11pt">READ project</hi>
                        <hi style="font-size:11pt" xml:space="preserve"> (2018a). Services https://read.transkribus.eu/services/ (accessed 27 March 2019).</hi>
                    </bibl>
                    <bibl rend="Bibliography 1">
                        <hi rend="bold" style="font-size:11pt">READ project</hi>
                        <hi style="font-size:11pt" xml:space="preserve"> (2018b). About https://read.transkribus.eu/about/ (accessed 27 March 2019).</hi>
                    </bibl>
                    <bibl rend="Bibliography 1">
                        <hi rend="bold" style="font-size:11pt">READ project</hi>
                        <hi style="font-size:11pt" xml:space="preserve"> (2018c). How To Prepare Test Projects with Transkribus - for Archives and Libraries https://transkribus.eu/wiki/images/8/81/HowToPrepareTestProjects.pdf (accessed 27 March 2019).</hi>
                    </bibl>
                    <bibl rend="Bibliography 1">
                        <hi rend="bold" style="font-size:11pt">READ project</hi>
                        <hi style="font-size:11pt" xml:space="preserve"> (2018d). How To Train A Handwritten Text Recognition Model In Transkribus https://transkribus.eu/wiki/images/3/34/HowToTranscribe_Train_A_Model.pdf (accessed 26 March 2019).</hi>
                    </bibl>
                    <bibl rend="Bibliography 1">
                        <hi rend="bold" style="font-size:11pt">Romero, V., Toselli, A. H. and Vidal, E.</hi>
                        <hi style="font-size:11pt" xml:space="preserve"> (2012). </hi>
                        <hi rend="italic" style="font-size:11pt">Multimodal Interactive Handwritten Text Transcription</hi>
                        <hi style="font-size:11pt">. Vol. 80. (Series in Machine Perception and Artificial Intelligence). Singapore: World Scientific Pub.</hi>
                    </bibl>
                    <bibl rend="Bibliography 1">
                        <hi rend="bold" style="font-size:11pt">Sánchez, J. A., Bosch, V., Romero, V., Depuydt, K. and Does, J. de</hi>
                        <hi style="font-size:11pt" xml:space="preserve"> (2014). Handwritten text recognition for historical documents in the transcriptorium project. </hi>
                        <hi rend="italic" style="font-size:11pt">Proceedings of the First International Conference on Digital Access to Textual Cultural Heritage</hi>
                        <hi style="font-size:11pt">. Madrid, Spain: ACM Press, pp. 111–17 doi:10.1145/2595188.2595193.</hi>
                    </bibl>
                    <bibl rend="Bibliography 1">
                        <hi rend="bold" style="font-size:11pt">Smith, D. A. and Cordell, R.</hi>
                        <hi style="font-size:11pt" xml:space="preserve"> (2019). </hi>
                        <hi rend="italic" style="font-size:11pt">A Research Agenda for Historical and Multilingual Optical Character Recognition</hi>
                        <hi style="font-size:11pt">. Northeastern University https://ocr.northeastern.edu/report/ (accessed 10 March 2019).</hi>
                    </bibl>
                    <bibl rend="Bibliography 1">
                        <hi rend="bold" style="font-size:11pt">Toledo, J. I., Carbonell, M., Fornés, A. and Lladós, J.</hi>
                        <hi style="font-size:11pt" xml:space="preserve"> (2019). Information extraction from historical handwritten document images with a context-aware neural model. </hi>
                        <hi rend="italic" style="font-size:11pt">Pattern Recognition</hi>
                        <hi style="font-size:11pt" xml:space="preserve">, </hi>
                        <hi rend="bold" style="font-size:11pt">86</hi>
                        <hi style="font-size:11pt">: 27–36 doi:https://doi.org/10.1016/j.patcog.2018.08.020.</hi>
                    </bibl>
                    <bibl rend="Bibliography 1">
                        <hi rend="bold" style="font-size:11pt">Toselli, A. H., Leiva, L. A., Bordes-Cabrera, I., Hernández-Tornero, C., Bosch, V. and Vidal, E.</hi>
                        <hi style="font-size:11pt" xml:space="preserve"> (2018). Transcribing a 17th-century botanical manuscript: Longitudinal evaluation of document layout detection and interactive transcription. </hi>
                        <hi rend="italic" style="font-size:11pt">Digital Scholarship in the Humanities</hi>
                        <hi style="font-size:11pt" xml:space="preserve">, </hi>
                        <hi rend="bold" style="font-size:11pt">33</hi>
                        <hi style="font-size:11pt">(1): 173–202 doi:https://doi-org.libproxy.ucl.ac.uk/10.1093/llc/fqw064.</hi>
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>
</TEI>
