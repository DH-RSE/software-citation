<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title>Hyper Audio Linking – Generating Hybrids of Text and Video Content for Digital Publishing</title>
                <author>
                    <persName>
                        <surname>Blaha</surname>
                        <forename>Agnes</forename>
                    </persName>
                    <affiliation>Transforming Freedom, Austria</affiliation>
                    <email>ablaha@gmx.net</email>
                </author>
                <author>
                    <persName>
                        <surname>Findeisen</surname>
                        <forename>Andreas Leo</forename>
                    </persName>
                    <affiliation>Transforming Freedom, Austria</affiliation>
                    <email>mail@leofindeisen.net</email>
                </author>
            </titleStmt>
            <editionStmt>
                <edition>
                    <date>2019-05-05T17:21:00Z</date>
                </edition>
            </editionStmt>
            <publicationStmt>
                <publisher>Name, Institution</publisher>
                <address>
                    <addrLine>Street</addrLine>
                    <addrLine>City</addrLine>
                    <addrLine>Country</addrLine>
                    <addrLine>Name</addrLine>
                </address>
            </publicationStmt>
            <sourceDesc>
                <p>Converted from a Word document</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <appInfo>
                <application ident="DHCONVALIDATOR" version="1.22">
                    <label>DHConvalidator</label>
                </application>
            </appInfo>
        </encodingDesc>
        <profileDesc>
            <textClass>
                <keywords scheme="ConfTool" n="category">
                    <term>Paper</term>
                </keywords>
                <keywords scheme="ConfTool" n="subcategory">
                    <term>Pre-Conference Workshop and Tutorial</term>
                </keywords>
                <keywords scheme="ConfTool" n="keywords">
                    <term>Digital publishing; transcripts; speech to text; hybrid publishing;</term>
                </keywords>
                <keywords scheme="ConfTool" n="topics">
                    <term>digital archives and digital libraries</term>
                    <term>audio</term>
                    <term>video</term>
                    <term>multimedia</term>
                    <term>scholarly editing</term>
                    <term>crowdsourcing</term>
                    <term>English</term>
                    <term>digital humanities (history</term>
                    <term>theory and methodology)</term>
                    <term>communication and media studies</term>
                </keywords>
            </textClass>
        </profileDesc>
    </teiHeader>
    <text>
        <body>
            <div>
                <p>The Digital Humanities as a field of research and publication face both new opportunities and challenges due to the increasing number of media sources relevant to researchers and students, no matter their age and origin. Aggregator platforms like YouTube or Vimeo let formerly unknown materials surface that are relevant for new research in the humanities. Meanwhile, large public and private collections held by historical organizations, broadcasting corporations and NGOs, or individuals like artists, scientists or politicians remain to be indexed, investigated and re-published (Sommer, 2016). At the same time, researchers who are experimenting with new, creative ways to combine curating, scholarship and presentation draw attention to the immersive and narrative potential of sound-based media (see e.g. Barber, 2017; Murray and Wiercinski, 2014; Cohen, Rakerd, Rehberger &amp; Boyd 2012).</p>
                <p>Some of the use cases relevant to the field of digital humanities that will probably become even more frequent over the next years include:</p>
                <list type="unordered">
                    <item>Support for oral history researchers who need to transcribe large amounts of recordings</item>
                    <item>Using transcripts for lectures and online learning tools, both for students and the public at large</item>
                    <item>Enhancing the usability of digital A/V archives via full text search</item>
                    <item>Facilitating community contribution and citizen science projects</item>
                    <item>Furthering the accessibility of A/V content (e.g. for deaf people)</item>
                    <item>Intertwining multimedia material and text for research papers published in online journals</item>
                </list>
                <p>Alternating between more theory-focused discussion and hands-on experience, we will different methods to integrate transcripts into multimedia formats that are useable for research and publications. After a brief introduction into the principles and current possibilities as well as the limitations of computerized speech to text transcription, particularly in comparison with tools for manual transcription such as WebAnno and OCTRA, we will introduce participants to a small number of different speech-to-text software packages that can be used to semi-automatically transcribe A/V content, while discussing their respective pros and cons.</p>
                <p>We will then demonstrate how to use the open source package ffmpeg to extract and convert various types of A/V recordings to formats suitable for further processing and try out automatic speech to text conversion with OH portal, an online transcription tool developed and maintained by the phonetics research team at the university of Munich (
                    <ref target="https://www.phonetik.uni-muenchen.de/apps/oh-portal/">https://www.phonetik.uni-muenchen.de/apps/oh-portal/</ref>) and Watson, a powerful, trainable natural language processing tool developed by IBM. 
                </p>
                <p>For many in the DH community, creating a good transcript is just the start. Presenting research to fellow academics and the public at large, garnering interest for archives and projects, creating lively and easy to use learning material - all while preserving the non-verbal aspects of raw sources - are often just as important. This is probably even more true for novel, hybrid formats which have been theorized to be result of an amalgamation of analog and digital publishing (Ludovico, 2012).</p>
                <p>As an exemplary solution, we will introduce Hyper Audio Linking, a technique for the presentation of digital content that allows to link transcripts to pre-defined jump marks in video or audio recordings via JavaScript. HAL augmentation deals with diverse content aspects of a source while letting the original untouched. It can be used for all kinds of sources, be it contemporary recordings of lectures and panel discussions, interviews, or historical footage, as well as some art genres like theatre plays, films, or audio dramas. By defining sections or “chapters” and linking them to timestamps, the transcript can be used to jump between those parts in the original media, allowing recipients to switch between reading or viewing/listening mode. The resulting multi-media hybrid can be further augmented by defining formatting options for different types of content and by including various metadata, images, annotations, keywords, and the like. The result is an elegant and easy to use frontend interface that allows for full-text search and easy navigation within A/V content.</p>
                <p>A simplified workflow of an oral history project that uses HAL both as support for researchers and to publish research results and multimedia documents can be seen in figure 1. Importantly, HAL-augmented files can not only be used for the final step of publishing and presenting results. Depending on the configuration of jump marks, they can also support members of the research team in navigating recordings or in tracing observations, selected utterances and topics over multiple sources. Meanwhile, the method is flexible enough to be introduced on the fly at any point in time. If desired, its use may also be restricted to a certain part of collected sources, e.g. only those that are selected for public access.</p>
                <figure>
                    <graphic n="1001" width="15.993180555555556cm" height="8.653638888888889cm" url="Pictures/f8f7bd6e2ad601e031f88e63e7d5676f.jpeg" rend="inline"/>
                </figure>
                <p>Figure 1: Sample workflow with HAL integrated in an oral history project</p>
                <p>Using an existing interface to a database of videos on history and politics of digital culture, participants will experiment with different ways to use HAL links within transcripts. We will discuss and compare our Drupal-based implementation with other existing tools such as ELAN, an annotation tool for A/V content developed at the Max Planck Institute for Psycholinguistics in Nijmegen. We will also talk about some of the key differences between software designed to work as a standalone tool for researchers versus a method developed for usage either as the interface of an online archive or as an enrichment or additional feature of web publishing formats.</p>
                <p>To round off the workshop, we will start to build a web page featuring A/V content, a transcript, and additional material such as photographs and annotations from scratch. Using just a text editor and a few simple lines of Html and JavaScript code, participants will learn to apply HAL augmentation to their own publications. We will use a pre-configured installation of the open source content management system Drupal that can be customized to fit different use cases, including curated online collections, project documentation, event pages etc.</p>
                <p>For this second practice part of the workshop, participants should ideally bring their own A/V sources and start working on their personal project. Those who don’t have a specific use case in mind (yet) will be able to choose among different sources provided by the workshop team instead.</p>
                <p>The last workshop unit will be a discussion dealing with the editorial planning for publication. Whether you are an individual producer, a research team or an online cluster, you will have to make certain decisions in how to manage the publication: Who is the audience that will be primarily addressed? Which specific needs have to be taken into account with regards to usability, accessibility and technological literacy? How much (if any) pre-existing knowledge on the topic can be assumed, and how much introductory information should be included?</p>
                <div>
                    <head>Target audience and requirements</head>
                    <p>Previous workshops and presentations of Hyper-Audio-Linking have been held at BASICS, transmediale Berlin, at the Ludwig-Boltzmann-Institute for Media.Art.Research, Linz, and most recently as part of the EADH conference Galway 2018. Based on these earlier workshops on similar topics, we expect to work with a group of between ten and fifteen participants, which seems ideal for a more hands-on experience.</p>
                    <p>There are no skill requirements for participation, all introductions into software usage and programming will be suitable for beginners but can be easily adapted to participants with more advanced levels of pre-existing knowledge.</p>
                    <p>Participants should bring their own laptop. Participants who use a laptop provided by their employer should make sure to either have all software pre-installed or know that they are authorized to install software on their computer.</p>
                    <p>All required software is either open access or free to use, there will be no additional costs.</p>
                </div>
                <div>
                    <head>Pre-conference support and provision of material</head>
                    <p>Participants who would like to familiarize themselves with HAL in advance will be given access to stubs of prepared A/V content on our platform Transforming Freedom.org four weeks before the conference start. </p>
                    <p>Download links for other software packages and instruction material on how to install and use the respective software will be made available to the participants about two weeks in advance of the workshop. </p>
                </div>
                <div>
                    <head>Intended length and format</head>
                    <p>The duration of the workshop will be a half day, that is, approximately four hours including breaks. As far as the format is concerned, we will alternate between theory-focused presentation, group discussion, and practical tasks that let participants try out different techniques supported by the instructors.</p>
                </div>
            </div>
        </body>
        <back>
            <div type="bibliogr">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend="bold">Barber, J. F.</hi> (2017). Radio Nouspace: Sound, Radio, Digital Humanities. 
                        <hi rend="italic">Digital Studies/Le champ numérique, 7(1), 1.</hi> DOI: 
                        <ref target="http://doi.org/10.16995/dscn.275">http://doi.org/10.16995/dscn.275</ref> (accessed 05 May 2019).
                    </bibl>
                    <bibl>
                        <hi rend="bold">Cohen, S., Rakerd, B., Rehberger, D., &amp; Boyd, D. A.</hi> (2012). Oral history in the digital age: the imperative for rethinking best practices based on a survey of the field(s). Retrieved from 
                        <ref target="http://ohda.matrix.msu.edu/2012/07/ohda-survey/">http://ohda.matrix.msu.edu/2012/07/ohda-survey/</ref>. (accessed 04 May 2019).
                    </bibl>
                    <bibl>
                        <hi rend="bold">Ludovico, A.</hi> (2012). Post-Digital Print: The Mutation of Publishing since 1894. 
                        <hi rend="italic">Onomatopee 77</hi>.
                    </bibl>
                    <bibl style="text-align:left;">
                        <hi rend="bold">Murray, A. and Wiercinski, J.</hi> (2014). A Design Methodology for Sound-based Web Archives. 
                        <hi rend="italic">Digital Humanities Quarterly</hi> 8.2, 
                        <ref target="http://digitalhumanities.org/dhq/vol/8/2/000173/000173.html">http://digitalhumanities.org/dhq/vol/8/2/000173/000173.html</ref> (accessed 05 May 2019).
                    </bibl>
                    <bibl>
                        <hi rend="bold">Sommer, B.</hi> (2016). 
                        <hi rend="italic">Practicing Oral History in Historical Organizations</hi>. London: Routledge.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>
</TEI>
