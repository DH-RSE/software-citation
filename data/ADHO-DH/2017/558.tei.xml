<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/yoann/Work/Grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.4-SNAPSHOT" ident="GROBID" when="2019-06-05T06:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">OBSERVATÓR!O2016</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Gianella</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Instituto de Matemática Pura e Aplicada</orgName>
								<orgName type="department" key="dep2">Instituto de Matemática Pura e Aplicada</orgName>
								<address>
									<country>Brazil, Brazil</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luiz</forename><surname>Velho</surname></persName>
							<email>lvelho@impa.br</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Instituto de Matemática Pura e Aplicada</orgName>
								<orgName type="department" key="dep2">Instituto de Matemática Pura e Aplicada</orgName>
								<address>
									<country>Brazil, Brazil</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">OBSERVATÓR!O2016</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Visualizations</head><p>Approximately 180,000 of the collected tweets included unique images. The production of large sets of digital images inaugurates new avenues for researchers interested in the human creative practice. In this sense, the investigation of Lev Manovich on digital methods to study visual culture is quite relevant. With this in mind, we explored Rio-2016 images through Deep Learning approaches. As the investigation is currently ongoing, we will report the research process of a single task, which resulted in the Torch Mosaic visualization.</p><p>During the pre-Olympics, it became evident that many of the images gathered by our query scripts were related to the Olympic torch relay and depicted the iconic object. Part of these images were accompanied by texts that mentioned the torch, but not all. In addition, some tweets mentioning the torch relay incorporated images that didn't depict the object. In other words, text analysis alone was not sufficient to detect a set of images containing the torch.</p><p>Thus, we referred to a Deep Learning approach to recognize the Olympic torch in our database.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The field of visual pattern recognition has been recently improved by the efficient performance of Convolutional Neural Networks (CNN). In 2012, the work of Krizhevsky et al. on training a deep convolutional neural network to classify the 1.2 million images in the ImageNet LSVRC-2010 contest into 1000 different classes had a substantial impact on the computer vision community.</head><p>More recently, and thanks to Google, computer vision tasks such as image classification have become more accessible and applicable. That's because the company released last year their open source software library TensorFlow. This library runs code for image classification on Inception-v3 CNN model, which can be retrained on a distinct image classification task (this quality is referred to as transfer learning). By creating a set of training images, it is possible to update the parameters of the model and use it to recognize a new image category. That said, we retrained the network by showing it a sample of 100 manually labeled images containing the torch. Finally, the retrained network ran over our database and returned a set of images with their corresponding confidence score for the new category.   The organization nature of the mosaic visualization is mainly aesthetic. Nevertheless, zooming and panning the mosaic allows the user to explore a wide variety of views, and to discover image details and surprises such as the spoof picture of Fofão, a Brazilian fictional character, carrying the torch.</p><p>For DH2017 poster session, we expect to present the results for another subject feature -the sporting disciplines -and visualisation technique -the videosphere - we are working on at the moment. In addition, we plan to discuss with participants some possible scenarios in which Deep Learning models could be applied to help image collections become more discoverable and expressive. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Confidence score over 83% Until June 25th, around 1500 images with over 85% confidence score for the Olympic torch category had been classified by our network. We used them to create a mosaic visualization that can be zoomed and panned. The mosaic idea is that, given an image (target image), another image (mosaic) is automatically build up from several smaller images (tile images). To implement the mosaic, we used a web-based viewer for high-resolution zoomable images called OpenSeadragon.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. The target image</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. The mosaic</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Bibliography Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E., C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Angue- lov, D., ... &amp; Rabinovich, A.</head><label></label><figDesc>(2012). "Imagenet classification with deep convolutional neural networks". Advances in neural information processing systems, pp. 1097-1105. Manovich, L (2012). "How to Compare One Million Im- ages?". In Berry, D. (ed), Understanding Digital Humani- ties. Palgrave, pp. 249-278.Szegedy(2015). "Going deeper with convolutions". Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9.</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
