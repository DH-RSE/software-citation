<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/yoann/Work/Grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.4-SNAPSHOT" ident="GROBID" when="2019-06-05T06:24+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Distinguishing Newspaper Genres. Exploring Automated Classification of Journalism&apos;s Modes of Expression</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Harbers</surname></persName>
							<email>f.harbers@rug.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Groningen</orgName>
								<address>
									<country key="NL">the Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juliette</forename><surname>Lonij</surname></persName>
							<email>juliette.lonij@kb.nl</email>
							<affiliation key="aff1">
								<orgName type="institution">National Library of the Netherlands</orgName>
								<address>
									<country key="NL">the Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Distinguishing Newspaper Genres. Exploring Automated Classification of Journalism&apos;s Modes of Expression</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>This paper examines the opportunities, approaches and issues of automatically classifying historical newspaper articles from the Netherlands for 'genre' as an expression of the historically and culturally determined conception of journalism. Genre is defined as "language use in a conventionalized communicative setting in order to give expression to a specific set of communicative goals of a disciplinary or social institution, which give rise to stable structural forms" <ref type="bibr">(Hand- ford 2010)</ref>. As <ref type="bibr">Barnhurst and Nerone (2001)</ref> argue: "The form includes the way the medium imagines itself to be and to act. In its physical arrangement, structure, and format, a newspaper reiterates an ideal for itself." Examining the generic form of newspaper articles form a historical perspective therefore sheds an interesting light on the way newspaper journalism has developed.</p><p>The digital era, which is typified as the 'age of abundance' of historical newspaper material, poses new challenges to historical research. Historical approaches to selecting and analyzing newspapers, rooted in the assumption of a scarcity of available material, had to be replaced with social scientific methods, such as quantitative content analysis <ref type="bibr">(Nicholson 2013;</ref><ref type="bibr">Broersma 2009</ref>). Yet, manual quantitative content analyses are still highly time consuming and therefore expensive. Moreover, even then the size of the material that can be covered represents only a small part of the amount of material available <ref type="bibr">(Har- bers 2014)</ref>. Automated forms of (content) analysis have the potential to alleviate or even solve this issue. As such, automatic forms of content analysis would be highly suitable for longitudinal and also comparative historical research into the development of newspapers, which particularly grapples with the overabundance of available research material <ref type="bibr">(Broersma 2009)</ref>.</p><p>However, although these approaches have a great appeal to researchers <ref type="bibr">(Allen, Waldstein &amp; Zhu 2008;</ref><ref type="bibr">Grimmer &amp; Stewart 2013)</ref>, research in this vein is mostly done in information science and linguistics. It seldom has a press historical perspective <ref type="bibr">(Broersma 2009)</ref>. Moreover, the emphasis has mostly been on topical modeling <ref type="bibr">(Lee &amp; Myaeng 2002)</ref>, whereas attention for automatic classification of style and genre is scarce. Rather than determining what subjects and themes are being discussed, this project aims to examine genre as a modes of expression of newspapers, shedding light on the discursive context <ref type="bibr">(Handford 2010)</ref>. This is a particularly difficult task as genres are dynamic and can change or fade away over time while new ones can emerge. Moreover, genres are ideal-typical discursive constructs, which means the textual manifestations do not always match the characteristics of these constructs perfectly, nor can they always be clearly delineated from other genres.</p><p>The research question therefore is:</p><p>To what extent and how can historical newspaper articles be automatically classified for genre?</p><p>To examine this question, we have designed a research project that builds on an existing set of metadata describing several textual characteristics, such as genre, of a large sample of historical newspaper articles. This dataset was the result of a large-scale research project into the historical development of European newspapers with the title 'Reporting at the boundaries of the public sphere. Form, Style and Strategy of European Journalism, 1880-2005'. The set of metadata is derived from a manual content analysis that coded for genre based on a detailed rule-based coding manual. The metadata set relates to a corpus of approximately 33.000 Dutch newspaper articles from three types of Dutch newspapers, divided over the sample years <ref type="bibr">1885</ref><ref type="bibr">, 1905</ref><ref type="bibr">, 1925</ref><ref type="bibr">, 1965</ref><ref type="bibr">, 1985</ref><ref type="bibr">and 2005</ref><ref type="bibr">(Harbers, 2014</ref>. This set of metadata thus provides us with a number of labeled example articles that can be used to train and formally evaluate a classifier that is able to automatically predict the genre of additional samples of historical newspaper articles. In order to so the metadata first has to be connected to the full text of the corresponding digitized articles in the Dutch newspaper repository of the National Library (KB).</p><p>The second step is to use this enriched dataset to train a classifier that can classify historical newspaper articles automatically.</p><p>This paper first shows a way to connect the metadata to the digitized historical newspaper articles (Phase 1). Ultimately, it offers an outline of a concrete machine learning approach, applying linear and nonlinear classifiers, to predict the genre of a newspaper article. As a part of this, the paper discusses the different tools we have tried out and the problems we have encountered in the process (Phase 2). Specifically, the paper reflects on the way the rule-based approach to determining genre in the manual content analysis relates to the training of an automatic classifier based on machine learning techniques.</p><p>In order to link the articles described in the existing metadata set to the corresponding KB data, we first created a number of rules to find the most promising candidate links for each item in the original data set, based on the position of the article on the page, its size, and the presence of images and quotes. Since these rule alone turned out not to be sufficiently accurate, a simple classifier was trained to select the best link from the candidate set, if any, based on features such as the difference in size and number of images present between the article as described in the original data set and the article as found in the KB repository, as well as author mentions and subject matter, amongst other features. By only accepting links predicted by this classifier with a relatively high confidence value approximately 50% of all articles could be automatically linked, with an error rate of 0.5%. Some genres were underrepresented in the automatically linked set and were manually expanded upon.</p><p>The data set resulting from phase 1 was then used to create a training and test set for the actual genre classifier. This, again, involved taking several steps: first, the OCR for the articles in the set was retrieved and cleaned of quoted text by means of regular expressions. Next, the remaining text was pre-processed with the Natural Language Processing software package Frog, performing tasks such as segmentation, tokenization, and part-of-speech tagging. From the resulting annotated text, the relevant features for each article were calculated, such as number of words, number of sentences, number of direct quotes removed, and, most importantly, number of adjectives and various types of pronouns found in the text. These features, together with the existing genre labels were finally used to train a Support Vector Machine to choose one of eight possible genres for each article, ranging from news report and interview to news analysis and opinion article.</p><p>The initial results we obtained with this classifier were quite promising. Our first attempt resulted in an accuracy score of 58%, with the default accuracy by predicting the majority class or genre being 46%. The confusion matrix made from the predictions provides important information about which genres are most difficult to predict and what mistakes are most commonly made. This information can help us to fine-tune the existing features. Moreover, we have not yet implemented all the textual features that typify the different genres, such as named entities occurring in the text, sentiment, or self-classification to name only a few. Finally, we will compare the results of different algorithms, including deep learning approaches. Based on this, we expect to be able to improve these initial results in the coming months and present our final results in more detail at the conference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bibliography</head></div>		</body>
		<back>
			<div type="annex">
			</div>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
