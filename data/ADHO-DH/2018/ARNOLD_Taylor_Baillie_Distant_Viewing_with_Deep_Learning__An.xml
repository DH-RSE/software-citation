<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title type="full">
                    <title type="main">Distant Viewing with Deep Learning: An Introduction to Analyzing Large Corpora of Images</title>
                    <title type="sub"/>
                </title>
                <author>
                    <persName>
                        <surname>Arnold</surname>
                        <forename>Taylor Baillie</forename>
                    </persName>
                    <affiliation>University of Richmond, United States of America</affiliation>
                    <email>tarnold2@richmond.edu</email>
                </author>
                <author>
                    <persName>
                        <surname>Tilton</surname>
                        <forename>Lauren Craig</forename>
                    </persName>
                    <affiliation>University of Richmond, United States of America</affiliation>
                    <email>ltilton@richmond.edu</email>
                </author>
            </titleStmt>
            <editionStmt>
                <edition>
                    <date>2018-05-03T01:43:07.533611000</date>
                </edition>
            </editionStmt>
            <publicationStmt>
                <publisher>Name, Institution</publisher>
                <address>
                    <addrLine>Street</addrLine>
                    <addrLine>City</addrLine>
                    <addrLine>Country</addrLine>
                    <addrLine>Name</addrLine>
                </address>
            </publicationStmt>
            <sourceDesc>
                <p>Converted from an OASIS Open Document</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <appInfo>
                <application ident="DHCONVALIDATOR" version="1.22">
                    <label>DHConvalidator</label>
                </application>
            </appInfo>
        </encodingDesc>
        <profileDesc>
            <textClass>
                <keywords scheme="ConfTool" n="category">
                    <term>Paper</term>
                </keywords>
                <keywords scheme="ConfTool" n="subcategory">
                    <term>SIG endorsed pre-conference workshop</term>
                </keywords>
                <keywords scheme="ConfTool" n="keywords">
                    <term>deep learning</term>
                    <term>image processing</term>
                    <term>clustering</term>
                </keywords>
                <keywords scheme="ConfTool" n="topics">
                    <term>corpora and corpus activities</term>
                    <term>image processing</term>
                    <term>audio</term>
                    <term>video</term>
                    <term>multimedia</term>
                    <term>content analysis</term>
                    <term>cultural studies</term>
                    <term>English</term>
                    <term>computer science</term>
                </keywords>
            </textClass>
        </profileDesc>
    </teiHeader>
    <text>
        <body>
            <div type="div1" rend="DH-Heading1">
                <head>Short Description</head>
                <p>This tutorial provides a hands-on introduction to the use of deep learning techniques in the study of large image corpora. The TensorFlow and Keras libraries within the Python programming language are used to facilitate this analysis. No prior programming experience is required.</p>
                <p>Image analysis tasks covered in the tutorial include object detection, facial recognition, image similarity, and image clustering. We will make three open-access image corpora (historic photographs, still frames from moving images, and scanned works of art) available in order to test these methods. Alternatively, participants may bring and use an image dataset of interest to them. At the conclusion of the tutorial, participants will have created an interactive website running locally on their machines. This website will provide tools for analyzing their selected dataset. Additional instructions for making the website publicly available will be provided.</p>
            </div>
            <div type="div1" rend="DH-Heading1">
                <head>Audience and Number of Participants</head>
                <p>This tutorial is aimed at scholars who work with visual materials who want to integrate DH methods into their analysis of image corpora. Our tutorial is based off of lectures notes used in a non-major, undergraduate-level course at the University of Richmond. It is accessible to participants with little to no programming background. However, as the tutorial will focus on the methods behind image processing rather than low-level coding, it will also be interesting and useful for experienced programmers new to image processing.</p>
                <p>Following the large number of participants at the AVinDH SIG sponsored Workshop in Montreal for DH20167 and our popular tutorial at DH2016 in Krakow, we expect the workshop participation to be equally popular with somewhere between 15 and 25 participants.</p>
            </div>
            <div type="div1" rend="DH-Heading1">
                <head>Presenter Information</head>
                <p>
                    <hi rend="bold">Taylor Arnold </hi>is Assistant Professor of Statistics at the University of Richmond. A recipient of grants from the NEH and ACLS, Arnold's research focuses on computational statistics, text analysis, image processing, and applications within the humanities. His first book 
                    <hi rend="italic">Humanities Data in R</hi> (Springer, 2015) explores four core analytical areas applicable to data analysis in the humanities: networks, text, geospatial data, and images. His second book, the forthcoming 
                    <hi rend="italic">A Computational Approach to Statistical Learning</hi> (CRC Press 2018), explores connections between modern machine learning techniques with theories of statistical estimation. Numerous journal articles extrapolate on these ideas in the context of particular applications. Arnold has also released several open-source libraries in R, Python, Javascript and C. Visiting appointments have included Invited Professor at Université Paris Diderot and Senior Scientist at AT&amp;T Labs.
                </p>
                <p>
                    <hi rend="bold">Lauren Tilton </hi>is Assistant Professor of Digital Humanities in the Department of Rhetoric and Communications at the University of Richmond and a member of Richmond's Digital Scholarship Lab. Her current book project focuses on participatory media in the 1960s and 1970s. She is the Co-PI of the project 
                    <hi rend="italic">Participatory Media</hi>, which interactively engages with and presents participatory community media from the 1960s and 1970s. She is also a director of 
                    <hi rend="italic">Photogrammar</hi>, a web-based platform for organizing, searching and visualizing the 170,000 photographs from 1935 to 1945 created by the United States Farm Security Administration and Office of War Information (FSA-OWI). She is the co-author of 
                    <hi rend="italic">Humanities Data in R</hi> (Springer, 2015). She is co-chair of the American Studies Association's Digital Humanities Caucus.
                </p>
            </div>
            <div type="div1" rend="DH-Heading1">
                <head>Detailed Outline</head>
                <p>In this three hour tutorial we plan to spend the first 15 minutes getting all participants set up with the software and datasets required for the tutorial. The tutorial participants will we able to work on any reasonably recent version of Windows, macOS, or Linux. All of the software is free and open source. The remained of the workshop will consist of two 75-minutes sessions with a 15 minute break between them.</p>
                <p>Each of the two 75-minute sessions will consist of working collectively through “labs” formatted as IPython notebooks. Participants will have the option of using one of three pre-compiled datasets during the workshop depending on their interests:</p>
                <list type="unordered">
                    <item>historic photographs</item>
                    <item>still frames from moving images</item>
                    <item>scanned works of art</item>
                </list>
                <p>Alternatively, tutorial participants may alternatively work with their own collection of images.</p>
                <p>The first session will focus on describing the potential difficulties of working with image data and explaining how deep learning can be used to address several of these challenges. Working at a conceptual level we will work through the following tasks:</p>
                <list type="unordered">
                    <item>how to structure a large collection of images as files on a computer</item>
                    <item>how to load images into Python as multidimensional arrays</item>
                    <item>the concepts behind applying neural networks to image data</item>
                    <item>code for projecting images into the penultimate layer of the YOLOv4 neural network</item>
                    <item>methods for visualizing the output projects from the neural networks</item>
                </list>
                <p>The second session will focus on how the features detect in the first session can be used to annotate higher level features and measure the similarity between images. Specifically:</p>
                <list type="unordered">
                    <item>the application of image projections to image similarity metrics</item>
                    <item>the application of image projections to object detection</item>
                    <item>the application of image projections to face detection</item>
                </list>
                <p>In the final 30 minutes, we will discuss how these techniques ultimately can be used to address humanities questions. This will culminate in running Python code that will output the constructed annotations as an interactive website running locally on each user's computer. This will open up further possibilities for extending the methods of the tutorial without the need for an extensive programming background.</p>
            </div>
            <div type="div1" rend="DH-Heading1">
                <head>Special requirements</head>
                <p>The tutorial will require an overhead projector and internet access for all participants. We will forward information for downloading the required software ahead of time, however, to reduce the load on the internet on the day of the tutorial. Similarly, we will bring USB drives with the image corpora in case the internet connection speed makes manual downloading large files prohibitively slow.</p>
            </div>
        </body>
        <back>
            <div type="bibliogr">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend="bold">Arnold, T. and Tilton, C.</hi> (2015). 
                        <hi rend="italic">Humanities Data in R</hi>. New York, NY: Springer.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Arnold, T., Kane, M., and Lewis, B.</hi> (2017). 
                        <hi rend="italic">A Computational Approach to Statistical Learning</hi>. New York, NY: CRC Press.
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>
</TEI>
