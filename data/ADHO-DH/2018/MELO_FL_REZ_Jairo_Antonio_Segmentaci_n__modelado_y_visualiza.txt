Introducción
Una de las características de la cultura jurídica del antiguo régimen era la evidente polisemia de sus conceptos (Hespanha, 2002). Términos que actualmente pertenecen al plano teológico, moral, histórico y literario; tenían un valor normativo dentro del lenguaje jurídico que afectaba la práctica del gobierno y la justicia. Como explica Alejandro Agüero, la perspectiva crítica develó una lógica del orden natural del mundo y del poder político en la que el derecho escrito si bien no es irrelevante tampoco cumple el papel protagónico en la organización de las ciudades y los reinos (Agüero Nazar, 2012: 84).
El giro metodológico, de la exégesis a la auscultación del pensamiento jurídico a través de los conceptos centrales del discurso normativo desde la edad media europea, ha implicado cruzar las fronteras de la historia del derecho como campo especializado del estudio del derecho para entrar a discutir con la disciplina histórica. La hermenéutica jurídica trasciende por lo tanto el ejercicio de la interpretación del texto para remitirse al “sentido” (
sinn
) del derecho en un enfoque cercano a la filosofía hermenéutica (Costa, 1972: 46), cuya derivación más conocida por los historiadores la representan Gadamer y Koselleck (1997).
Con este trabajo pretendemos explorar las posibilidades que brindan los métodos de análisis computacional para la historia de los conceptos y en general del lenguaje jurídico-político anterior al siglo XIX, en el entendido que el perdón permite analizar un elemento fundamental del poder político de la Edad Moderna (Foucault, 1975: 56–57), así como el proceso de secularización y de pretendida tecnificación del indulto en el marco del proyecto de modernización legislativa decimonónico (Prodi, 2000).
La construcción del corpus: modelado básico de la información.
El corpus textual objeto de esta muestra está compuesto de documentos seleccionados de fondos de justicia y gobierno de archivos españoles y colombianos. Al no existir una serie documental consistente para el problema del perdón, fue necesario realizar una exploración y recolección de documentación en diversos repositorios que permitiera representar el universo de la clemencia en el ámbito del virreinato del Nuevo Reino de Granada.
Con el propósito de estructurar la información, se aprovechó el entorno Omeka para facilitar tanto la transcripción como la asignación de metadatos al contenido y a los elementos (Melo Flórez, 2016). Se identificaron distintos tipos documentales que se agruparon en cédulas, peticiones y concesiones de indulto, legislación, doctrina, prisiones, perdones particulares, expedientes judiciales y biografías. Para estos dos últimos elementos se construyó un tipo de elemento (ítem-type) con lo cual se puede recuperar información específica como suplicaciones, vistas fiscales, sentencias, alegatos de defensores, testimonios.
La transcripción de los documentos se realizó de manera tradicional intentando conservar el valor fonético o literal de las fuentes, por lo cual el texto digitalizado no fue modernizado en su ortografía ni en la acentuación. Un problema consistió en el desarrollo de abreviaturas, las cuales por lo general se indican haciendo uso de corchetes, por ejemplo, N
vo
R
no
de Granada se desarrolla como N[ue]vo R[ei]no de Granada. Por el momento se ha optado por imitar la etiqueta <expan> del modelo TEI del modo [expan = Nuevo Reino de Granada] con lo cual se adelanta la identificación de algunos elementos semánticos y por otra parte solventa la lectura automática del texto. La misma operación se realiza con etiquetas como <abbr>, <gloss>, <note>, <corr>, <sic>, <placeName>, <geo>, <textLang mainLang> y <name type>.
Finalmente, la información se recuperó mediante la función
metadata
de Omeka que permite seleccionar entre diferentes tipos de metadatos para luego exportarlos en HTML y convertirlos a texto plano (Turkel and Crymble, 2012). Con el propósito de visualizar el cambio de significado el corpus se segmentó en seis grupos temporales: 1739-1775, 1776-1789, 1790-1807, 1808-1818, 1819-1829, 1830-1842.
Segmentación
Antes del análisis textual, el texto requiere ser
tokenizado
, es decir, segmentado en unidades lingüísticas con la intención de conocer las métricas de las fuentes (Mikheev, 2005). Este proceso tiene el propósito de agrupar caracteres alfanuméricos en palabras, diferenciar tipos (número de palabras diferentes en un corpus), la frecuencia de cada palabra representada como
tokens
, y aplicar el proceso de
stemming
(reducir las palabras a su raíz) y la lematización (formas flexionadas de una palabra). Por lo tanto, en esta etapa, el análisis se reduce a la estructura básica del texto, su construcción y la medición del peso de sus elementos (Jockers, 2013: 4). El resultado se presenta en la tabla 1, aunque el primer segmento (1700-1775) revela la disparidad temporal respecto a las demás divisiones, por lo cual se comprende deberá corregir esta discrepancia en un futuro ejercicio. Los periodos con mayor cantidad de tokens están representados por aquellas etapas más convulsas del periodo: la rebelión de los comunes de 1781 y el proceso de revolución e independencia desde 1808 hasta 1830.
Corpus
Tokens
Types
Lemmas
1700-1775
112136
15514
15514
1808-1818
93301
12198
12538
1776-1790
80015
11438
11714
1819-1830
51548
8510
8605
1830-1842
32968
6578
6736
1790-1808
25885
5932
6043
Tabla 1. Resultados del proceso de segmentación del corpus por segmentos
La abundancia de tipos y lemas se deriva de la cantidad de variaciones que el software no tiene la capacidad de deducir formas de una misma palabra, por ejemplo, indulto e yndulto es leído como dos vocablos separadas. La manera más simple de solucionar este inconveniente consiste en modernizar la ortografía de las expresiones arcaicas, sin embargo, esto disociaría el corpus de las fuentes doctrinales y legales impresas, cuya información se recupera por técnicas de OCR. En este caso nos remitimos nuevamente a la representación de grafemas, tarea propia de la paleografía, y su uso por parte de escribanos en la Edad Moderna, así como las posibilidades de semi-automatización y estandarización de esta tarea.
Análisis y visualización
La colocación es un fenómeno léxico que da cuenta de las unidades fraseológicas más allá de las locuciones con significado propio. Su interpretación se fundamenta en la frecuencia estadística con la cual ciertos vocablos se relacionan entre sí y cuál es la relevancia de dicha asociación (Alonso Ramos, 1995: 9–28). En este sentido, consideramos esta es una de las estrategias de la lingüística que mejor podemos aprovechar para percibir un posible cambio semántico (Pazos-Bretaña, 2016). Para realizar el análisis de colocación nos servimos de la herramienta informática
LancsBox
(Brezina et al., 2015), así como de las propuestas metodológicas del lingüista Paul Baker (2016: 142–48). Cada segmento del corpus fue interpretado con la opción “GraphColl” del mencionado programa, la cual se configuró con una estrategia estadística MI (
mutual information statistic
) que favorece las relaciones léxicas entre palabras evitando al mismo tiempo artículos de uso frecuente como “el”, “la” o “de”. Se utilizó la extensión de análisis estándar de cinco palabras hacia la izquierda y la derecha del término.
El resultado de cada segmento se asemeja al presentado en la gráfica 1, en el cual se despliegan los valores más significativos de la colocación. En este ejemplo, el término indulto (representado con caracteres comodín para solventar los problemas de
semmatization
y lematización) se despliega en una red que comprende en un primer nivel los términos real, facultad, gracia, perdón, cédula, delito, reos, presos, concesión, entre otros. Todos estos son términos que coinciden con el discurso tradicional del perdón real que dominó durante la Edad Moderna castellana (Rodríguez Flores, 1971; Sandoval Parra, 2014).
Gráfica 1. Red semántica centrada en el concepto indulto (1739-1775). R5-L5, MI(5)
Si se compara con la gráfica 2, el vocablo perdón es reemplazado por el nombre gracia, separándose completamente los términos perdón, clemencia y misericordia del nombre indulto, aunque siguen formando parte de las impetraciones y de las cartas de perdón de parte. Esto parece indicar que en el lenguaje de la práctica jurídico-política hubo un fenómeno de metonimia en el cual la gracia reemplazó al perdón, en este caso, gracia era equivalente a perdón pero no a indulto (por ello se añadiría la conjunción copulativa “indulto y gracia”).
Gráfica 2. Red semántica centrada en el concepto indulto (1790-1807). R5-L5, MI(5)
Proyecciones
Este ejercicio abarca varios procesos relevantes para el análisis de corpus de información histórica no estructurada. Con el avance de la digitalización de fuentes documentales en archivos y bibliotecas en ambos lados del Atlántico la tarea de recuperación y macroanálisis de la información se hace más compleja, por lo cual es necesario ya no sólo introducir metodologías computacionales utilizadas en contextos anglosajones, sino construir estrategias propias que permitan lidiar con una tradición paleográfica y archivística particular.
Las tareas inmediatas que se plantean para este proyecto incluyen el resolver la transcripción de documentos para lo cual se está explorando la plataforma Omeka S, así como la posible exportación de elementos y modelarlos en XML-TEI. Del mismo modo, se pretende mejorar el modelo de segmentación construyendo una estrategia para resolver las disparidades grafológicas. Se espera que estos ejercicios en un futuro pueden ser relevantes para los proyectos de digitalización actuales en Latinoamérica.
Bibliografía
Agüero Nazar, A.
(2012). Historia política e Historia crítica del derecho: convergencias y divergencias.
PolHis
,
5
(10): 81–88.
Alonso Ramos, M.
(1995). Hacia una definición del concepto de colocación: de J. R. Firth a I. A. Mel’ĉuk.
Revista de Lexicografía
,
1
: 9–28.
Baker, P.
(2016). The shapes of collocation.
International Journal of Corpus Linguistics
,
21
(2): 139–64 doi:10.1075/ijcl.21.2.01bak.
Brezina, V., McEnery, T. and Wattam, S.
(2015). Collocations in context: A new perspective on collocation networks.
International Journal of Corpus Linguistics
,
20
(2): 139–73 doi:10.1075/ijcl.20.2.01bre.
Costa, P.
(1972). Semantica e storia del pensiero giuridico.
Quaderni fiorentini per la storia del pensiero giuridico moderno
,
1
(1): 45–87.
Foucault, M.
(1975).
Surveiller et punir: naissance de la prison
. Paris: Gallimard.
Gadamer, H.-G. and Koselleck, R.
(1997).
Historia y hermenéutica
. (Ed.) Villacañas, J. L. & Oncina Coves, F. Barcelona: Paidós.
Hespanha, A. M.
(2002).
Cultura jurídica europea: síntesis de un milenio
. (Trans.) Soler, I. and C. Valera Madrid: Tecnos.
Jockers, M. L.
(2013).
Macroanalysis: Digital Methods and Literary History
. (Topics in the Digital Humanities). Urbana: University of Illinois Press.
Melo Flórez, J. A.
(2016). Metadatos
Cibercliografía
http://cibercliografia.org/manuales/crear-un-fichero-de-investigacion-con-omeka/metadatos/ (accessed 28 April 2018).
Mikheev, A.
(2005). Text Segmentation. In Mitkov, R. (ed),
The Oxford Handbook of Computational Linguistics
. Oxford: Oxford University Press http://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199276349.001.0001/oxfordhb-9780199276349-e-10 (accessed 25 November 2017).
Pazos-Bretaña, J.-M.
(2016). El efecto de la historia sobre el cambio semántico en el español peninsular.
Itinerarios: revista de estudios lingüisticos, literarios, históricos y antropológicos
(23): 123–39.
Prodi, P.
(2000).
Una Storia Della Giustizia: Dal Pluralismo Dei Fori Al Moderno Dualismo Tra Coscienza e Diritto
. (Collezione Di Testi e Di Studi). Bologna: Il mulino.
Rodríguez Flores, M. I.
(1971).
El perdón real en Castilla (siglos XIII-XVIII)
. Salamanca: Universidad de Salamanca.
Sandoval Parra, V.
(2014).
Manera de Galardón: Merced Pecuniaria y Extranjería En El Siglo XVII
. (Sección de Obras de Historia). Madrid: Fondo de Cultura Económica : Red Columnaria.
Turkel, W. J. and Crymble, A.
(2012). From HTML to List of Words (part 2).
Programming Historian
https://programminghistorian.org/lessons/from-html-to-list-of-words-2 (accessed 28 April 2018).
