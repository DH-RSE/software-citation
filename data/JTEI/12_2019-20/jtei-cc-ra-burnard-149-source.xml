<?xml version="1.0" encoding="UTF-8"?><?xml-model href="http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_jtei.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?><?xml-model href="http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_jtei.rng" type="application/xml"
  schematypens="http://purl.oclc.org/dsdl/schematron"?>
<!-- $Id: jtei-cc-ra-burnard-149-source.xml 819 2019-09-06 00:32:19Z ron $ -->
<TEI xmlns="http://www.tei-c.org/ns/1.0" rend="jTEI">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title type="main">What is TEI Conformance, and Why Should You Care?</title>
        <author>
          <name>
            <forename>Lou</forename>
            <surname>Burnard</surname>
          </name>
          <affiliation>Lou Burnard has been closely associated with the <orgName>TEI</orgName> since
            its inception, initially as <roleName>European editor</roleName>, as an elected member
            of the TEI Board and for many years as an active member of the TEI Council. Since
            retirement from <orgName>Oxford University Computing Services</orgName>, where he was
            responsible for the development of the Oxford Text Archive, the British National Corpus,
            and several other key projects in the Digital Humanities, he has continued to provide
            consultancy and training services to many research projects, notably in
            France.</affiliation>
          <email>lou.burnard@gmail.com</email>
        </author>
      </titleStmt>
      <publicationStmt>
        <publisher>TEI Consortium</publisher>
        <date>06/12/2018</date>
        <availability>
          <licence target="https://creativecommons.org/licenses/by/4.0/">
            <p>For this publication a Creative Commons Attribution 4.0 International license has
              been granted by the author(s) who retain full copyright.</p>
          </licence>
        </availability>
      </publicationStmt>
      <seriesStmt>
        <title level="j">Journal of the Text Encoding Initiative</title>
        <editor role="guest">Janelle Jenstad</editor>
        <editor role="guest">Kathryn Tomasek</editor>
        <editor role="guest">Martin Holmes</editor>
        <editor role="chief">John Walsh</editor>
        <editor role="managing">Anne Baillot</editor>
        <editor role="technical">Ron Van den Branden</editor>
        <biblScope unit="issue" n="12">Selected Papers from the 2017 TEI Conference</biblScope>
      </seriesStmt>
      <sourceDesc>
        <p>No source, born digital.</p>
      </sourceDesc>
    </fileDesc>
    <encodingDesc>
      <projectDesc>
        <p>OpenEdition Journals -centre for open electronic publishing- is the platform for journals
          in the humanities and social sciences, open to quality periodicals looking to publish
          full-text articles online.</p>
      </projectDesc>
    </encodingDesc>
    <profileDesc>
      <langUsage>
        <language ident="en">en</language>
      </langUsage>
      <textClass>
        <keywords xml:lang="en">
          <term>conformance</term>
          <term>standardization</term>
          <term>interoperability</term>
          <term/>
        </keywords>
      </textClass>
    </profileDesc>
    <revisionDesc>
      <change when="2019-08-28">Ron Van den Branden updated publication date and revision
        description.</change>
      <change when="2019-01-17">Martin Holmes entered editors’ proofing corrections.</change>
      <change when="2018-12-06">Ron Van den Branden encoded the file.</change>
    </revisionDesc>
  </teiHeader>
  <text>
    <front>
      <div type="abstract" xml:id="abstract">
        <p>The recommendations of the Text Encoding Initiative (TEI) seem to have become a defining
          feature of the methodological framework of the Digital Humanities, despite recurrent
          concerns that the system they define is at the same time both too rigorous for the
          manifold variability of humanistic text, and not precise enough to guarantee
          interoperability of resources defined using it. In this paper I question the utility of
          standardization in a scholarly context, proposing however that documentation of formal
          encoding practice is an essential part of scholarship. After discussing the range of
          information such documentation entails, I explore the notion of conformance proposed by
          the TEI Guidelines, suggesting that this must operate at both a technical syntactic level,
          and a less easily verifiable semantic level. One of the more noticeable features of the
          Guidelines is their desire to have (as the French say) both the butter and the money for
          the butter; I will suggest that this polymorphous multiplicity is an essential component
          of the system, and has been a key factor in determining the TEI’s continued relevance.</p>
      </div>
    </front>
    <body>
      <div xml:id="encodingstandards">
        <head>What Are Encoding Standards Actually For?</head>
        <p>As the old joke says, the good thing about standards is that there are so many to choose
          from. You can choose to follow a dictatorial, centrally imposed,
          we-know-what’s-best-for-you (WKWBFY) encoding method, like Microsoft Word. You can choose
          to follow a handcrafted, idiosyncratic, we-know-what-we’re-doing (WKWWD) kind of encoding
          standard made up and maintained by the leading lights of a particular research community,
          like <ref target="https://sourceforge.net/p/epidoc/wiki/Home/"
                  >EpiDoc</ref>.<note><p><bibl><author>Tom Elliott</author>, <author>Gabriel
                  Bodard</author>, <author>Hugh Cayless</author>, et al., <title level="m">EpiDoc:
                  Epigraphic Documents in TEI XML</title>, <date>2006–2017</date>, accessed October
                25, 2018, <ptr target="http://epidoc.sf.net"/>.</bibl></p></note> Or you can just go
          ahead and do your own encoding thing, which I like to characterize as the
          nobody-understands-my-problems (NUMP) kind of standard. In academia, there’s a good
          argument for each of these approaches; indeed it has been suggested that different
          components of the TEI itself accord differing priority to each of these. The TEI header,
          for example, can be used in a highly prescriptive WKWBFY manner, while users of the TEI
          proposals for feature-structure analysis must be assumed to Know What Is Best for Them.
          And every customizer of the TEI faced with a large amount of ambiguously encoded legacy
          data, or an intransigent user community, must be grateful that in some aspects it permits
          a NUMPty approach (the survival of both vanilla and <soCalled>flavored</soCalled>
          <gi>div</gi> elements such as <gi>div1</gi> and <gi>div2</gi> being a notable example).
          For each approach to standardization has its merits. WKWBFY saves a lot of time and effort
          reinventing the wheel and ensures that your work will be processable and usable in at
          least one application environment: the downside is that you may not want or like the world
          view that the system embodies, but you can’t change it. WKWWD probably means you are
          dealing with congenial and familiar views and are guaranteed respect within your
          community, but no one outside that community will know what to do with your stuff, and you
          may be a bit limited if you want to push the boundaries of knowledge or praxis within it.
          And, of course, NUMP guarantees you the luxury of making all your own decisions, getting
          everything just the way you want, but consequently not only risking isolation from your
          peers but also having to spend lots of time and effort doing technical work that has
          nothing to do with your real scholarly preoccupations.</p>
        <p>When the choice is so hard to make, it may be a good idea to reconsider the motivation
          for making it in the first place. What do we actually gain from adopting an explicit
          encoding standard? What scholarly advantage is there in formally defining the formats of
          our digital re-presentations of cultural artifacts? We may do it simply in order to be
          seen to be ticking the right boxes in a funding agency’s list of criteria; we may do it
          because our elders and betters have told us we should; we may do it because we know no
          better. Such considerations, though intellectually less persuasive, may play a more
          significant part in enlarging the community of standards-conforming users than motivations
          derived from a consideration of scholarly utility. But it still seems useful to ask the
          question: how does the use of explicit standards in the markup of digital resources
          contribute to the success or failure of a scholarly enterprise?</p>
        <p>First, I suggest, we should not forget that the application of markup is an inherently
          scholarly action which, since the goal is to express a scholarly interpretation, is an
          inherently hermeneutic activity. The choice of markup vocabulary is not an arbitrary one,
          but one with consequences. Any given choice may make it harder to express a truth about a
          document or a document’s intentions; it may make it easier to say something which is
          convenient, but false. To dismiss as <q>mere semantics</q> concerns about the proper
          application of markup is thus to embark upon a very dangerous path, if of course you share
          my belief that every scholarly encoding should truthfully represent without convenient
          distortion a scholarly reading.</p>
        <p>Second, if the function of markup is to express an interpretation, then the markup
          language itself should as far as possible eschew ambiguity. Markup defines and determines
          the interface between human interpretation and algorithmic processing. It determines what
          an algorithm has at its disposal to work on yet it is frequently (if not necessarily) the
          product of a nonalgorithmic human interpretation. Life is complicated enough without
          introducing additional fuzziness and inconsistency into the processing stack. We would
          like to live in a world where two equally well-informed observers looking at the same
          encoding will reach similar or identical conclusions as to the interpretations which
          occasioned that encoding. We would also like to be confident that two equally
          well-informed encoders, considering the same textual phenomenon, and having the same
          interpretation of it, will encode that interpretation in the same way. (This is not, of
          course, the same as wishing that all well-informed encoders should reach the same
          interpretative conclusions about a given text. Quite the contrary.) Consequently we desire
          the claims embodied by a marked-up document to be formally verifiable in some way, even
          though there may be limits to the extent to which that can be achieved. Verifiability
          implies the existence of some formal definition for the markup language, against which
          instances of it can be checked, preferably automatically. Talking solely of XML documents,
          we would prefer them to be not just <soCalled>well-formed</soCalled> but also
            <soCalled>valid</soCalled>. If two documents are both valid with respect to the same XML
          schema, we can at least have some confidence that they express comparable interpretations:
          we have reason to believe they will talk about the same things in the same terms.</p>
        <p>The full validation of scholarly markup, however, requires more than simple XML validity
          since a marked-up document has intention beyond what an XML schema can express. A typical
          XML schema will allow me to say that the XML element <gi>p</gi> must appear within the XML
          element <gi>div</gi> and not the reverse, but it will not easily let me say that the
          content of my <gi>p</gi> elements corresponds with a paragraph of text rather than, say, a
          page or a potato. For that information, the user must consult project-specific
          documentation, which should spell out how exactly the intentions behind this set of
          encoded documents are realized by its surface components (such as the start and end tags
          and the attribute value pairs). In the absence of that documentation, all we have are
          expectations based on knowledge of habitual practice.</p>
        <p>Third, therefore, we need to complement the automatic validation of our markup with
          semantic checks which, in our present state of knowledge, are not automatable, and require
          human judgement. It is no coincidence that SGML, the ancestor of XML, was produced by a
          lawyer: the rules embodied by an SGML DTD, like those in the statute book, must be
          interpreted to be used. In the field of the law, the statute book is completed by
          precedents; in the case of an XML schema used by a broad community such as the TEI, the
          rules incarnated in the TEI Guidelines are completed by the practice of those using them,
          whether we are thinking about the Guidelines as a whole, or the customizations of them
          used by individual projects. As discussed further below, a TEI customization expresses how
          a given project has chosen to interpret the general principles enumerated by the
          Guidelines, as well as formally specifying which particular components of the Guidelines
          it uses. It also provides ample opportunity, through documentation and exemplification, to
          guide a human judgement as to the way in which the markup should be understood, and
          therefore the extent to which different datasets using it can be integrated or rendered
          interoperable.</p>
      </div>
      <div xml:id="documentation">
        <head>How Are Encoding Standards to Be Documented?</head>
        <p>As a minimum, the documentation of an encoding language has to be able to specify the
          same things as a schema does, including the names of the elements and attributes used,
          their possible contents, how elements may be validly combined, and what kinds of values
          are permitted for their attributes. Currently available schema languages do not provide an
          entirely identical range of facilities of this kind, nor do they conceptualize the
          validation of documents in exactly the same way, but they are in sufficiently broad
          agreement for it to be possible to model the information they require using a simple XML
          language, which now forms a part of the TEI tagset documentation system, referred to here
          and elsewhere as ODD: an abbreviation for <soCalled>One Document Does it all</soCalled>
          (see further <ref type="bibl" target="#rahtz13">Rahtz and Burnard 2013</ref>; <ref
            type="bibl" target="#burnard04">Burnard and Rahtz 2004</ref>).</p>
        <p>Of course, if schema models were all that ODD supported, it would be hard to persuade
          anyone to use it. The full ODD language provides for much more than the basic information
          required to create a schema model. For example, a full TEI element specification may
          contain:</p>
        <list rend="ordered">
          <item>a canonical name for the element, together with explanatory glosses for the name in
            various languages; alternative names in other languages; equivalents in other markup
            schemes;</item>
          <item>at least one summary description of the meanings and usages intended for the
            element;</item>
          <item>information about the element and attribute classes to which the element
            belongs;</item>
          <item>information about the element’s content model;</item>
          <item>formal specifications for any constraints additional to those expressed by the
            content model;</item>
          <item>a list of specifications for any attributes defined as local to the element rather
            than being inherited from an attribute class;</item>
          <item>formal specifications for the recommended processing model applicable to the
            element;</item>
          <item>annotated examples of usage;</item>
          <item>additional commentary or usage notes;</item>
          <item>a list of references to the chapter of the Guidelines text where the element is
            discussed more fully.</item>
        </list>
        <p>A TEI specification therefore potentially provides data which can be used to facilitate
          many different markup-related processes in a more productive way—making it possible, for
          example, to provide context-sensitive help in different languages, to generate formal
          schema specifications in different schema languages automatically, to provide
          user-oriented tutorial manuals, to develop more intelligent data entry and validation
          systems, or simply to act as a point of entry into the canonical TEI documentation.</p>
        <p>A criticism sometimes made of XML schemas in general and the TEI in particular is that
          they encourage an excessively reductionist perspective. Robinson (<ref xml:id="quoteref1"
            target="#robinson09" type="bibl">2009</ref>) is not alone in asserting that <quote
            source="#quoteref1">the concept of what <soCalled>text</soCalled> is, upon which (for
            instance) the Text Encoding Initiative principles are based<gap/> is positivist,
            overconfident, simplistic and neglects the materiality of actual text instances.</quote>
          TEI markup is believed to convey what a text <quote source="#quoteref2">really is</quote>
            (<ref xml:id="quoteref2" target="#derose90" type="bibl">De Rose et al. 1990</ref>),
          discarding as secondary distractions all the rugosities of real text such as choice of
          typeface or accidentals of printing. But when choosing and defining a markup scheme,
          different projects will legitimately disagree as to which aspects are distractions and
          which are essential. It may after all be that typographic accidentals are precisely the
          focus of scholarly attention, as for example when transcribing early print editions, to
          say nothing of manuscripts. Comparatively recent developments of the TEI have attempted to
          address this concern by enriching the available element set, enabling it to represent (for
          example) digital facsimiles, detailed manuscript transcriptions and descriptions, or
          genetic editions. The cost of this enrichment is evidently that the TEI model becomes more
          complex, so much so that it is doubtful whether it makes any sense to talk of a single TEI
          model, even though some parts of it seem to be universal. The benefit of this enrichment
          is, equally evidently, the ability it confers for a far broader community of users to
          define models precisely fitted to their particular textual perspective, even if those
          models differ widely in the importance they attribute to particular textual features.
          Those for whom the digital edition is a carefully constructed textual reading or set of
          readings can use the TEI to encode them, just as effectively as those for whom it is a
          collection of scrupulously represented and analyzed page images. Both communities benefit,
          moreover, from the availability of a set of common concepts which do not need to be
          redefined or disputed.</p>
        <p>It is often claimed that by focusing on the platonic essence of some collection of data,
          a data model will equally effectively facilitate many possible applications for those
          data. But in the real world, a compromise must be found: in the absence of any engagement
          at all with the way the data being modeled is intended to be used, a model risks being of
          theoretical interest only. The <soCalled>processing model</soCalled> recently added to the
          TEI ODD language is an example of a facility provided by that system which may be said to
          help redress that balance by formally specifying the kind of processing that the encoder
          considers appropriate for a given element. The processing model for an element might, for
          example, just indicate the class of formatting appropriate for it; or it might indicate
          that this is one of the so-called <soCalled>janus</soCalled> elements which present
          alternative encodings for the same phenomenon. In either case, the intention is to
          simplify the task of the application developer faced with a specific customization of the
          TEI, by enlarging the scope of available information beyond what is provided by an XML
          schema. Such documentation will also clearly benefit the person attempting to curate the
          data for the long term. One of the many partially fulfilled promises of the SGML
          revolution was that by abstracting data description away from data processing, data
          longevity would be assured. The experience of those who have tried to reuse existing TEI
          resources suggests that this is true, if only up to a point. One of the take-home messages
          from ambitious reuse projects such as Project Monk (<ref target="#unsworth09" type="bibl"
            >Unsworth and Mueller 2009</ref>) appears to be that ease of reuse is directly
          proportionate to the availability of precise documentation concerning the way a project
          used or intended to use the TEI.</p>
        <p>We conclude, therefore, that the way a data model is recorded and documented is likely to
          be of critical importance in determining its long-term usefulness as well as its immediate
          effectiveness. Today’s digital projects are complex and sometimes overengineered
          constructs; maintaining a clear and accurate record of the data models on which they are
          based is correspondingly necessary.</p>
      </div>
      <div xml:id="customization">
        <head>The Importance of Customization</head>
        <p>As suggested above, the richness of today’s TEI makes it almost essential to customize it
          for any given application, by selecting from the available specifications. To facilitate
          that task, the specifications are grouped together, both physically into named
            <soCalled>modules</soCalled>, and logically into named <soCalled>classes</soCalled>.
          Each module contains a number of related declarations, and modules can be combined as
          necessary, though in practice there are a few modules which provide components needed by
          almost any encoding. In earlier versions of the Guidelines, a distinction was made between
          modules which provided components specific to a particular kind of document (the
            <soCalled>base</soCalled> tagsets) and those which provided components specific to a
          particular kind of analysis (the <soCalled>topping</soCalled> tagsets). The idea was that
          a schema would typically use a single base and multiple toppings, though it was also
          possible to combine multiple bases. This, the so-called pizza model, did not survive into
          TEI P5, where all modules are considered equal. A class, by contrast, is an abstract
          object to which elements point in order to express their semantic or structural status.
          Two kinds of classes are distinguished: model classes and attribute classes. The members
          of a model class share structural properties, in particular the locations in a content
          model where they are permitted; the members of an attribute class share identically
          defined attributes. A customization may define new classes, delete existing ones, or
          modify the membership of a class, though these are facilities that can have unexpected
          consequences, as we discuss below. In SGML-based versions of the Guidelines, classes were
          represented by parameter entities which could be modified by a document instance, thus
          providing extension points for the encoding scheme. In RELAX NG, classes are represented
          as patterns, with similar capabilities.</p>
        <p>A customization which just specifies a selection of modules will overgenerate, not only
          in the sense that the resulting schema will contain specifications for components that
          will never be used, but also because the TEI often provides multiple ways of encoding the
          same phenomenon. For example, the TEI provides three elements for the representation of a
          traditional bibliographic record: <gi>bibl</gi>, <gi>biblStruct</gi>, and
            <gi>biblFull</gi>; these elements differ in their internal syntax, but are semantically
          identical. Similarly, the core module provides a handful of elements (such as
            <gi>foreign</gi>, <gi>emph</gi>, and <gi>soCalled</gi>) for signaling the function
          associated with visual distinctions such as italicization or quotation marks, while also
          providing a way of simply signaling the fact of visual salience or highlighting itself by
          means of the element <gi>hi</gi>. Any or all of these may use any or all of three
          attributes, <att>rend</att>, <att>rendition</att>, or <att>style</att>, each of which
          offers a quite different way of representing how exactly the source is visually or
          otherwise salient. Similarly, the TEI <ident>att.datable</ident> attribute class provides
          two distinct sets of attributes for normalizing dates and times, one conforming to W3C,
          the other conforming to ISO.<note><p>The W3C data formats are as specified by <ref
                target="https://www.w3.org/TR/xmlschema-2/">XML Schema Part 2: Datatypes Second
                Edition</ref>; the ISO formats are specified by ISO/IEC 8601.</p></note> Plus, for
          good measure, a third subclass called <ident>att.datable.custom</ident> allows the encoder
          to use their own conventions. The TEI is scrupulously agnostic even about how a TEI
          document itself is to be constructed: the classic TEI document comprises a TEI header and
          a transcribed text; the transcribed text may, however, be combined with a set of digitized
          images or replaced by one. It is also possible to replace (or complement) the traditional
          text transcription (which aims to capture the logical organization of the source document)
          with a <soCalled>source-oriented</soCalled> transcription which captures just its physical
          organization and eschews other interpretive gestures. And there are plans to add a further
          parallel component to contain annotations made upon the text in a
            <soCalled>stand-off</soCalled> manner (see further <ref target="#pose14" type="bibl"
            >Pose et al. 2014</ref>).</p>
        <p>This multiplicity of choice can be bewildering and may seem absurd. Yet every element and
          attribute in the TEI Guidelines is there because some member of the scholarly community
          has plausibly argued that it is essential to their needs; where there is a choice,
          therefore, it is not because the TEI is indecisive, it is because all of the available
          options have been considered necessary by someone, even if no one (except perhaps those
          blessed with the task of maintaining the TEI) ever considers all of them together.</p>
        <p>A project wishing to use the TEI, and to document that usage accurately, is therefore
          obliged to proceed with caution. Just selecting a few promising modules is not necessarily
          the best approach: a selection must also be made from the components provided by those
          modules, since selecting everything available is a recipe for confusion. Those unwilling
          or inadequately resourced to make this effort can use one of the generic TEI
          customizations made available by the TEI itself (<ref
            target="http://www.tei-c.org/Vault/P5/3.4.0/doc/tei-p5-exemplars/html/tei_simplePrint.doc.html"
            >TEI simplePrint</ref>,<note><p>See <bibl><author>Lou Burnard</author>, <author>Martin
                  Mueller</author>, <author>Sebastian Rahtz</author>, <author>James
                  Cummings</author>, and <author>Magdalena Turska</author>, <title level="m">An
                  Introduction to TEI simplePrint</title>, <pubPlace>n.p.</pubPlace>: <publisher>TEI
                  Consortium</publisher>, January <date>2017</date>, accessed October 26, 2018, <ptr
                  target="http://www.tei-c.org/Vault/P5/3.4.0/doc/tei-p5-exemplars/html/tei_simplePrint.doc.html"
                /></bibl>.</p></note> for example), or by specific research communities (<ref
            target="http://www.stoa.org/epidoc/gl/latest/">EpiDoc</ref><note><p><bibl><author>Tom
                  Elliott</author>, <author>Gabriel Bodard</author>, <author>Elli Mylonas</author>,
                  <author>Simona Stoyanova</author>, <author>Charlotte Tupman</author>,
                  <author>Scott Vanderbilt</author>, et al., <title level="m">EpiDoc Guidelines:
                  Ancient documents in TEI XML</title> (<edition>version 9</edition>),
                  <date>2007–2017</date>, accessed October 26, 2018, <ptr
                  target="http://www.stoa.org/epidoc/gl/latest/"/>.</bibl></p></note> is an
          excellent example; see also <ref target="#bodard10" type="bibl">Bodard 2010</ref>). But
          adopting an off-the-peg encoding system is always going to be less satisfactory than
          customizing one that fits more precisely the actual needs of a project and the actual data
          modeled within it. (It is assumed that a data analysis of some kind is a necessary
          precursor to any digital project.)</p>
        <p>Furthermore, it is painfully true that nothing in digital form is ever really finished.
          Almost inevitably, as a project evolves, things that should have been done differently
          will emerge. In the light of experience, it becomes much easier to change the list of
          available elements to match actual encoding practices more closely. Beginners often think
          it is better to allow almost any kind of content in their schema: an extreme case of this
          misapprehension leads people to use <ident>tei_all</ident> (the exhaustive TEI exemplar
          schema which includes the entirety of TEI features) for everything. It may well be that a
          project starts off a little uncertain about the kind of data it will have to be able to
          handle. But as an encoding project matures, these uncertainties disappear and
          project-specific praxis becomes better understood. The cost-benefit ratio of allowing for
          the unforeseen begins to change. Every element in your schema is another element to
          explain to the encoders, another element to document and find examples for, and another
          element whose usage needs to be checked for consistency. It is also another element that
          the poor overworked software developer writing code to process the encoding has to be
          prepared to handle.</p>
        <p>Similar considerations apply to attributes, and in particular to their ranges of values.
          At the outset of a project, it may have been impossible to predict what values would be
          appropriate for some attribute, and hence the initial model will have allowed anything.
          The price of this laissez-faire policy is that in the absence of guidance, encoders will
          supply widely varying values, for example <val>centre</val>, <val>centered</val>, or
            <val>middle</val>, all meaning (probably) the same thing. Once it becomes clear which
          values are appropriate, it is better to provide such guidance, by adding a
            <gi>valList</gi> to the ODD, even if this entails some additional work cleaning up
          existing data.</p>
        <p>Customization is very often a simple matter of selection, or formally speaking a
          subsetting operation. For example, a customization which specifies that attribute values
          be taken from a closed list of possible values, rather than being any token of the
          appropriate datatype, is a subsetting operation: the set of documents it considers valid
          is a pure subset of the set of documents considered</p>
        <p>The diagram in <ptr target="#figure1" type="crossref"/> represents the variety of
          possible customizations.</p>
        <figure xml:id="figure1">
          <graphic url="images/figure1.png" height="726px" width="1034px"/>
          <head type="legend">Varieties of Customization</head>
        </figure>
        <p>Each of the shapes here may be understood to represent three different things: <list
            rend="bulleted">
            <item>an ODD: that is, a collection of TEI specifications constituting a
              customization</item>
            <item>a formal schema generated from that ODD, and its natural language
              documentation</item>
            <item>the set of documents considered valid by that schema</item>
          </list>
        </p>
        <p>The TEI provides a monolithic unmodified schema called <ident>tei_all</ident> which
          contains all of the elements, classes, macros, and other components defined by the TEI. As
          noted above, for all practical purposes a user of the TEI must make a selection from this
          cornucopia, which I will call a <soCalled>TEI customization</soCalled>, represented as a
          named set of modifications and encoded by a TEI ODD. Of course there are many, many
          possible TEI customizations, each involving different choices of elements or attributes or
          classes, but there are at least two different kinds of customization: a <term>TEI
            subset</term> and a <term>TEI extension</term>. (In proposing this terminology, I am
          reinventing a distinction proposed by David Birnbaum [<ref target="#birnbaum00"
            type="bibl">Birnbaum 2000</ref>, esp. sec. 5.1] which talks of modifications as
            <soCalled>supersets</soCalled> or <soCalled>subsets</soCalled>.)</p>
        <p>When a set of modifications results in a schema which regards as valid a subset of the
          documents considered valid by <ident>tei_all</ident>, I will call this a <soCalled>TEI
            subset</soCalled>; the Guidelines also identify this as a <term>clean
            modification</term>. Where this is not the case, I propose the term <soCalled>TEI
            extension</soCalled>, which the Guidelines identify as an <term>unclean
            modification</term>. A customization which adds new elements or attributes, or one in
          which elements are systematically renamed, cannot result in a subset, because the set of
          documents that the schema generated from it will consider valid is not a proper subset of
          the documents regarded as valid by the <ident>tei_all</ident> schema.</p>
        <p>A change to the content model of an existing TEI element may or may not result in a TEI
          subset. For example, if <ident>tei_all</ident> does not specify an order for the child
          elements of some content model, a customization which does constrain that order will be a
          TEI subset: every document it considers to be valid is also valid according to
            <ident>tei_all</ident>. The reverse is not the case, however: if <ident>tei_all</ident>
          does specify an order, a customization which relaxes that constraint will result in a
          schema that considers valid some documents considered invalid by <ident>tei_all</ident>;
          it is therefore a TEI extension. Removing an element from an attribute class will result
          in that element losing the attributes supplied by the class which (on the assumption that
          none of them is mandatory) will result in a subset. Removing an element from a model class
          will similarly (in most cases) mean that the element ceases to be available in the content
          of other elements, and hence also usually results in a subset. Adding an element to a
          model class in which it did not previously figure, however, will usually result in a TEI
          extension. (Further examples of typical kinds of modification are given in the Guidelines:
            <ref target="#tei18" type="bibl">TEI Consortium 2018, <ref
              target="http://www.tei-c.org/Vault/P5/3.4.0/doc/tei-p5-doc/en/html/USE.html">chap.
              23</ref></ref>.)</p>
        <p>TEI extensions which include TEI elements or attributes whose properties or semantics
          have been significantly changed are expected to place those elements or attributes in a
          different namespace. Such elements should, as far as possible, be included in existing
          content models by making them members of existing TEI classes, rather than by explicitly
          modifying the content model of an existing element. On the face of it, this means that any
          element referencing a new element will have a different content model, and should
          therefore be in a different namespace too. And the same ought to apply to <emph>its</emph>
          parent elements, and so on up to the TEI element itself. Fortunately, there is a nuance of
          detail which means we do not need to invoke this <soCalled>turtles all the way
            up</soCalled> scenario, provided content models are defined not in terms of specific
          elements but with reference to model classes. A class reference will be dereferenced to a
          specific set of elements only when an ODD is converted to a schema; this is necessary
          because the set in question will depend on which elements are available in the
          customization. Any element, including one from a non-TEI namespace, may claim membership
          in a TEI model class and hence legitimately appear in the content of a TEI element
          referencing that class.</p>
        <p>I argue in the next section that TEI conformance is not simply a matter of validity
          against a schema. Nevertheless, there are a few hardwired rules built into the TEI model,
          which the customizer ignores at their (or rather, their potential audience’s) peril.</p>
        <p>For example, a TEI Header really <emph>must</emph> have a title statement containing at
          least one title, along with a publication statement and source description, even if the
          latter two have no significant content. A TEI <gi>text</gi> element really
            <emph>must</emph> contain a <gi>body</gi> element. TEI <gi>div</gi> elements really
            <emph>must</emph> nest correctly within one other. The structural classes in terms of
          which content models are defined really <emph>must</emph> be respected: hence one
            <gi>p</gi> cannot contain another, and a phrase-level element such as <gi>hi</gi> cannot
          contain a block-like element such as <gi>p</gi>.</p>
        <p>Some of these restrictions are the subject of regular debate on TEI-L and elsewhere, but
          for the most part they are, in my view, integral parts of the TEI model. It is a part of
          the definition of a TEI <gi>div</gi> that once you have encountered another nested
            <gi>div</gi> within it, only <gi>div</gi> elements at the same hierarchic level are
          permitted until it finishes; a non-tessellating division element might well be useful, but
          if one is defined it must be distinguished clearly from the existing TEI <gi>div</gi>, for
          example by placing it in a different namespace (assuming that this particular aspect of
          the TEI abstract model remains unchanged).</p>
        <p>Breaking these rules may have unexpected consequences. For example, a customization which
          removes the element <gi>title</gi> completely will result in a schema in which no TEI
            <gi>teiHeader</gi> element can ever be considered valid, since the mandatory components
          of the TEI Header are an essential part of it; a TEI Header which lacks them is a
          different kind of object, and should not present itself as being something which it is
          not.</p>
      </div>
      <div xml:id="teiconformance">
        <head>What Is TEI Conformance?</head>
        <p>Umberto Eco remarks that <quote source="#quoteref3">a novel is a machine for generating
            interpretations</quote> (<ref xml:id="quoteref3" target="#eco84" type="bibl">Eco 1984,
            2</ref>). We might say that the TEI is a machine for generating schemas to formally
          represent such interpretations. However, just as not all interpretations of a novel have
          equivalent expository force, so not all TEI customizations are of equal effectiveness or
          appropriateness; indeed, what is effective or appropriate for one purpose may not be for
          another. A customization explains and defines a view of what it is meaningful and
          appropriate for a given project to assert about a set of instance documents. It does this
          by reference to the very large pre-existing range of concepts distinguished by the TEI,
          selecting from that range the particular distinctions it wishes to make, possibly
          modifying some of them, possibly adding to them. I suggest that our assessment of the
            <soCalled>appropriateness</soCalled>, or conformance, of a given customization should
          take into account the way in which that customization is expressed and the claims it
          consequently makes about its understanding of concepts originally enumerated by the
          TEI.</p>
        <p>There are also good pragmatic grounds for wanting to know how a given customization has
          modified the TEI definitions. Such knowledge enables us to make comparisons among
          different customizations, to assess their relative closeness to the original Guidelines,
          and to determine what might be necessary to make documents using those different
          customizations interchangeable, if not interoperable. As Martin Holmes (<ref
            target="#holmes16" type="bibl">2016</ref>) and others have pointed out, the pursuit of
          unmediated interoperability among TEI documents is largely chimerical, whereas the
          information provided by the documentation of a TEI customization will often be all that is
          needed to make documents using that customization interchangeable.</p>
        <p>Beyond pragmatic considerations, however, a definition of TEI conformance, and some rules
          of thumb for assessing it, are surely needed if the TEI Guidelines are to be more than
          increasingly stale dogma. I suggest that the most useful definition of TEI conformance is
          one that takes into account the original design goals and recommendations of the
          Initiative (<ref target="#msmq88" type="bibl">Sperberg-McQueen and Burnard 1988</ref>),
          which are explicitly formulated to benefit a very broad range of applications and
          disciplines, rather than to impose a single one-size-fits-all standard. It follows that an
          assessment of TEI conformance involves more than simply checking whether the customization
          is a subset of <ident>tei_all</ident> or an extension of it in which all non-TEI
          components have been clearly identified as such. It must also take into account the extent
          to which the encoding respects the TEI semantic model. Where the encoding uses TEI-defined
          elements, these should represent the concepts associated with those elements by the TEI
          Guidelines. Where an encoding enlarges that set of concepts, it should not misuse TEI
          elements to do so, but make explicit that it addresses concepts not addressed by the TEI,
          for example by placing elements in a non-TEI namespace.</p>
        <p>In assessing conformance, there is a natural tendency to attach particular importance to
          validity against a schema, since this is something which can be automatically tested,
          whereas checking the semantic validity of an encoding is not in principle automatable.
          Validation of a document which uses a TEI extension may additionally require the use of a
          namespace-aware validator such as <ref target="https://www.oxygenxml.com/onvdl.html"
            >oNVDL</ref>,<note><p><bibl><title level="u">oNVDL - Oxygen XML NVDL Implementation
                  Based on Jing</title>, <pubPlace>Craiova, Romania</pubPlace>: <publisher>Syncro
                  Soft</publisher>, accessed October 26, 2018, <ptr
                  target="https://www.oxygenxml.com/onvdl.html"/>.</bibl></p></note> which can
          validate different parts of an XML document against possibly many different schemas, using
          the Namespace-based Validation Dispatching Language, defined as part 4 of the ISO standard
          for Document Schema Definition Languages (<ref target="#iso06" type="bibl">ISO
          2006</ref>). This is one reason why validity against <ident>tei_all</ident> has limited
          significance in assessing the conformance of a customization, other than to determine
          whether it is a TEI subset or a TEI extension. The TEI was designed to facilitate
          customization both by subsetting and by extension; either process therefore has the
          potential to result in something which should be considered
            <soCalled>conformant</soCalled>.</p>
        <p>Earlier versions of the P5 Guidelines introduced a notion of <soCalled>TEI
            conformable</soCalled> or <soCalled>algorithmic conformance</soCalled> to identify TEI
          extensions which might be placed at the <soCalled>acceptable</soCalled> end of a notional
          scale of conformance. <quote source="#quoteref4">A document is said to be TEI Conformable
            if it is a well-formed XML document which can be transformed algorithmically and
            automatically into a TEI Conformant document as defined above without loss of
            information</quote> (<ref xml:id="quoteref4" target="#tei08" type="bibl">TEI Consortium
            2008, <ref target="http://www.tei-c.org/Vault/P5/1.1.0/doc/tei-p5-doc/en/html/USE.html"
              >sec. 23.3</ref></ref>). A customization which systematically provides alternative
          identifiers for all the TEI elements it uses by means of the <gi>altIdent</gi> element
          provided for this purpose is clearly more <soCalled>conformable</soCalled> than one which
          simply redefines a few elements with different names, but with the same semantics and the
          same content models as the existing ones. A customization which defines a new element (say
            <gi>botanicalName</gi>) and adds it to an existing class (<ident>model.nameLike</ident>,
          for example) will be more <soCalled>conformable</soCalled> if it also provides an explicit
          TEI mapping for it, using the <gi>equiv</gi> element in its specification to indicate that
          this element is equivalent to <tag>name type="botanical"</tag>. However, despite its
          initial attractiveness, the notion of <soCalled>conformability</soCalled> is impossible to
          define exhaustively and precisely, since anything can be algorithmically converted to
          something else, given sufficient ingenuity, and it no longer features in the Guidelines
          discussion of conformance.</p>
        <p>Nevertheless, if the only distinction we can make as regards conformance is between a TEI
          subset (which is probably ipso facto conformant, though not necessarily) and a TEI
          extension (which is probably ipso facto nonconformant, though not necessarily), the notion
          is not a very helpful one. Intuitively, it seems evident that some modifications are
          closer in spirit to the TEI conceptual model than others, even if they result in a schema
          which is not a TEI subset as previously defined. At the <soCalled>more
            acceptable</soCalled> end of the scale we might place the case of systematic renaming
          already cited; another might be the addition of additional attributes to an existing
          element, where that does not result in a conflict of any kind. For example, not all
          elements are members of the class <ident>att.typed</ident>, and thus many cannot be
          subcategorized. A customization in which (say) the <gi>address</gi> element gains a
            <att>type</att> attribute so that the encoder can distinguish postal addresses from
          email addresses seems entirely innocuous. A processor which knows about the TEI element
            <gi>address</gi> will not go badly astray if it simply ignores the new attribute. If,
          however, the new attribute has a value such as <val>machine</val> or <val>IP</val>, we
          might begin to feel that the concept of <soCalled>address</soCalled> has shifted somewhat,
          and an uninformed TEI processor might well be at a loss to deal with it. Subcategorization
          of this kind should not be a back door to redefining the meaning of an element
          completely.</p>
        <p>A more problematic case of nonconformance would be where a generic subcategorization
          attribute such as <att>type</att> is used to make a distinction already made by an
          existing more precise attribute. For example, <gi>title</gi> has both <att>level</att> and
            <att>type</att> attributes; using the latter to specify the former would be a
          nonconformant usage, even though, in this case, no extension is involved. It is analogous
          to inventing a new non-TEI element that duplicates the function of an existing TEI
          element. Because the TEI is hospitable to other XML vocabularies, an extension using
          elements from another scheme may easily introduce such duplications. For example, if
          Dublin Core elements were embedded directly in the TEI Header, they would duplicate the
          function of many existing TEI elements, with consequent integrity problems, even though
          the DC elements might be clearly labelled as non-TEI, or even embedded within the TEI
            <gi>xenoData</gi> element.</p>
        <p>The ability to extend the range of encodings supported by the TEI simply and
          straightforwardly remains a fundamental requirement for a scheme which is intended to
          serve the needs of research. This requirement has several important benefits: <list
            rend="bulleted">
            <item>it enables the TEI to integrate with comparative ease other specialized XML
              vocabularies, such as MathML, SVG, or most recently MML;</item>
            <item>it facilitates and encourages the development of new TEI components by the broader
              community;</item>
            <item>it simplifies the task of interchange by reducing the possibility of ambiguous or
              incoherent encoding.</item>
          </list>
        </p>
        <p>This polytheoricity underlies the TEI’s apparent complexity, and is also a major
          motivation for the requirement that a modification should use namespaces in a coherent
          manner: in particular, that elements not defined by the TEI, or TEI elements whose
          definition has been modified to such an extent that they arguably no longer represent the
          same concept, should not be defined within the TEI namespace. Of course, reasonable people
          may reasonably disagree about whether two concepts are semantically different, just as
          they may disagree about how to define either concept in the first place. That is part of
          what Darrell Raymond (in an unpublished draft of <ref xml:id="quoteref5"
            target="#raymond96" type="bibl">Raymond, Tompa, and Wood 1996</ref>) memorably called
          the <quote source="#quoteref5">hellfire of ontology</quote> into which the descriptive
          markup project has plunged an entire generation.</p>
        <p>As a simple example of these ontological anxieties, consider the TEI <gi>stamp</gi>
          element. This is intended, if one is to judge from the examples in the Guidelines, to
          document marks impressed on a manuscript or incunable with the aid of a rubber stamp or
          similar object, typically to indicate ownership. But what of marks impressed on a letter
          to indicate the time and date it was posted (the <soCalled>postmark</soCalled>)? What,
          indeed, of the little paper sticker affixed to a postcard or envelope to indicate that
          postage has been paid, the postage stamp? Is either of these semantically close enough to
          the TEI’s existing <gi>stamp</gi> for us to use that element to document them? If a
          postage stamp is not a kind of TEI <gi>stamp</gi>, maybe it is a kind of TEI
          <gi>seal</gi>? A TEI customization designed for a collection of transcribed postcards
          might choose to make use of either of these existing elements for the purpose; or it might
          choose to define its own new element. A TEI application searching blindly through an
          archive for information about seals or stamps (according to the TEI definitions) will be
          misled by either of the first modifications, whereas the presence of a new element should
          not confuse it, as previously noted. This suggests, perhaps paradoxically, that the use of
          a non-TEI element results in a more conformant document than the repurposing of existing,
          semantically related, elements.</p>
        <p>As a further example, consider the Dublin Core <gi>dc:title</gi> element. This has the
          same semantics and serves the same function as the TEI <gi>title</gi> which is a mandatory
          component of the TEI <gi>titleStmt</gi> in the TEI Header. A modification which redefines
          the TEI <gi>titleStmt</gi> to require a <gi>dc:title</gi> instead of a <gi>title</gi>
          might plausibly be argued to respect the TEI conceptual model, even though it is clearly
          invalid with respect to a TEI schema.</p>
        <p>The ability to use explicitly labeled non-TEI elements in a TEI modification may be seen
          as an important coping mechanism, enabling the TEI community to experiment with changes to
          the usual ways of doing things and to enlarge the scope of the scheme in a controlled and
          nondisruptive way. I have argued elsewhere (<ref target="#burnard13" type="bibl">Burnard
            2013</ref>) that one reason for the TEI’s continued longevity is precisely its ability
          to mutate and evolve. This ability is not without a price: the creation of a customization
          does require some knowledge of the whole architecture, and some technical expertise. For
          those already expert in database or non-TEI XML technologies and for the novice alike, the
          effort to maintain TEI conformance may seem an unnecessary additional hurdle.</p>
        <p>These difficulties do not, however, invalidate the general principle that TEI conformance
          should entail a respect for the consensus, just as much as it facilitates autonomy. As we
          have shown, even in the case of a customization which has eschewed extension and appears
          to be a straightforward TEI subset, an assessment of TEI conformance involves attention to
          some constraints which are not formally verifiable. I conclude by suggesting that
          conformance requires attention to two important if largely unenforceable requirements of
            <soCalled>honesty</soCalled> and <soCalled>explicitness</soCalled>.</p>
        <p>By <soCalled>honesty</soCalled> I mean that elements in the TEI namespace must respect
          the semantics which the TEI Guidelines supply as a part of their definition. For example,
          the TEI defines an element <gi>l</gi> as containing <quote source="#quoteref6">a single,
            possibly incomplete, line of verse</quote>.<note><p><bibl xml:id="quoteref6"
                  ><orgName>TEI Consortium</orgName>. <date>2018</date>. <title level="m">TEI P5:
                  Guidelines for Electronic Text Encoding and Interchange</title>. <edition>Version
                  3.4.0</edition>. Last updated July 23. <pubPlace>N.p.</pubPlace>: <publisher>TEI
                  Consortium</publisher>. <ptr
                  target="http://www.tei-c.org/Vault/P5/3.4.0/doc/tei-p5-doc/en/html/ref-l.html"
                />.</bibl></p></note> If an encoding distinguishes verse and prose, it would be
          dishonest to use this element to mark line breaks in prose, since to do so would imply
          that the element contains verse rather than prose. Most TEI elements are provided in order
          to make an assertion about the semantics of a piece of text: that it contains a personal
          name rather than a place name, for example, or a date rather than a number. Misapplying
          such elements is clearly counterproductive. (Honestly made misreadings are of course
          entirely forgiveable: an encoding always asserts an interpretation, not the absolute truth
          of that interpretation.)</p>
        <p>By <soCalled>explicitness</soCalled> I mean that modifications should be properly
          documented, preferably by means of an ODD specifying exactly how the TEI declarations on
          which they are based have been derived. (An ODD need not of course be based on the TEI at
          all, but in that case the question of TEI conformance does not arise.) The ODD language is
          rich in documentary components, not all of which are automatically processable, if only
          because their processing is not fully specified (the <gi>equiv</gi> and
            <gi>altIdentifier</gi> elements, for example). But it is usually much easier to
          determine how the markup of a set of documents should be interpreted or processed from an
          ODD than it is from the many pages of human-readable documentation needed to explain
          everything about an idiosyncratic encoding scheme.</p>
        <p>To summarize and conclude, I suggest that we should say of a document that it is
            <soCalled>TEI conformant</soCalled> if and only if : <list rend="bulleted">
            <item>it is a well formed XML document; and</item>
            <item>it is valid against one or more schemas, which may be either a TEI subset or a TEI
              extension; and</item>
            <item>its usage of elements in the TEI namespace is compatible with the intended
              function of those elements as defined by the TEI Guidelines; and</item>
            <item>its usage of the TEI markup scheme is fully described by a TEI-conformant ODD or
              analogous documentation.</item>
          </list>
        </p>
        <p>The purpose of these rules is to make interchange of documents easier. They do not
          guarantee it, and they certainly do not provide any guarantee of interoperability. But
          they make much simpler, for example, the kind of scenario envisaged by Holmes (<ref
            target="#holmes16" type="bibl">2016</ref>) in which a richly encoded, highly
          personalized TEI encoding can be simply down-translated to other, possibly less
          expressive, semistandardized encodings for purposes of interchange. As more and more
          independent agencies undertake mass digitization and encoding projects, the risk of a new
          confusion of tongues—the threatened Tower of Babel which the TEI was specifically created
          to resist—has not retreated. A definition of conformance which relies on an enforced
          lowest common denominator standard (Dublin Core springs to mind) makes it hard to benefit
          from truly sophisticated and scholarly standards. One which promotes permissiveness and
          extensibility, as the TEI does, has to balance the sophistication of what it makes
          feasible with a clear and accessible definition of its markup. Unlike many other
          standards, the goal of the TEI <soCalled>standard</soCalled> is not to enforce consistency
          of encoding, but to provide a means by which encoding choices and policies may be more
          readily understood, and hence more easily made algorithmically comparable.</p>
      </div>
    </body>
    <back>
      <div type="bibliography">
        <listBibl>
          <bibl xml:id="birnbaum00"><author>Birnbaum, David J.</author>
            <date>2000</date>. <title level="a">The Relationship between General and Specific DTDs:
              Criticizing TEI Critical Editions.</title>
            <title level="j">Markup Languages: Theory and Practice</title>
            <biblScope unit="volume">3</biblScope> (<biblScope unit="issue">1</biblScope>):
              <biblScope unit="page">17–53</biblScope>. Author’s version, last revised July 5, 2000,
            available at <ptr target="http://www.obdurodon.org/djb/tei-crit/"/>.</bibl>
          <bibl xml:id="bodard10"><author>Bodard, Gabriel</author>. <date>2010</date>. <title
              level="a">EpiDoc: Epigraphic Documents in XML for Publication and Interchange.</title>
            In <title level="m">Latin on Stone: Epigraphic Research and Electronic Archives</title>,
            edited by <editor>Francisca Feraudi-Gruénais</editor>, <biblScope unit="page"
              >101–18</biblScope>. <pubPlace>Lanham, MD</pubPlace>: <publisher>Lexington
              Books</publisher>.</bibl>
          <bibl xml:id="burnard13">Burnard, Lou. 2013. <title level="a">The Evolution of the Text
              Encoding Initiative: From Research Project to Research Infrastructure.</title>
            <title level="j">Journal of the Text Encoding Initiative</title>
            <biblScope unit="issue">5</biblScope>. <ptr
              target="https://journals.openedition.org/jtei/811"/>; doi:<idno type="doi"
              >10.4000/jtei.811</idno>.</bibl>
          <bibl xml:id="burnard04"><author>Burnard, Lou</author>, and <author>Sebastian
              Rahtz</author>. <date>2004</date>. <title level="a">RelaxNG with Son of ODD</title>.
            In <title level="m">Proceedings of Extreme Markup Languages 2004</title>. <ptr
              target="http://conferences.idealliance.org/extreme/html/2004/Burnard01/EML2004Burnard01.html"
            />.</bibl>
          <bibl xml:id="derose90"><author>De Rose</author>, <author>Steven J.</author>,
              <author>David G. Durand</author>, <author>Elli Mylonas</author>, and <author>Allen H.
              Renear</author>. <date>1990</date>. <title level="a">What Is Text, Really?</title>
            <title level="j">Journal of Computing in Higher Education</title>
            <biblScope unit="volume">1</biblScope> (<biblScope unit="issue">2</biblScope>):
              <biblScope unit="page">3–26</biblScope>. doi:<idno type="doi"
              >10.1007/BF02941632</idno>.</bibl>
          <bibl xml:id="eco84"><author>Eco, Umberto</author>. <date>1984</date>. <title level="m"
              >Postscript to <soCalled>The Name of the Rose</soCalled></title>. Translated by
              <editor role="translator">William Weaver</editor>. <pubPlace>New York</pubPlace>:
              <publisher>Harcourt Brace Jovanovich</publisher>.</bibl>
          <bibl xml:id="holmes16"><author>Holmes, Martin</author>. <date>2016</date>. <title
              level="a">Whatever Happened to Interchange?</title>
            <title level="j">Digital Scholarship in the Humanities</title>
            <biblScope unit="issue">32, Issue suppl_1</biblScope> (1 April 2017): <biblScope
              unit="page">i63–i68</biblScope>. doi:<idno type="doi"
            >10.1093/llc/fqw048</idno>.</bibl>
          <bibl xml:id="iso06"><orgName>ISO (International Organization for
              Standardization)</orgName>. <date>2006</date>. <title level="m">Information technology
              — Document Schema Definition Languages (DSDL) — Part 4: Namespace-based Validation
              Dispatching Language (NVDL).</title> ISO/IEC 19757–4:2006.
            <pubPlace>Geneva</pubPlace>: <publisher>ISO</publisher>. <ptr
              target="https://www.iso.org/standard/38615.html"/>.</bibl>
          <bibl xml:id="pose14"><author>Pose, Javier</author>, <author>Patrice Lopez</author>, and
              <author>Laurent Romary</author>. <date>2014</date>. <title level="u">A Generic
              Formalism for Encoding Stand-off Annotations in TEI</title>. <ptr
              target="https://hal.inria.fr/hal-01061548/"/>.</bibl>
          <bibl xml:id="rahtz13"><author>Rahtz, Sebastian</author>, and <abbr>Lou Burnard</abbr>.
              <date>2013</date>. <title level="a">Reviewing the TEI ODD System</title>. In <title
              level="m">Proceedings of the 2013 ACM Symposium on Document Engineering (DocEng
              ’13)</title>, <biblScope unit="page">193–96</biblScope>. <pubPlace>New
            York</pubPlace>: <publisher>ACM</publisher>. <ptr
              target="https://ora.ox.ac.uk/objects/pubs:434097"/>; <ref
              target="http://doi.acm.org/10.1145/2494266.2494321.">doi:<idno type="doi"
                >10.1145/2494266.2494321</idno></ref>.</bibl>
          <bibl xml:id="raymond96"><author>Raymond, Darrell</author>, <author>Frank Tompa</author>,
            and <author>Derick Wood</author>. <date>1996</date>. <title level="a">From Data
              Representation to Data Model: Meta-semantic Issues in the Evolution of SGML.</title>
            <title level="j">Computer Standards &amp; Interfaces</title>
            <biblScope unit="volume">18</biblScope> (<biblScope unit="issue">1</biblScope>):
              <biblScope unit="page">25–36</biblScope>. doi:<idno type="doi"
              >10.1016/0920-5489(96)00033-5</idno>.</bibl>
          <bibl xml:id="robinson09"><author>Robinson, Peter</author>. <date>2009</date>. <title
              level="a">What Text Really Is Not, and Why Editors Have to Learn to Swim</title>.
              <title level="j">Literary and Linguistic Computing</title>
            <biblScope unit="volume">24</biblScope> (<biblScope unit="issue">1</biblScope>):
              <biblScope unit="page">41–52</biblScope>. doi:<idno type="doi"
              >10.1093/llc/fqn030</idno>.</bibl>
          <bibl xml:id="msmq88"><author>Sperberg-McQueen, C. M.</author>, and <author>Lou
              Burnard</author>. <date>1988</date>. <title level="u">Design Principles for Text
              Encoding Guidelines. TEI ED P1</title>. December 14, 1988, revised January 9, 1990.
              <ptr target="http://www.tei-c.org/Vault/ED/edp01.htm"/>.</bibl>
          <bibl xml:id="tei08"><orgName>TEI Consortium</orgName>. <date>2008</date>. <title
              level="m">TEI P5: Guidelines for Electronic Text Encoding and Interchange</title>,
            edited by <editor>Lou Burnard</editor> and <editor>Syd Bauman</editor>. <edition>Version
              1.1.0</edition>. <pubPlace>Oxford</pubPlace>: <publisher>TEI Consortium</publisher>.
            PDF and HTML versions available at <ptr
              target="http://www.tei-c.org/Vault/P5/1.1.0/doc/tei-p5-doc/en/html/"/>.</bibl>
          <bibl xml:id="tei18"><orgName>TEI Consortium</orgName>. <date>2018</date>. <title
              level="m">TEI P5: Guidelines for Electronic Text Encoding and Interchange</title>.
              <edition>Version 3.4.0</edition>. Last updated July 23. <pubPlace>N.p.</pubPlace>:
              <publisher>TEI Consortium</publisher>. <ptr
              target="http://www.tei-c.org/Vault/P5/3.4.0/doc/tei-p5-doc/en/html/"/>.</bibl>
          <bibl xml:id="unsworth09"><author>Unsworth, John</author>, and <author>Martin
              Mueller</author>. <date>2009</date>. <title level="u">The MONK Project Final
              Report</title>. September 2. <ptr
              target="http://www.monkproject.org/MONKProjectFinalReport.pdf"/>.</bibl>
        </listBibl>
      </div>
    </back>
  </text>
</TEI>
