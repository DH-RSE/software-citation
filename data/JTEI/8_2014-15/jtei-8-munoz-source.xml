<?xml version="1.0" encoding="UTF-8"?><?xml-model href="http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_jtei.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?><?xml-model href="http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_jtei.rng" type="application/xml"
	schematypens="http://purl.oclc.org/dsdl/schematron"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" rend="jTEI">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title type="main">Texts and Documents</title>
        <title type="sub">New Challenges for TEI Interchange and Lessons from the Shelley-Godwin
          Archive</title>
        <author>
          <name>
            <forename>Trevor</forename>
            <surname>Muñoz</surname>
          </name>
          <affiliation>Trevor Muñoz is <roleName>assistant dean for digital humanities
              research</roleName> at the <orgName>University of Maryland Libraries</orgName> and an
              <roleName>associate director</roleName> of the <orgName>Maryland Institute for
              Technology (MITH)</orgName>. He works on developing digital research projects and
            services at the intersection of digital humanities centers and libraries. Trevor’s
            research interests include electronic publishing and the curation and preservation of
            digital humanities research data.</affiliation>
          <email>tmunoz@umd.edu</email>
        </author>
        <author>
          <name>
            <forename>Raffaele</forename>
            <surname>Viglianti</surname>
          </name>
          <affiliation>Raffaele Viglianti is a <roleName>research programmer</roleName> at the
              <orgName>Maryland Institute for Technology in the Humanities (MITH)</orgName>. He is
            involved in front-end development and TEI-based digital editorial projects. Raffaele
            holds active roles in both the TEI and MEI communities and his research on digital
            editing spans both TEI [textual] and MEI [musical] practices.</affiliation>
          <email>rviglian@umd.edu</email>
        </author>
      </titleStmt>
      <publicationStmt>
        <publisher>TEI Consortium</publisher>
        <date>23/09/2015</date>
        <availability>
          <licence target="https://creativecommons.org/licenses/by/4.0/">
            <p>For this publication a Creative Commons Attribution 4.0 International license has
              been granted by the author(s) who retain full copyright.</p>
          </licence>
        </availability>
      </publicationStmt>
      <seriesStmt>
        <title level="j">Journal of the Text Encoding Initiative</title>
        <editor role="guest">Arianna Ciula</editor>
        <editor role="guest">Fabio Ciotti</editor>
        <editor role="chief">John Walsh</editor>
        <editor role="managing">Martin Holmes</editor>
        <editor role="technical">Ron Van den Branden</editor>
        <biblScope unit="issue" n="8">Selected Papers from the 2013 TEI Conference</biblScope>
      </seriesStmt>
      <sourceDesc>
        <p>No source, born digital.</p>
      </sourceDesc>
    </fileDesc>
    <encodingDesc>
      <projectDesc>
        <p>Revues.org -centre for open electronic publishing- is the platform for journals in the
          humanities and social sciences, open to quality periodicals looking to publish full-text
          articles online.</p>
      </projectDesc>
    </encodingDesc>
    <profileDesc>
      <langUsage>
        <language ident="en">en</language>
      </langUsage>
      <textClass>
        <!-- [RvdB] keywords missing -->
        <keywords xml:lang="en">
          <term>digital archive</term>
          <term>diplomatic transcript</term>
          <term>schema design</term>
          <term>manuscript encoding</term>
          <term>linked data</term>
          <term>interchange</term>
          <term>Romanticism</term>
        </keywords>
      </textClass>
    </profileDesc>
  </teiHeader>
  <text>
    <front>
      <div type="abstract" xml:id="abstract">
        <p>The introduction in 2011 of additional <soCalled>document-focused</soCalled> (as opposed
          to <soCalled>text-focused</soCalled>) elements represents a significant additional
          commitment to modeling two distinct ontologies for textual data within the standard
          governed by the Text Encoding Initiative (TEI) Guidelines. A brief review of projects
          using the new elements suggests that scholars generally treat the
            <soCalled>document-focused</soCalled> and <soCalled>text-focused</soCalled> models as
          distinct and even severable—the tools of separate interpretive communities within literary
          studies. This paper will describe challenges encountered by members of the development and
          editorial teams of the Shelley-Godwin Archive (S-GA) in attempting to produce TEI-encoded
          data (as well as an accompanying reading environment) that supports both document-focused
          and text-focused approaches through automated conversion. Based on the experience of the
          S-GA teams, the increase in expressiveness achieved through the addition of
          document-focused elements to the TEI standard also raises the stakes for
            <soCalled>interchange</soCalled> between and among data modeled according to these
          parallel approaches.</p>
      </div>
      <div type="acknowledgements">
        <p>This paper was originally presented at the 2013 TEI Members’ Meeting, October 2–5, 2013,
          in Rome, Italy. We would like to thank the audience members from that original
          presentation for their engaging and probing questions. We would also like to thank Neil
          Fraistat, who collaborated on the development of the original presentation. Thanks also to
          Jennifer Guiliano, who commented on drafts of this piece. Finally, the ideas developed
          here owe everything to the team of people who have participated in the Shelley-Godwin
          Archive project. The Shelley-Godwin Archive is the ever-growing, collaborative product of
          many hands across a variety of institutions and disciplines. Please see <ptr
            target="http://shelleygodwinarchive.org/about"/> for a full list of our collaborators.
          We thank them profusely.</p>
      </div>
    </front>
    <body>
      <div xml:id="background">
        <head>Background of the Shelley-Godwin Archive</head>
        <p> The Shelley-Godwin Archive is a project involving the Maryland Institute for Technology
          in the Humanities (MITH) and the Bodleian, British, Huntington, Houghton, and New York
          Public Libraries that will eventually contain the works and all known manuscripts of Mary
          Wollstonecraft, William Godwin, Percy Bysshe Shelley, and Mary Wollstonecraft Shelley. The
          S-GA project began in 2011 and completed its first phase of work in 2015. In October 2013,
          the project released a beta version of its online reading environment containing
          high-resolution images and accompanying TEI-encoded transcriptions of the three surviving
          manuscript notebooks containing Mary Shelley’s drafts of <title level="m">Frankenstein,
            or, The Modern Prometheus</title>.</p>
        <p>The development of the S-GA from its original conception to current plans for second and
          future phases of work reflects wider shifts in emphasis within the digital humanities:
          from construction and online presentation of expert-curated digital collections (<ref
            type="bibl" target="#palmer04">Palmer 2004</ref>) to experiments with more participatory
          forms of scholarship (<ref type="bibl" target="#burdick12">Burdick et al. 2012</ref>). The
          central claims of the original grant proposal for S-GA (submitted in 2010)<note>The
            authors joined the S-GA Project in 2011 and 2013 respectively.</note> reach back to
          rhetoric from earlier digital humanities and digital library development that centered on
          the possibilities for technology to enable virtual reunification of dispersed collections.
          Such motivations were more common to the framing of digital projects ten years older than
          S-GA—dating from the early- to mid-2000s (<ref type="bibl" target="#deegan02">Deegan and
            Tanner 2002</ref>; for a fuller discussion see <ref type="bibl" target="#punzalan13"
            >Punzalan 2013</ref>). Driven by the original vision of virtual reunification (largely
          without editorial intervention), the proposal for the project’s first phase centered on
          imaging of manuscript materials from the partner libraries: <quote source="#quoteref1"
            >With the digitization of these items, particularly P. B. Shelley’s notebooks, the
            Archive will make an invaluable contribution to Romantic scholarship—bringing together
            an entire group of widely scattered rare sources</quote> (<ref xml:id="quoteref1"
            type="bibl" target="#nypl10">New York Public Library 2010</ref>).</p>
        <p>Yet, the original plan for the S-GA also showed hallmarks of a field in transition—from
          one in which simply getting materials online was a central goal to one increasingly
          focused on allowing users to interact with online materials in additional ways, a trend
          loosely captured under the banner of <soCalled>Web 2.0</soCalled> (<ref type="bibl"
            target="#oreilly05">O’Reilly 2005</ref>). The catalogue of functionalities proposed for
          S-GA (all based on a prior collaborative project between several of the partners, <title
            level="m">The Shakespeare Quartos Archive</title>) speaks to a nebulous and evolving
          conception of how those outside the project team might interact with this kind of digital
          scholarship. Users would have, the proposal declared, <quote source="#quoteref2">capacity
            to collate texts, the ability to overlay images of the original printed editions,
            compare images side by side, search full-text, and tag text with user
            annotations</quote> [<emph>sic</emph>] (<ref xml:id="quoteref2" type="bibl"
            target="#nypl10">New York Public Library 2010</ref>). By the time work commenced in late
          2011, the encoding of materials from the archive in TEI had been promoted to a more
          significant component of the project alongside digitization, while other potential
          features were deferred.</p>
        <p>The decision to invest in TEI encoding of the S-GA materials along with a reading
          environment designed to take advantage of features of these textual data has allowed the
          project to remain current with developments in the digital humanities and scholarly
          editing not envisioned in the original proposal. Through work on the text encoding schema
          and reading environment, the S-GA project has refined its conception of how this type of
          scholarship can create new knowledge. Rather than a grab-bag of <soCalled>Web
            2.0</soCalled> functionalities, engagement with text encoding, an interpretive method
          created by and specific to the digital humanities, forms the backbone of the S-GA
          project’s work with these important materials.</p>
      </div>
      <div xml:id="motivations">
        <head>Motivations for the S-GA Encoding Scheme</head>
        <p>The start of text encoding work on the S-GA coincided with the addition of the new
            <soCalled>document-focused</soCalled> elements to the TEI in the release of P5 version
          2.0.1. These additions were the product of recent efforts by a subgroup of the TEI
          Manuscript Special Interest Group and have resulted in a considerable expansion of <title
            level="a">Representation of Primary Sources</title> (<ref
            target="http://www.tei-c.org/Vault/P5/2.0.1/doc/tei-p5-doc/en/html/PH.html">chapter 11
            of the TEI Guidelines</ref>). In the ontology that the new elements are intended to help
          express, digital text is encoded by describing the relationship of written traces to their
          physical carriers (<ref type="bibl" target="#tei11">TEI Consortium 2011</ref>). This
          encoding approach switches focus from text as communicative act or linguistic content to
          text as sign on some physical support; for the purposes of this paper this approach will
          be referred to as <soCalled>document-focused</soCalled> encoding. That is, encoders may
          formalize their understanding of how the text takes form on a surface; they will, for
          example, identify zones that group text topographically and the lines of text within such
          zones. Encoders may moreover track an author’s actions on the page, identify textual
          revisions, movements, and deletions, and assert a temporal order for such actions.
          Describing how a text has been inscribed on a surface is an essential preoccupation of
          scholars who practice genetic textual criticism. The document-focused encoding strategy is
          closely but not exclusively identified with the interpretive goals of genetic criticism
          throughout this discussion. Divergences from a strict genetic editing approach will be
          described below. The document-focused approach contrasts with an ontology of text in which
          encoders describe, through combinations of elements and attributes, what a certain portion
          of text <q>is</q>. By surrounding characters with a <gi>p</gi> element, for example, an
          encoder formally asserts that those characters form a <term>paragraph</term>. This
          approach can quickly become more and more complex, depending on both the text and the
          encoder’s research agenda. Herein this approach will be referred to as
            <soCalled>text-focused</soCalled> encoding (cf. <ref type="bibl" target="#rehbein13"
            >Rehbein and Gabler 2013</ref>).</p>
        <p>Given that the majority of materials in the Shelley-Godwin Archive consist of autograph
          manuscripts, the editorial team quickly adopted several of the new elements proposed by
          the manuscript working group such as <gi>sourceDoc</gi>, <gi>zone</gi>, and <gi>line</gi>
          (with their greatly restricted content models) into its TEI customization. This
          document-focused approach has served the project well. It yields an encoding scheme that
          targets features of greatest interest to the scholarly editors who make up the initial
          user community (the principal investigator and collaborators). Also, focus on documents
          permits rigorous description of often complicated sets of additions, deletions, and
          emendations. In the case of the manuscript notebooks of <title level="m"
            >Frankenstein</title>, the encoding scheme for S-GA identifies each page as a
            <gi>surface</gi> containing one or more <gi>zone</gi>s.<note>As the TEI Guidelines note,
              <gi>surface</gi> may represent an opening in a codex within a single element. However,
            since the original items in this case have been disbound for conservation treatment,
              <gi>surface</gi> always refers to a single recto or verso.</note> Most pages have a
          main body of writing as well as a wide left margin, where Shelley’s husband Percy wrote
          annotations and revisions to the developing text. These separate writing areas are encoded
          as <gi>zone</gi> elements containing writing organized into <gi>line</gi> elements. On top
          of this basic model, information about authorial hands (who wrote what) is encoded as well
          as revisions—including deletions, additions, substitutions, and transposed and retraced
          text. The reading environment created from this encoding is used to publish a
          semi-diplomatic transcription of the text alongside a facsimile image.</p>
        <figure xml:id="figure1">
          <graphic url="images/jtei-8-munoz-figure-01.png" width="575px" height="402px"/>
          <head type="legend">A screenshot of the primary reading interface of the Shelley-Godwin
            Archive</head>
        </figure>
        <p>As the discussion above suggests, the S-GA encoding scheme borrows concepts and
          terminology from genetic editing where the motivations align; namely in the representation
          of the <foreign xml:lang="fr">mise-en-page</foreign> of writing on the manuscripts.
          However, the SG-A does not seek to produce genetic editions of the works represented in
          the archive. Digital genetic editions usually emphasize the temporal sequence of authorial
          revision and make a stronger distinction between what is on the page and what is
          interpreted from the page. For example, the <title level="m">Digitale Faustedition</title>
          project—which directly contributed to the expansion of the chapter of the TEI Guidelines
          on representation of primary sources—made this distinction by using two different encoding
          models for the same documents. The models correspond to the concepts of
            <soCalled>record</soCalled> and <soCalled>interpretation</soCalled> (<foreign
            xml:lang="de">Befund</foreign> and <foreign xml:lang="de">Deutung</foreign>) first
          introduced in 1971 by Hans Zeller (cited in <ref type="bibl" target="#brüning13">Brüning,
            Henzel, and Pravida 2013</ref>). The <soCalled>record</soCalled> (<foreign xml:lang="de"
            >Befund</foreign>) consists of information about a primary source, of which the editor
          can make a detailed diplomatic transcription as the record of what is
            <soCalled>found</soCalled> on the source.<note>Some interpretation is always involved in
            determining what is important among the facts that can be <soCalled>found</soCalled> in
            the document. If anything, dealing with <foreign xml:lang="de">Befund</foreign> in a
            digital context poses new complications, because digital diplomatic transcriptions are
            less bound by the limits of paper-based reproduction. Elena Pierazzo (<ref
              xml:id="quoteref3" type="bibl" target="#pierazzo11">2011, 463</ref>) has pointed out
            that <quote source="#quoteref3"><supplied>f</supplied>or print the choice of which
              features to include in <supplied>a</supplied> transcription is limited largely by the
              limits of the publishing technology. In contrast, the digital medium has proved to be
              much more permissive and so editors need new scholarly guidelines to establish
                <q>where to stop</q>.</quote> The challenges in establishing clear expectations for
            a digital diplomatic transcription reveal how the <foreign xml:lang="de"
              >Befund</foreign> is very much subject to editorial interpretation: editors still need
            to choose what to record from among what is evident from the source.</note> For example,
          some text that has been struck through may only be encoded as being struck through (i.e.,
          not deleted). The <soCalled>interpretation</soCalled> (<foreign xml:lang="de"
            >Deutung</foreign>) records an editor’s understanding of a writing act on the page; for
          example, some struck-through text is interpreted as a deletion. The <title level="m"
            >Digitale Faustedition</title> project sees this interpretation as belonging to a
          linguistic domain; therefore, it conflates the marking of <soCalled>deletion</soCalled>
          with a more traditional text-focused encoding that includes linguistic and literary
          structures such as paragraphs and verses.</p>
        <p>The S-GA, not being a genetic edition, conflates in one encoding model the
          transcriptional and editorial work more closely related to the document (roughly
          corresponding to <foreign xml:lang="de">Befund</foreign> and <foreign xml:lang="de"
            >Deutung</foreign>). This conflation is not an accidental failure to conform to one or
          another ontology of text. The task of developing an encoding scheme to match the goals of
          the S-GA project pushed the editorial team to consciously borrow tools from both
          interpretive communities. That is, rather than seeking to produce an established edition
          or publication, the S-GA project has chosen to embrace the ambiguous nature of this type
          of digital humanities work (<ref type="bibl" target="#price09">Price 2009</ref>) in
          pursuit of the goal of constructing the S-GA as a work site wherein the encoded text,
          along with its tailor-made reading environment, <soCalled>operationalizes</soCalled>
          certain aspects of editorial theory. The encoding scheme of the S-GA, drawing on a
          document-focused approach, is a formal model for operationalizing literary knowledge about
          how texts are constructed from written documents (<ref type="bibl" target="#moretti13"
            >Moretti 2013</ref>). Franco Moretti defines <soCalled>operationalizing</soCalled> as
            <quote source="#quoteref4">the process whereby concepts are transformed into a series of
            operations <gap/>. Operationalizing means building a bridge from concepts to
            measurement, and then to the world</quote> (<ref xml:id="quoteref4" type="bibl"
            target="#moretti13">103–4</ref>). In Moretti’s case measurement involves quantification
          of features of literary texts, but measurement need not imply only quantification. In the
          case of S-GA, the encoding scheme is a formal model by which information about the
            <foreign xml:lang="fr">mise-en-page</foreign> of the various writing traces helps
          develop greater knowledge about the literary work <title level="m"
          >Frankenstein</title>.</p>
        <p>To achieve this goal, the editorial team needed to be able to produce two distinct
          representations of the S-GA materials so as to provide rigorous, semi-diplomatic
          transcriptions of the fragile manuscripts for those with an interest in the compositional
          practices of a significant group of British Romantic authors, and also to make available
          clear <soCalled>reading texts</soCalled> for those who are primarily interested in the
          final state of each manuscript. Thus, what was needed was not only the powerful new
          formalization of document-focused encoding but also a mechanism to enable movement back
          and forth between document-focused and text-focused models of the materials in the
          Archive. The development of the document-focused encoding scheme has been described above.
          The work of automating the production of usable <soCalled>reading texts</soCalled> encoded
          in text-focused TEI markup from data that is modeled according to a document-focused
          approach proved much more challenging. Conversion and interchange between these two models
          poses challenges for encoding practice and workflow, for data provenance and
          maintainability, and for reading environment and presentation.</p>
      </div>
      <div xml:id="workflow">
        <head>Encoding Workflow Challenges</head>
        <p>The conflict between representing multiple hierarchies of content objects and the
          affordances of XML is well known, and the TEI Guidelines as well as the professional
          literature of the text encoding community discuss several possible solutions (<ref
            type="bibl" target="#tei11">TEI Consortium 2011</ref>; <ref type="bibl"
            target="#renear96">Renear, Mylonas, and Durand 1993</ref>; <ref type="bibl"
            target="#roland03">Roland 2003</ref>; <ref type="bibl" target="#piez13">Piez
          2013</ref>). One of these solutions is to designate a primary hierarchy and to represent
          additional hierarchies with empty milestone elements that can be used by some processing
          software to construct an alternate representation of the textual object. The approach
          taken by the S-GA team to produce both document-focused and text-focused TEI data is a
          version of the milestone-based approach. The document-focused elements form the principal
          hierarchy while milestone elements are supplied to support automatic conversion to
          text-focused markup (which will contain elements such as <gi>div</gi>, <gi>p</gi>,
            <gi>lineGrp</gi>, etc.).</p>
        <p>This solution places increased burden on document encoders to maintain
            <soCalled>correctness</soCalled>, thus potentially lowering data consistency and
          quality. For instance, empty element milestones representing the beginning and ending of
          textual features have no formal linkages as part of the document-focused document tree.
          Encoders must supply identifiers and pointers to indicate these linkages. Ensuring that
          these identifiers and pointers pair correctly must be accomplished with some mechanism
          other than the RELAX NG validation that checks conformance to the rules specified in the
          TEI schema. In S-GA this is partly addressed by a number of Schematron rules added to our
          TEI schema customization. These further checks, however, add an additional step within the
          processing workflow that must be balanced against the need for a simpler and efficient
          encoding workflow. As noted above, managing multiple hierarchies through the use of
          milestones is not new. The experience of the S-GA team suggests that the new possibilities
          available through the increased expressiveness of the TEI Guidelines, which include the
          additional document-focused elements, also increase the scope for projects to produce data
          that reflect two divergent ontologies, and thus to encounter the difficulties involved in
          the <soCalled>workarounds</soCalled> for multiple hierarchies more frequently.</p>
      </div>
      <div xml:id="maintainability">
        <head>Maintainability and Provenance Challenges</head>
        <p>In addition to posing challenges for maintaining workflows with good quality control
          while producing data, use of the milestone strategy for multiple hierarchies (ontologies)
          decreases the reusability of the textual data produced. The project relies on an automatic
          process to convert the document-focused encoding into a text-focused one. This process
          consists of <ptr type="software" xml:id="R1" target="#readingtei"/>
          <ref target="https://github.com/umd-mith/sg-readingTEI">a set of XSLT
            transformations</ref> authored by <rs type="soft.agent" ref="#R1">Wendell Piez</rs>, who
          served as a consultant to the S-GA project in 2013. These transformations are structured
          as a pipeline—progressively remodeling the document-focused TEI data to a more familiar
          text-focused TEI.<note>The automated transformation workflow was originally managed using
              <ptr type="software" xml:id="R2" target="#xproc"/><rs type="soft.name" ref="#R2"
              >XProc</rs> to compose the various stylesheets but was converted to an <ptr
              type="software" xml:id="R3" target="#apachecocoon"/><rs type="soft.name" ref="#R3"
              >Apache Cocoon</rs> block for ease of maintenance by project staff at MITH.</note>
          Some of the stages involved in this process include, for example, identifying chapter
          boundaries that span across multiple <gi>surface</gi>s (which for convenience are
          maintained in separate files), and then combining the content of these surfaces into a
          single <tag>div type="chapter"</tag>. While some transformations can be handled
          heuristically, others require a <soCalled>hint</soCalled> for the processor. To support
          this automated conversion, the S-GA team needed to go beyond purpose-built milestone
          elements like <gi>delSpan</gi> and <gi>addSpan</gi> and, in effect, semantically overload
          the general purpose <gi>milestone</gi> element using attributes. The value of an attribute
          on <gi>milestone</gi> indicates which text-focused element is intended to appear in a
          particular location:<note>This solution is loosely analogous to some of the ways custom
            data attributes are intended to be used under the HTML5 Specification: <ptr
              target="http://www.w3.org/html/wg/drafts/html/CR/dom.html#embedding-custom-non-visible-data-with-the-data-*-attributes"
            />.</note>
          <egXML xmlns="http://www.tei-c.org/ns/Examples">
            <zone>
              <!-- previous lines -->
              <line>
                <del rend="strikethrough">also</del>
                <metamark> [</metamark>
                <mod>
                  <del rend="overwritten">w</del>
                  <milestone unit="tei:p" spanTo="#mp1"/>
                  <add place="intralinear">W</add>
                </mod> hen I was about <mod>
                  <del rend="strikethrough">twelve</del>
                  <add place="superlinear">fourteen</add>
                </mod> years </line>
              <line>old we were at our house near</line>
              <!-- more lines -->
              <anchor xml:id="mp1"/>
            </zone>
          </egXML>
        </p>
        <p>This solution is explained in the project’s documentation, and the convention used would
          be (one hopes) evident after cursory examination of the data. Nonetheless, the desire to
          make available two models of the text forced the S-GA team to add markup to the project’s
          canonical document-focused data. This makes the encoding more unique to the S-GA project
          and less easily consumable by future users with different goals.</p>
        <p>To avoid the conceptual and technical challenges involved in automating the
          transformation between text-focused and document-focused representations, the two sets of
          data could each have been created by hand (rather than automatically generated) and
          maintained separately. Indeed, this is the approach followed by the <title level="m"
            >Digitale Faustedition</title> project, where a distinction between what the project
          calls <soCalled>documentary</soCalled> and <soCalled>textual</soCalled> transcription was
          considered necessary not only as a reaction to encoding problems, but also as a practical
          application of theoretical distinctions between documentary record and editorial
          interpretation (<ref type="bibl" target="#brüning13">Brüning, Henzel, and Pravida
            2013</ref>). The <title level="m">Faustedition</title> project team, however, still
          encountered technical challenges when trying to correlate and align these two
          transcriptions automatically. Use of collation and natural language processing tools
          helped with this problem, but eventually more manual intervention was needed.</p>
        <p>The S-GA team felt that maintaining two data sets representing different aspects of the
          textual objects would have led to serious data consistency, provenance, and curation
          problems. As the example of the <title level="m">Faustedition</title> project shows,
          separate representations must be kept in sync with project-specific workflows developed
          for this purpose. In the case of S-GA, documentary transcription is the main focus; the
          greatly increased cost and time involved in also maintaining a textual transcription would
          have reduced the size of the corpus that could be encoded and thus the amount of materials
          from the archive that could be made fully available under the initial phase of the
          project. These exigencies prompted the project’s attempts to automate the generation of
          text-focused TEI data from the core document-focused data that the project editors were
          creating.</p>
      </div>
      <div xml:id="presentation">
        <head>Presentation Challenges</head>
        <p>The display and presentation of document-focused encoding is another technical challenge
          introduced by the new TEI elements. Rendering a diplomatic transcription is more easily
          achievable in a coordinate-based system; the S-GA project, therefore, adopted
          SharedCanvas, a data model developed by Stanford University and a coalition of partners,
          which allows editors (and potentially future users) to construct views out of linked data
          annotations. Such annotations, expressed in the Open Annotation vocabulary, relate images,
          text, and other resources to an abstract <soCalled>canvas</soCalled>. S-GA is developing
          and deploying a viewer for SharedCanvas that uses HTML5 technologies to display
          document-focused TEI elements that are mapped as annotations to a SharedCanvas manifest, a
          Linked Open data graph that ties all the SharedCanvas components together. The encoding
          scheme does not record position coordinates for every zone and line, but the positions of
          main zones to be painted on a canvas are automatically inferred, and base HTML display
          rules govern the rendering of text within these zones.</p>
        <p>SharedCanvas not only provides S-GA with a framework to publish TEI transcriptions, but
          also enables the Archive to move further toward a sustainable participatory
          infrastructure. The SharedCanvas model allows for further layers of annotations to be
          added dynamically to a manifest; the S-GA already makes use of this for appending search
          result highlights to the linked data graph and for displaying these to the user.
          Eventually, the project aims to use the same mechanism to enable user comments and
          annotations. The engagement of students and other scholars will be driven by the
          possibility of creating annotations in the Open Annotation format, so that any
          SharedCanvas viewer will be able to render them. It remains a matter for the future
          development of the project to understand whether annotations can be added dynamically to
          the source TEI—especially those pertaining to transcription and editorial statements—or
          whether these secondary annotations, created after the main encoding of documents is
          complete, should always be managed separately from the source TEI data.</p>
      </div>
      <div xml:id="interchange">
        <head>The Need for Interchange Between Document-Focused and Text-Focused Models</head>
        <p>There is intellectual power and utility in both document-focused and text-focused
          approaches to creating digital texts; the scholarly community has gained by the increased
          expressiveness of maintaining two ontologies within the standard governed by the TEI
          community. There are also intellectual and practical reasons why it is undesirable to
          maintain data reflecting these two models as separate or severable representations. The
          experience of the S-GA editorial team lends support to Peter Robinson’s claim that <quote
            source="#quoteref5">document, text and work exist in a continuum, and
              <supplied>that</supplied> the questions of intention, agency, authority, and meaning
            exert pressure at every level of reading</quote> (<ref xml:id="quoteref5" type="bibl"
            target="#robinson13">2013, 114</ref>). The ability to move along this continuum is an
          affordance that a digital text should support because it is in the alternation between
          these two ontological models that editors enact the construction of their particular form
          of humanistic knowledge. </p>
        <p>The motility inherent in this model of digital text projects creates significant pressure
          to address the problem of <soCalled>interchange</soCalled> between and among textual data
          modeled according to different schemes. Syd Bauman has provided a valuable operational
          definition of interchange in the context of text encoding. Following Bauman’s argument,
            <soCalled>interchangeable</soCalled> data is that for which some human intervention
          (changing data to suit a new system or modifying a system to process new data) is required
          but for which this intervention can be accomplished without direct human communication
          with the data originator—because the data is in some way standard or documented (<ref
            type="bibl" target="#bauman11">Bauman 2011</ref>). Indeed what the S-GA team has pursued
          is a strategy for staying document-focused in terms of data creation while preserving the
          ability to produce and share text-focused encoded data by specifying the appropriate
          semantics within the more widely used text-focused ontology of digital text and developing
          data-transformation pipelines that use those semantics as a guide.</p>
        <p>For Bauman it seems that interchange (<q>blind interchange</q> as he delineates it)
          represents a best compromise between interoperability (full equality of semantics across
          different text models) and the liberty or expressiveness that motivates scholarly text
          encoding in the first place. This form of interchange is made possible by <q>a lot of
            adherence to standards</q> and extensive documentation of deviation from those standards
          (see also <ref type="bibl" target="#flanders09">Flanders 2009</ref>). This argument is
          deployed against skeptics of the value of markup or advocates of other approaches to
          curation of digital textual data. The case of the two ontologies of text now co-existing
          within the TEI Guidelines is somewhat different—both are part of the TEI standard. The
          need for interchange between data modeled according to these different approaches is real
          and urgent for a project such as the Shelley-Godwin Archive, which will increasingly
          depend on the ability to flip back and forth between different representations of the data
          most relevant to different communities seeking to use the Archive as a site for their own
          knowledge-making.</p>
        <p>The debates around if and how TEI is a usable standard for interchanging scholarly
          information about texts are by now very old. The dilemma faced by the S-GA in attempting
          to create specialized document-focused data but also to generate and share text-focused
          data—all of it <soCalled>TEI data</soCalled>—suggests a complication of and a possible
          extension to Bauman’s conclusions about interchange. Bauman’s argument is still couched in
          terms of polarity even as it suggests a <soCalled>common-sense</soCalled> relaxation of
          intensity toward the whole question of TEI’s suitability as a standard, a kind of lowering
          of expectations from interoperability to interchange. Geoffrey C. Bowker and Susan Leigh
          Star suggest that <quote source="#quoteref6">standardization has been one of the common
            solutions</quote> to the problem of <quote source="#quoteref6">how objects can inhabit
            multiple contexts at once, and have both local and shared meaning</quote> but that the
          vocabulary of standardization is insufficient <quote source="#quoteref6">to characterize
            the heterogeneity and the processual nature of information ecologies</quote> (<ref
            xml:id="quoteref6" type="bibl" target="#bowker99">Bowker and Star 1999, 293</ref>). The
          more nuanced conception of the issues and interactions involved in the types of problems
          that Bowker and Star develop could be useful to the TEI community.</p>
        <p>Following earlier scholars in the domain of social studies of science, Bowker and Star
          describe a process of balancing <quote source="#quoteref7">local constraints, received
            standardized applications, and the re-representation of information</quote> (<ref
            xml:id="quoteref7" type="bibl" target="#bowker99">1999, 292</ref>). This could easily be
          describing the process of developing a TEI project. When these arrangements become <quote
            source="#quoteref8">ongoing stable relationship<supplied>s</supplied> between different
            social worlds and <gap/> shared objects are built across community boundaries</quote>,
          Bowker and Star refer to the results as <soCalled>boundary objects</soCalled> (<ref
            xml:id="quoteref8" type="bibl" target="#bowker99">1999, 292</ref>). Thus Bauman’s
          description of <soCalled>interchange</soCalled> around the standard of the TEI above, and
          Star’s assertion that <quote source="#quoteref9">boundary objects are a sort of
            arrangement that allow different groups to work together without consensus</quote> (<ref
            xml:id="quoteref9" type="bibl" target="#star10">Star 2010, 602</ref>), seem well
          aligned. In this discussion, the TEI encoding standard is the boundary object: a <quote
            source="#quoteref10">set of work arrangements that are at once material and processual
            <gap/> resid<supplied>ing</supplied> between social worlds (or communities of practice)
            where <supplied>this object</supplied> is ill structured</quote> (<ref
            xml:id="quoteref10" type="bibl" target="#star10">604</ref>). Star observes that multiple
          groups take advantage of the <soCalled>interpretive flexibility</soCalled> of boundary
          objects and customize them for local purposes. In this sense, the S-GA’s use of the TEI’s
          formal mechanisms to produce a custom schema and the workflow-driven introduction of
          project-specific markup and markup conventions (overloading milestones) discussed earlier
          are hallmarks of work with boundary objects.</p>
        <p>Yet, according to Star, a less-studied dynamic in the use of boundary objects is the way
            <quote source="#quoteref11">groups that are cooperating without consensus tack
            back-and-forth between <supplied>local and shared</supplied> forms of the object</quote>
            (<ref xml:id="quoteref11" type="bibl" target="#star10">605</ref>). This is where the
          experience of S-GA becomes particularly relevant. By seeking to maintain at the level of
          the data model the kind of flexibility that Peter Robinson sought to achieve through
          processing and presentation (<ref type="bibl" target="#robinson09">Robinson 2009</ref>),
          the encoding scheme that S-GA has developed for itself and the automatic conversion
          processes that operate on it enact the tacking-back-and-forth that Star describes. The
          implications for the wider TEI community reside in the linkage Star articulates between
          boundary objects and the development—and, it would seem to follow, maintenance—of
          infrastructures and standards.</p>
        <p>According to Star and her collaborators, infrastructures and standards are a <quote
            source="#quoteref12">scal<supplied>ing</supplied> up</quote> from the back-and-forth use
          of boundary objects (<ref xml:id="quoteref12" type="bibl" target="#star10">2010,
          605</ref>). In this sense, the introduction of a document-focused ontology within the TEI
          alongside the more common text-focused approach is an opportunity as well as a challenge.
          Increased commitment to one or the other ontological model of text increases the
          difficulty that other interpretive communities will face in adapting the digital text to
          their local meanings and practices. The process of developing the S-GA exposed challenges
          related to workflow and quality control, maintainability, and presentation. Yet, the
          concept of boundary objects and their extension into infrastructures and standards
          provides a framework for articulating the value of constructing a digital text object that
          spans current boundaries in editorial theory and practice. Digital texts that span the
          interpretive communities of different schools within textual editing and literary
          scholarship, by applying pressure to notions of interchange, promote circulation within
          the system of the standard that contributes to its greater health.</p>
      </div>
    </body>
    <back>
      <div type="bibliography">
        <listBibl>
          <bibl xml:id="bauman11"><author>Bauman, Syd</author>. <date>2011</date>. <title level="a"
              >Interchange vs. Interoperability</title> In <title level="m">Balisage: The Markup
              Conference 2011 Proceedings</title>. <pubPlace>Montréal, QC</pubPlace>. doi:<idno
              type="doi">10.4242/BalisageVol7.Bauman01</idno>.</bibl>
          <bibl xml:id="bowker99"><author>Bowker, Geoffrey C.</author>, and <author>Susan Leigh
              Star</author>. <date>1999</date>. <title level="m">Sorting Things Out: Classification
              and Its Consequences</title>. <pubPlace>Cambridge, MA</pubPlace>: <publisher>MIT
              Press</publisher>. <ptr
              target="http://search.ebscohost.com/login.aspx?direct=true&amp;scope=site&amp;db=nlebk&amp;db=nlabk&amp;AN=13186"
            />.</bibl>
          <bibl xml:id="brüning13"><author>Brüning, Gerrit</author>, <author>Katrin Henzel</author>,
            and <author>Dietmar Pravida</author>. <date>2013</date>. <title level="a">Multiple
              Encoding in Genetic Editions: The Case of <title level="m">Faust</title></title>.
              <title level="j">Journal of the Text Encoding Initiative</title>
            <biblScope unit="issue">4</biblScope>. <ptr target="http://jtei.revues.org/697"/>.
              doi:<idno type="doi">10.4000/jtei.697</idno>.</bibl>
          <bibl xml:id="burdick12"><author>Burdick, Anne</author>, <author>Johanna Drucker</author>,
              <author>Peter Lunenfeld</author>, <author>Todd Presner</author>, and <author>Jeffrey
              Schnapp</author>. <date>2012</date>. <title level="a">The Social Life of the Digital
              Humanities</title>. In <title level="m">Digital_Humanities</title>, <biblScope
              unit="page">73–98</biblScope>. <pubPlace>Cambridge, MA</pubPlace>: <publisher>MIT
              Press</publisher>.</bibl>
          <bibl xml:id="deegan02"><author>Deegan, Marilyn</author>, and <author>Simon
              Tanner</author>. <date>2002</date>. <title level="m">Digital Futures: Strategies for
              the Information Age</title>. <pubPlace>New York</pubPlace>: <publisher>Neal-Schuman
              Publishers</publisher>.</bibl>
          <bibl xml:id="flanders09"><author>Flanders, Julia</author>. <date>2009</date>. <title
              level="u">Dissent and Collaboration</title>. Paper presented at Digital Humanities
            2009, College Park, MD, June 22–25.</bibl>
          <bibl xml:id="moretti13"><author>Moretti, Franco</author>. <date>2013</date>. <title
              level="a"><soCalled>Operationalizing</soCalled>: Or, the Function of Measurement in
              Literary Theory</title>. <title level="j">New Left Review</title>
            <biblScope unit="issue">84</biblScope>: <biblScope unit="page"
            >103–19</biblScope>.</bibl>
          <bibl xml:id="nypl10"><orgName>New York Public Library</orgName>. <date>2010</date>.
              <title level="u">Application to the National Endowment for the Humanities (NEH)
              Humanities Collections and Reference Resources: Shelley-Godwin Archive</title>. <ptr
              target="https://securegrants.neh.gov/publicquery/main.aspx?f=1&amp;gn=PW-50939-11"
            />.</bibl>
          <bibl xml:id="oreilly05"><author>O’Reilly, Tim</author>. <date>2005</date>. <title
              level="a">What Is Web 2.0: Design Patterns and Business Models for the Next Generation
              of Software</title>. <title level="m">O’Reilly Media</title>. September 5. <ptr
              target="https://web.archive.org/web/20140204114855/http://oreilly.com/web2/archive/what-is-web-20.html"
            />.</bibl>
          <bibl xml:id="palmer04"><author>Palmer, Carole L.</author>
            <date>2004</date>. <title level="a">Thematic Research Collections</title>. In <title
              level="m">A Companion to Digital Humanities</title>, edited by <editor>Susan
              Schreibman</editor>, <editor>Ray Siemens</editor>, and <editor>John Unsworth</editor>,
              <biblScope unit="chapter">chap. 24</biblScope>. <pubPlace>Oxford</pubPlace>:
              <publisher>Blackwell</publisher>. <ptr
              target="http://www.digitalhumanities.org/companion/"/>.</bibl>
          <bibl xml:id="pierazzo11"><author>Pierazzo, Elena</author>. <date>2011</date>. <title
              level="a">A Rationale of Digital Documentary Editions</title>. <title level="j"
              >Literary and Linguistic Computing</title>
            <biblScope unit="volume">26</biblScope> (<biblScope unit="issue">3</biblScope>):
              <biblScope unit="page">463–77</biblScope>. doi:<idno type="doi"
              >10.1093/llc/fqr033</idno>.</bibl>
          <bibl xml:id="piez13"><author>Piez, Wendell</author>. <date>2015</date>. <title level="a"
              >TEI in LMNL: Implications for Modeling</title>. <title level="j">Journal of the Text
              Encoding Initiative</title>
            <biblScope unit="issue">8</biblScope>. <ptr target="https://jtei.revues.org/1337"/>.
              doi:<idno type="doi">10.4000/jtei.1337</idno>.</bibl>
          <bibl xml:id="price09"><author>Price, Kenneth M.</author>
            <date>2009</date>. <title level="a">Edition, Project, Database, Archive, Thematic
              Research Collection: What’s in a Name?</title>
            <title level="j">Digital Humanities Quarterly</title>
            <biblScope unit="volume">3</biblScope> (<biblScope unit="issue">3</biblScope>). <ptr
              target="http://www.digitalhumanities.org/dhq/vol/3/3/000053/000053.html"/>.</bibl>
          <bibl xml:id="punzalan13"><author>Punzalan, Ricardo L.</author>
            <date>2013</date>. <title level="u">Virtual Reunification: Bits and Pieces Gathered
              Together to Represent the Whole</title>. PhD diss., University of Michigan. <ptr
              target="http://hdl.handle.net/2027.42/97878"/>.</bibl>
          <bibl xml:id="rehbein13"><author>Rehbein, Malte</author>, and <author>Hans Walter
              Gabler</author>. <date>2013</date>. <title level="a">On Reading Environments for
              Genetic Editions</title>. <title level="j">Scholarly and Research
              Communication</title>
            <biblScope unit="volume">4</biblScope> (<biblScope unit="issue">3</biblScope>). <ptr
              target="http://src-online.ca/index.php/src/article/view/123"/>.</bibl>
          <bibl xml:id="renear96"><author>Renear, Allen H.</author>, <author>Elli Mylonas</author>,
            and <author>David Durand</author>. <date>1996</date>. <title level="a">Refining Our
              Notion of What Text Really Is: The Problem of Overlapping Hierarchies</title>. Final
            version, January 6. In <title level="m">Research in Humanities Computing: Selected
              Papers from the ALLC/ACH Conference.</title>
            <pubPlace>Oxford</pubPlace>; <pubPlace>New York</pubPlace>: <publisher>Clarendon
              Press</publisher>; <publisher>Oxford University Press</publisher>. <ptr
              target="http://hdl.handle.net/2142/9407"/>.</bibl>
          <bibl xml:id="robinson09"><author>Robinson, Peter</author>. <date>2009</date>. <title
              level="a">What Text Really Is Not, and Why Editors Have to Learn to Swim</title>.
              <title level="j">Literary and Linguistic Computing</title>
            <biblScope unit="volume">24</biblScope> (<biblScope unit="issue">1</biblScope>):
              <biblScope unit="page">41–52</biblScope>. doi:<idno type="doi"
              >10.1093/llc/fqn030</idno>.</bibl>
          <bibl xml:id="robinson13"><author>Robinson, Peter</author>. <date>2013</date>. <title
              level="a">Towards a Theory of Digital Editions</title>. <title level="j"
              >Variants</title>
            <biblScope unit="issue">10</biblScope>: <biblScope unit="page"
            >105–27</biblScope>.</bibl>
          <bibl xml:id="roland03"><author>Roland, Perry</author>. <date>2003</date>. <title
              level="a">Design Patterns in XML Music Representation</title>. In <title level="m"
              >ISMIR Conference Proceedings 2003</title>. <ptr
              target="http://jhir.library.jhu.edu/handle/1774.2/50"/>.</bibl>
          <bibl xml:id="star10"><author>Star, Susan Leigh</author>. <date>2010</date>. <title
              level="a">This Is Not a Boundary Object: Reflections on the Origin of a
              Concept</title>. <title level="j">Science, Technology &amp; Human Values</title>
            <biblScope unit="volume">35</biblScope> (<biblScope unit="issue">5</biblScope>):
              <biblScope unit="page">601–17</biblScope>. doi:<idno type="doi"
              >10.1177/0162243910377624</idno>.</bibl>
          <bibl xml:id="tei11"><orgName>TEI Consortium</orgName>. <date>2011</date>. <title
              level="m">TEI P5: Guidelines for Electronic Text Encoding and Interchange</title>.
              <edition>Version 2.0.1</edition>. Last updated December 22. <pubPlace>N.p.</pubPlace>:
              <publisher>TEI Consortium</publisher>. <ptr
              target="http://www.tei-c.org/Vault/P5/2.0.1/doc/tei-p5-doc/en/html/"/>.</bibl>
        </listBibl>
      </div>
    </back>
  </text>
</TEI>
