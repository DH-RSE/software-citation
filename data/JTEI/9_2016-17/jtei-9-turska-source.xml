<?xml version="1.0" encoding="UTF-8"?> <?xml-model href="http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_jtei.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?> <?xml-model href="http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_jtei.rng" type="application/xml" <?xml-model href="https://github.com/DH-RSE/software-citation/raw/main/schema/tei_software_annotation.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" rend="jTEI">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title type="main">Challenging the Myth of Presentation in Digital Editions</title>
        <author>
          <name>
            <forename>Magdalena</forename>
            <surname>Turska</surname>
          </name>
          <affiliation>Magdalena Turska is a <roleName>software developer</roleName> at
                <orgName><ref target="http://www.existsolutions.com/">eXist
              Solutions</ref></orgName> and an elected member of the <ref
              target="http://www.tei-c.org/Activities/Council/">TEI Consortium’s Technical
              Council</ref>. She has recently completed her <ref target="http://dixit.uni-koeln.de/"
              >DiXiT</ref> Marie Curie experienced researcher fellowship at <ref
              target="http://www.it.ox.ac.uk/">IT Services</ref>, University of Oxford where she was
            a member of the TEI Simple project and one of the authors of TEI Processing Model. She
            was a co-editor of the <ref target="http://dantiscus.al.uw.edu.pl/">Corpus Ioannes
              Dantiscus’ Texts and Correspondence</ref>. She teaches advanced TEI encoding, XSLT and
            XQuery and often helps projects with data modeling and application design.</affiliation>
          <email>tuurma@gmail.com</email>
        </author>
        <author>
          <name>
            <forename>James</forename>
            <surname>Cummings</surname>
          </name>
          <affiliation>James Cummings is the <roleName>Senior Academic Research Technology
              Specialist</roleName> for the <ref target="http://blogs.it.ox.ac.uk/acit-rs-team/"
              >Academic IT Research Support Team</ref> at <ref target="http://www.it.ox.ac.uk/">IT
              Services</ref>, <orgName>University of Oxford</orgName>. He is the founding director
            of the annual <ref target="http://digital.humanities.ox.ac.uk/dhoxss/">Digital
              Humanities at Oxford Summer School</ref> and at time of writing has been an elected
            member of the <ref target="http://www.tei-c.org/Activities/Council/">TEI Consortium’s
              Technical Council</ref> since 2005. He holds a <ref
              target="http://james.blushingbunny.net/phd.html">PhD in Medieval Studies</ref> from
            the University of Leeds and was director of <ref
              target="http://www.digitalmedievalist.org/">Digital Medievalist</ref> from 2009 to
            2012. He teaches advanced TEI encoding and customization and often helps projects with
            their schema design and other TEI consultation.</affiliation>
          <email>james.cummings@it.ox.ac.uk</email>
        </author>
        <author>
          <name>
            <forename>Sebastian</forename>
            <surname>Rahtz</surname>
          </name>
          <affiliation>Sebastian Rahtz had been both the <roleName>Director of Academic
              IT</roleName> (Research) and <roleName>Chief Data Architect</roleName> for <ref
              target="http://www.it.ox.ac.uk/">IT Services</ref> at the <orgName>University of
              Oxford</orgName>. He was a member of the <ref target="http://www.tei-c.org/Board/">TEI
              Consortium’s Board of Directors</ref> from 2000 to 2009, and was a member of the <ref
              target="http://www.tei-c.org/Activities/Council/">TEI Consortium’s Technical
              Council</ref> for well over a decade. He was lead architect for the TEI ODD
            customization system in TEI P5, and wrote much of the software and infrastructure which
            underpins the TEI’s work. He was one of the principal investigators of the TEI Simple
            project responsible for its overall design and execution.</affiliation>
          <email/>
        </author>
      </titleStmt>
      <publicationStmt>
        <publisher>TEI Consortium</publisher>
        <date>24/09/2016</date>
        <availability>
          <licence target="https://creativecommons.org/licenses/by/4.0/">
            <p>For this publication a Creative Commons Attribution 4.0 International license has
              been granted by the author(s) who retain full copyright.</p>
          </licence>
        </availability>
      </publicationStmt>
      <seriesStmt>
        <title level="j">Journal of the Text Encoding Initiative</title>
        <editor role="guest">Martin Müller</editor>
        <editor role="chief">John Walsh</editor>
        <editor role="managing">Anne Baillot</editor>
        <editor role="technical">Ron Van den Branden</editor>
        <biblScope unit="issue" n="9">Selected Papers from the 2014 TEI Conference; TEI and
          Materiality</biblScope>
      </seriesStmt>
      <sourceDesc>
        <p>No source, born digital.</p>
      </sourceDesc>
    </fileDesc>
    <encodingDesc>
      <projectDesc>
        <p>Revues.org -centre for open electronic publishing- is the platform for journals in the
          humanities and social sciences, open to quality periodicals looking to publish full-text
          articles online.</p>
      </projectDesc>
    </encodingDesc>
    <profileDesc>
      <langUsage>
        <language ident="en">en</language>
      </langUsage>
      <textClass>
        <keywords xml:lang="en">
          <term>TEI</term>
          <term>digital edition</term>
          <term>publication framework</term>
          <term>processing</term>
          <term>TEI Simple</term>
        </keywords>
      </textClass>
    </profileDesc>
    <revisionDesc>
      <change/>
    </revisionDesc>
  </teiHeader>
  <text>
    <front>
      <div type="abstract" xml:id="abstract">
        <p>Are the data of an edition means to a particular and privileged presentation, or is the
          presentation a side effect? Because of the changing nature of computer systems, with
          constant progression in hardware and software, the encoded texts are the most important
          long-term outcome of the project—the representation of the knowledge— and presentation
          within a particular application is destined to become obsolete relatively quickly.</p>
        <p>However, it is most often the presentation output, rather than the source data, which is
          published and shared. We believe this is largely because there is currently no way of
          expressing, in the source encoding, aspects of presentation which are seen by editors as a
          crucial part of their work. Given a framework for encoding processing expectations for a
          variety of output formats, editors would be much more inclined to share the encoded files
          as their prime output, and intentions for presentation would be much more likely to
          survive repeated technology transitions as processing tools develop and change.</p>
        <p>We believe the collision between the individuality of research and the quest for common
          tools that aid in the creation of digital editions will be solved not by creating another
          piece of specialized publishing software but rather by creating a general framework for
          processing TEI documents and similar, modular solutions for other tasks in the publishing
          workflow. Such an abstraction layer admittedly still requires some fluency in computer
          technologies, but far less than for setting up a publication system from scratch in a
          general-purpose programming language.</p>
      </div>
    </front>
    <body>
      <p>The number of publicly accessible digital editions is constantly growing, but only a
        relatively small percentage of them make their encoded source files openly available (<ref
          type="bibl" target="#franzini16">Franzini 2016</ref>). Without the sources we cannot hope
        for the much-anticipated and commonly advertised re-use of all this painstakingly collected
        and prepared content in innovative research, visualization, and popularization.</p>
      <div xml:id="look">
        <head><q>What is it Going to Look Like?</q></head>
        <p>Many (or indeed most) digital editions are created by people whose scholarly background
          is in textual editing. Therefore, the encoding phase is perceived only as an unavoidable
          step towards the real goal: the published edition, be it printed or presented
          otherwise.</p>
        <p>For large digital scholarly editions, the bulk of the work is in researching and creating
          the underlying data, so editors sometimes think that after the encoding is complete, the
          rest should be trivial. At the same time, they brace themselves for the long struggle to
          get minute details of presentation just right. The question one hears most often during
          the encoding stage is: <q>What is it going to look like?</q> And somehow the answer <q>Any
            way you like</q> just doesn’t seem to be understood or satisfy people. Another typical
          question is <q>How do I encode this to make it look like <emph>this or that</emph>?</q>.
          The latter should always ring the alarm and lead to serious discussion of editorial and
          encoding principles bearing in mind that honesty is one of the most important qualities of
          an editor.</p>
      </div>
      <div xml:id="outcome">
        <head>Data is the Important Long-term Outcome</head>
        <p>We would like to suggest that the encoding policy design (consisting of a schema and a
          set of local guidelines) and the later application of said policy to annotate a text are
          the most important acts that make all further research and long-term preservation of
          editors’ wealth of knowledge (not to mention publication) possible. Therefore in digital
          editions the encoded texts themselves are the most important long-term outcome of the
          project, while their initial presentation within a particular application should be
          considered only a single perspective on the data. Any given view will be far from unique
          or canonical, as different usage scenarios call for different presentations—ranging from
            <soCalled>reading text</soCalled> to <soCalled>interactive version</soCalled> with popup
          content, to chart, graph, or map representations and beyond. Furthermore, all initial
          presentations are also ephemeral, bound to be either modified over time as technologies
          and forms of digital publishing change, or languish in obsolescence on a forgotten
          server.</p>
      </div>
      <div xml:id="publication">
        <head>Editors will only Switch Focus to Quality of Encoding if Publication Becomes as
          Straightforward as Using a Text Processor</head>
        <p>In practice the perception of value is very different. For the majority of cases custom
          processing of encoded documents is outside the reach of a typical editor and inevitably
          involves asking for technical help—which requires money and other resources, and comes
          with inevitable delays and communication problems. And presentation is important as that
          is what other scholars, funding bodies, students, and the general public will see and
          respond to. If editors were able to change the presentation of deeply encoded materials
          with a degree of self-assurance resembling their skills with text processors, they could
          accept the point of view that good encoding is what ultimately counts the most. Then they
          might be more eager to share the encoded files, rather than just the output presentation,
          as the goal of their work.</p>
        <p>Does it mean we just need better tools? A legion of editors dream about <q>one tool that
            does it all</q>, preferably with a nice graphic interface that hides the ugliness of raw
          XML and makes the frustration of dealing with formal programming languages go away.</p>
        <p>The present situation is that there is some progress, and numerous digital humanities
          centers build custom workflows and in-house publishing systems, but often the use of these
          is limited to the host institution. Even making the infrastructure publicly available does
          not result in greater popularity and wider adaptation of the tools, as the case of the
          Kiln (formerly known as xMod) package developed at King’s College London and used
          practically exclusively there illustrates.<note><bibl><author>Jose Miguel Vieira</author>,
              and <author>Jamie Norrish</author>, <title level="u">Kiln</title>, accessed February
              11, 2016, <ptr target="https://github.com/kcl-ddh/kiln"/>.</bibl></note>
        </p>
        <p>Meanwhile, as Tara Andrews points out: <cit>
            <quote source="#quoteref1">Consensus is indeed lacking on what exactly a digital
              critical edition should be. As long as there is no agreement on the end result of
              digital philology, there can be none on its methods; as long as there is no consensus
              on method, there will not be widely applicable computational tools available to help
              produce digital critical texts.</quote>
            <ref type="bibl" xml:id="quoteref1" target="#andrews13">2013, 62</ref>
          </cit></p>
        <p>It is highly probable that such a consensus is, for various reasons, not achievable and
          that therefore no simple and universal editorial environment will materialize any time
          soon. This is an inherent consequence of the individuality of research and the diversity
          of the source material that is chosen as subject matter for digital editions and virtual
          archives. Thus, no matter how good the infrastructure and adoption of standard
          vocabularies may be, it will never become the ultimate solution, as no tool can cater for
          all the unknown features of innovative research projects.</p>
        <p>It seems quite telling that software development that has the biggest influence on
          digital humanities often takes place elsewhere and evolves with more general applications
          in mind: XML databases, search and indexing engines, XSLT processors, and visualization
          libraries; even the XML editors we use are never specifically designed to serve only the
          purposes of digital editions. This is not a bad thing in itself, but the natural
          consequence is that we need a customization layer on top of such technologies, as TEI
          framework does for oXygen editor, for example, to aid our particular goals.</p>
        <p>But before we start creating such a customization, perhaps we should take another look at
          the general software development scene and draw lessons from there. As our lives become
          more and more tied to electronic devices and we grow fond of and dependent on dozens of
          applications we use every day, we often forget that they were most probably built within
          some application framework. The framework-based approach to development helps programmers
          to devote their time to the specifics of their project rather than dealing with the
          typical low-level tasks necessary for building a working application, thereby reducing
          overall development time. Two popular definitions illustrate important aspects of what a
          framework is:</p>
        <cit>
          <quote source="#quoteref2">A <hi rend="italic">software framework</hi> is a concrete or
            conceptual platform where common code with generic functionality can be selectively
            specialized or overridden by developers or users.</quote>
          <ref type="bibl" xml:id="quoteref2" target="#sftechopedia">Techopedia: Software
            Framework</ref>
        </cit>
        <cit>
          <quote source="#quoteref3">In computer programming, a <term>software framework</term> is
            an abstraction in which software providing generic functionality can be selectively
            changed by additional user-written code, thus providing application-specific software. A
            software framework is a universal, reusable software environment that provides
            particular functionality as part of a larger software platform to facilitate development
            of software applications, products and solutions.</quote>
          <ref type="bibl" xml:id="quoteref3" target="#sfwikipedia">Wikipedia: Software
            Framework</ref>
        </cit>
        <p>The key concepts here are <term>abstraction</term> and the notion of <term>platform
            offering generic functionality with room for customization</term>. Such an abstraction
          layer still requires from the editor some programming and design skills, as well as good
          understanding of the input data. Nevertheless, the advantages include common conventions
          and default behaviour that does not need to be explicitly stated and requires extending
          only when particular projects have different needs. This significantly reduces development
          time and effort, while efficient encapsulation of underlying libraries and technologies
          reduces the developer’s learning curve and as a result leaves a much leaner and more
          standardized codebase to maintain.</p>
        <p>Is there a place for a similar approach in digital editions? There seems to be no reason
          why there should not be.</p>
        <cit>
          <quote source="#quoteref4">Of course, documents worth encoding in TEI are very different
            from customer letters. But not that different, and eight out of ten probably will
            benefit from staying within the confines of a well thought-out standard schema and its
            surrounding processing rules. And even the two that don’t may benefit from staying
            within that standard schema as far as possible.</quote>
          <ref target="#mueller13" xml:id="quoteref4" type="bibl">Mueller 2013</ref>
        </cit>
        <p>Here Mueller hints at the idea of having a standard, re-usable processing system. TEI
          seems to be particularly successful as a common vocabulary, perhaps because it does not
          assume any ideological position about methodologies but proposes a default schema and
          guidelines, while always allowing customization and extension whenever projects need
          something that TEI does not deliver. Yet precisely because of that, the processing and
          publishing of TEI-encoded files is mostly left to the editor, who is typically unprepared
          to handle the technical aspects involved. It is usually a tough compromise between the
          individuality of research and the reality of the world in which computer programs do not
          write themselves. Could this problem be solved, perhaps, not by creating a particular
          piece of specialized publishing software, but rather by creating a general framework for
          processing TEI documents?</p>
        <p>The most recent attempt at turning the TEI <term>vocabulary</term> into a TEI
            <term>framework</term> with a defined processing model has been undertaken by the TEI
            Simple<note>TEI Simple, GitHub, <ptr target="http://teic.github.io/TEI-Simple/"
            />.</note> project. This is not the place to describe the rationale for the development
          of the TEI Processing Model in detail here, as the project participants are working on
          another article devoted solely to that subject based on the paper presented at the TEI
          Conference 2015 in Lyon. Suffice it to say that it creates an abstract layer for
          processing TEI documents which can be defined with the TEI vocabulary itself, and comes
          with built-in processing defaults for all TEI Simple elements. Even though the scope of
          TEI Simple is only a subset of the TEI vocabulary suitable for representing early-modern
          and modern printed material, the ideas behind the TEI Processing Model documentation lend
          themselves very well to the purposes of processing any TEI or even any XML document, thus
          making TEI Simple something very different from the earlier TEI Lite project. The
          Processing Model framework developed as part of the TEI Simple project hides the
          complexity of transforming XML documents into other formats behind higher-level interfaces
          through which editors can express their decisions about processing in the familiar
          language of TEI XML without having any knowledge of the specific target media or
          processing implementation. It admittedly still requires very basic understanding of
          technologies like XPath and CSS, but the bar is set much lower when it comes to tweaking
          default processing rules, as compared with setting up a transformation system from scratch
          in XSLT or XQuery.</p>
        <p>The TEI Processing Model of course is not the complete solution, for at least two
          reasons. First, at the current stage it is still a proposal, without the user base that
          can ultimately confirm its viability, even though results from early adopters like <title
            level="m">SARIT</title> or <title level="m">Buddhist Stonesutras</title> or experiments
          with <title level="m">EEBO-TCP</title><note>Early English Books Online <ptr
              type="software" xml:id="eXist-db" target="#eXist-db"/><rs type="soft.name"
              ref="#eXist-db">eXist-db</rs> app, accessed February 11, 2016, <ptr
              target="http://showcases.exist-db.org/exist/apps/eebo/works/"/>.</note> are more than
          promising (see, for example, <ref type="bibl" target="#wicentowski15">Wicentowski and
            Meier 2015</ref>). Second, and more important, the Processing Model covers only the
          document transformation aspects of an edition; building a working application on top of it
          still remains a significant challenge for the editorial teams, though general-purpose
          application frameworks, like html templating for XQuery applications on top of eXistdb,
          are already there to help with that process. Nevertheless, we believe that the Processing
          Model is a crucial step in the right direction, addressing the greatest challenge in the
          publication process, and that it stands a good chance of gaining more traction and
          becoming part of the infrastructure and recommendations maintained by the TEI Consortium.
          It will be practical to incorporate the Processing Model into widely used application
          frameworks, resulting in a promising technology stack that truly empowers editors, as the
          U.S. Department of State’s Office of the Historian’s recent adoption<note>U.S. Department
            of State, Office of the Historian, accessed February 11, 2016, <ptr
              target="https://history.state.gov/"/>.</note> of a Processing Model library for
          eXistdb has demonstrated very clearly (<ref type="bibl" target="#wicentowski15"
            >Wicentowski and Meier 2015</ref>). There is no reason why this exercise could not be
          successfully repeated for other XML database systems such as BaseX. Thriving
          infrastructure projects like TAPAS<note>TAPAS Project, accessed February 11, 2016, <ptr
              target="http://www.tapasproject.org/"/>.</note> and broad research networks like
            DiXiT<note>Digital Scholarly Editions Initial Training Network (DiXiT), accessed
            February 11, 2016, <ptr target="http://dixit.uni-koeln.de/"/>.</note> would be natural
          targets for early adoption not only of TEI Simple, but also of the architecture and design
          principles it builds upon. As a result we could arrive at a flexible layered model of
          interlinked software packages to create a robust workflow for the creation, publication,
          and reuse of scholarly resources.</p>
      </div>
    </body>
    <back>
      <div type="bibliography">
        <listBibl>
          <bibl xml:id="andrews13"><author>Andrews, Tara L.</author>
            <date>2013</date>. <title level="a">The Third Way: Philology and Critical Edition in the
              Digital Age.</title>
            <title level="j">Variants</title>
            <biblScope unit="issue">10</biblScope>: <biblScope unit="page">61–76</biblScope>. <ptr
              target="https://lirias.kuleuven.be/bitstream/123456789/352304/2/variants_postprint.pdf"
            />.</bibl>
          <bibl xml:id="franzini16"><author>Franzini, Greta</author>. <date>2016</date>
            <title level="u">A Catalogue of Digital Editions</title>. Web. <ptr
              target="https://github.com/gfranzini/digEds_cat"/>.</bibl>
          <bibl xml:id="mueller13"><author>Mueller, Martin</author>. <date>2013</date>. <title
              level="a">TEI-Nudge or Libraries and the TEI.</title>
            <title level="m">Blog of the Center for Scholarly Communication &amp; Digital
              Curation</title>, October 1. <ptr target="http://sites.northwestern.edu/cscdc/?p=872"
            />.</bibl>
          <bibl xml:id="sftechopedia"><title level="a">Software Framework</title>, <title level="m"
              >Techopedia</title>, accessed January 16, 2016, <ptr
              target="http://www.techopedia.com/definition/14384/software-framework"/>.</bibl>
          <bibl xml:id="sfwikipedia"><title level="a">Software Framework</title>, <title level="m"
              >Wikipedia</title>, accessed January 16, 2016, <ptr
              target="https://en.wikipedia.org/wiki/Software_framework"/>.</bibl>
          <bibl xml:id="wicentowski15"><author>Wicentowski, Joseph C.</author>, and <author>Wolfgang
              Meier</author>. <date>2015</date>. <title level="u">Publishing TEI Documents with TEI
              Simple: A Case Study at the U.S. Department of State’s Office of the
              Historian.</title> Abstract only. In <title level="m">Proceedings of Balisage: The
              Markup Conference 2015</title>. Balisage Series on Markup Technologies 15. <ptr
              target="http://www.balisage.net/Proceedings/vol15/html/Wicentowski01/BalisageVol15-Wicentowski01.html"
            />. doi:<idno type="doi">10.4242/BalisageVol15.Wicentowski01</idno>.</bibl>
        </listBibl>
      </div>
    </back>
  </text>
</TEI>
