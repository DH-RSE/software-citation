<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0">
  <teiHeader xml:lang="en">
    <fileDesc>
      <titleStmt>
        <title type="main">Evaluating Digital Scholarship: Suggestions and Strategies for the Text
          Encoding Initiative</title>
        <author>
          <name><forename>Sarah L.</forename>
            <surname>Pfannenschmidt</surname></name>
          <affiliation>Sarah L. Pfannenschmidt, M.St., M.A., is a 2013 <roleName>graduate of the
              MSIS program</roleName> at the <orgName>University of Texas at Austin School of
              Information</orgName>, where her focus was on rare books and digital scholarly
            editing. Her ongoing research includes editing medieval Welsh, Irish, and English texts
            and the creation and use of digital editions.</affiliation>
          <email>spfannenschmidt@utexas.edu</email>
        </author>
        <author>
          <name><forename>Tanya E.</forename>
            <surname>Clement</surname></name>
          <affiliation>Tanya Clement, Ph.D, is an <roleName>assistant professor</roleName> at the
              <orgName>University of Texas at Austin School of Information</orgName>. Her primary
            area of research centers on scholarly information infrastructure as it impacts academic
            research, research libraries, and the creation of research tools and resources in the
            digital humanities.</affiliation>
          <email>tclement@ischool.utexas.edu</email>
        </author>
      </titleStmt>
      <publicationStmt>
        <publisher>TEI Consortium</publisher>
        <date>2014</date>
        <idno>Issue 7</idno>
        <availability>
          <p>TEI Consortium 2014 (Creative Commons Attribution-NoDerivs 3.0 Unported License)</p>
        </availability>
      </publicationStmt>
      <sourceDesc>
        <p>No source, born digital.</p>
      </sourceDesc>
    </fileDesc>
    <encodingDesc>
      <projectDesc>
        <p>Revues.org -centre for open electronic publishing- is the platform for journals in the
          humanities and social sciences, open to quality periodicals looking to publish full-text
          articles online.</p>
      </projectDesc>
    </encodingDesc>
    <profileDesc>
      <langUsage>
        <language ident="en">en</language>
      </langUsage>
      <particDesc>
        <listPerson>
          <person xml:id="participantD"/>
          <person xml:id="participantG"/>
          <person xml:id="participantH"/>
          <person xml:id="participantI"/>
          <person xml:id="participantL"/>
          <person xml:id="participantM"/>
          <person xml:id="participantN"/>
          <person xml:id="participantO"/>
          <person xml:id="participantP"/>
          <person xml:id="participantR"/>
          <person xml:id="participantQ"/>
          <person xml:id="participantS"/>
          <person xml:id="participantT"/>
        </listPerson>
      </particDesc>
      <textClass>
        <keywords xml:lang="en">
          <term>evaluation criteria</term>
          <term>digital scholarship</term>
          <term>pilot study</term>
          <term>text encoding</term>
        </keywords>
      </textClass>
    </profileDesc>
  </teiHeader>
  <text>
    <front>
      <div type="abstract" xml:id="abstract">
        <p>As part of a larger pilot study on the evaluation of digital scholarship, we consider
          what role, if any, the TEI Consortium and user community might play in evaluating
          scholarship that utilize the TEI tag set. Our rationale for focusing on the role of the
          TEI Consortium in the discussion of evaluation is twofold. First, the TEI Guidelines
          represents an encoding standard for texts that is supported by a large community actively
          interested in the application and development of these standards. Second, feedback
          concerning evaluation criteria for digital scholarship has not been explicitly gathered
          from the TEI community and may provide additional understanding of the value, process, and
          assessment of text encoding. Determining what to evaluate and how to do so reveals the
          community’s definitions of scholarship in general. The clarification and articulation of
          evaluation criteria, therefore, remains a high priority as digital scholarship continues
          to develop.</p>
      </div>
    </front>
    <body>
      <div xml:id="intro">
        <head>Introduction</head>
        <p>Application of computers to the study of the humanities is receiving more attention, yet
          digital humanities continues to work through a digital incunabula phase (<ref type="bibl"
            target="#crane06">Crane et al. 2006</ref>), particularly in terms of critical
          evaluation. The history of evaluating digital scholarship is long and complex, and
          multiple scholars have contributed important points to the discussion (<ref type="bibl"
            target="#schreibman11">Schreibman, Mandell, and Olsen 2011</ref>; <ref type="bibl"
            target="#cohen12">Cohen and Troyano 2012</ref>).<note>See also <bibl><orgName>NINES
                (Networked Infrastructure for Nineteenth-Century Electronic Scholarship)</orgName>,
                <title level="a">Evaluating Digital Scholarship: NINES/NEH Summer Institutes:
                2011–2012</title>, accessed December 29, 2012, <ptr
                target="http://institutes.nines.org/"/></bibl>.</note> However, one continuing
          concern is the need to define and outline fair evaluation criteria that will both enable
          improvement to digital methods and provide teaching examples of what is possible to the
          wider community (<ref type="bibl" target="#rockwell11">Rockwell 2011</ref>). Many scholars
          have argued that digital materials by nature contribute unique ontological and
          epistemological perspectives (<ref type="bibl" target="#purdy10">Purdy and Walker
            2010</ref>; <ref type="bibl" target="#mcgann01">McGann 2001</ref>) and require different
          evaluation criteria that those used for the original medium (<ref type="bibl"
            target="#mandell10">Mandell 2010</ref>; <ref type="bibl" target="#curran10">Curran
            2010</ref>; <ref type="bibl" target="#presner12">Presner 2012</ref>). Yet too often
          reviewers are still asked to evaluate materials without specific criteria, or to use
          criteria that may not be appropriate to a particular work (<ref type="bibl"
            target="#tanselle06">Tanselle 2006</ref>). Scholarly organizations, including the Modern
          Language Association (MLA) and the American Historical Association, have identified this
          concern and have provided suggestions as to general guidelines for evaluating digital
          scholarship (<ref type="bibl" target="#mla13b">Modern Language Association 2013b</ref>;
            <ref type="bibl" target="#wgephs10">Working Group on Evaluating Public History
            Scholarship, 2010</ref>). While this is a much-needed step, interpretation and
          implementation of evaluation guidelines remains largely at the discretion of individual
          institutions. The choice of which evaluative standards to apply also depends on the
          context of the review (for a journal article or for tenure and promotion, for example) as
          well as the nature of the work (is it a digital scholarly edition or is it a tool?) being
          assessed. Another concern in evaluation is the degree of expertise the reviewers should
          have in both the technology and the subject area that covers the material under
          consideration.</p>
        <p>The eclectic nature of digital scholarship poses challenges to the traditional method of
          finding one or two experts to take on review. The difficulty is partially due to the issue
          of determining what aspect of the scholarship is under review. A successful evaluation
          must be clear on what is being evaluated and why. The evaluation of digital tools in a
          larger project is a case in point. How should evaluators assess digital tools used in the
          production of scholarship: on the basis of a tool’s usability, its theoretical framework,
          its underlying code, all of these things, or something else entirely (<ref type="bibl"
            target="#anderson11">Anderson and McPherson 2011</ref>)? Text encoding is another
          example of this tension, because it reflects the process and methodology of editing, but
          may be more or less prominently featured in digital scholarship. It can therefore be
          unclear what aspect of the text encoding should be assessed (if at all) and who is
          qualified to evaluate it. Additionally, digital scholarship is, by necessity,
          collaborative and interdisciplinary. Determining the weight of the different aspects of a
          digital scholarly project is not an easy feat, since collaboration makes it difficult to
          distinguish the individual contributions within a group (<ref type="bibl"
            target="#burgess11">Burgess and Hamming 2011</ref>) as well as the hierarchy of value
          attributed to team members. Yet no one person can be an expert in every method, field, and
          medium: seemingly, collaborative work requires collaborative review. Who then should
          contribute to a review, and what weight does their criteria carry? What happens when
          digital work challenges theoretical and technical boundaries in innovative ways, and how
          should reviewers note this innovation? Yet again, the concern lies in determining what to
          look for when judging a scholarly project’s success or failure. After all, contributions
          to community may be in its failure to achieve certain goals rather than to meet them (<ref
            type="bibl" target="#flanders09">Flanders 2009</ref>; <ref type="bibl"
            target="#unsworth97">Unsworth 1997</ref>). Evaluators of digital scholarship not only
          require clear guidelines, but must also have criteria flexible enough to allow them to
          assess the <soCalled>success of failure</soCalled>, which challenges traditional
          definitions of scholarly value.</p>
        <p>This paper presents select findings from our study of the TEI community’s perspective on
          evaluating digital scholarship using the TEI Guidelines and the role that the organization
          should take in the review process. The focus for this study developed from the principal
          researcher’s interest in the creation and evaluation of digital scholarly editions as well
          as Tanya Clement’s interest, as the past reviews editor, in how the <title level="j"
            >Journal of the Text Encoding Initiative</title> (hereafter <title level="j"
            >JTEI</title>) might participate in the evaluation of digital scholarship. We used a
          very general definition of <term>scholarship</term> in this study since the burden of
          proving <term>scholarliness</term> is difficult and subjective. In general, we allowed
          participants to define scholarship according to their own understanding of the term. The
          project’s specific focus on the TEI is due to the wide use of the TEI Guidelines. The
          National Endowment for the Humanities has recommended the TEI Guidelines as the accepted
          standard for encoding texts in digital scholarship. The evolution of the Guidelines into
          their fifth permutation also demonstrates longstanding interest in the TEI tag set and its
          applications (<ref type="bibl" target="#tei13b">Text Encoding Initiative 2013b</ref>). The
          TEI Guidelines represent both a best practices standard as well as a theoretical approach
          to the markup of text (<ref type="bibl" target="#cummings07">Cummings 2007</ref>; <ref
            type="bibl" target="#renear04">Renear 2004</ref>; <ref type="bibl" target="#msmq94"
            >Sperberg-McQueen, 1994</ref>), and thus make it particularly interesting to consider as
          both a method and a philosophy of encoding. The breadth and depth of the TEI community
          also attracted our attention. The TEI Consortium (hereafter TEI-C) is international, and
          TEI members come from various humanities disciplines with different experience levels in
          the application of the TEI tag set. Formal membership in the TEI organization requires
          financial support and gives voting benefits. Membership in the organization, however, is
          not required to use the TEI tag set, to join a special interest group, or to become an
          expert user in its application. Because the organization has a strong emphasis on
          promoting the tag set and teaching others to use it, there are many more users of the TEI
          than are formally recognized as members.</p>
      </div>
      <div xml:id="methods">
        <head>Methods</head>
        <p>The study’s target population consisted of people with experience in the creation and
          production of digital scholarship that incorporated TEI encoding. Twenty people were
          interviewed for the study. Nine of these interviews were conducted in person; the
          remaining interviews were conducted remotely. We were particularly interested in speaking
          with TEI users and did not require a specific competence level with the TEI Guidelines to
          participate. Participants were not required to be members of the Consortium and came from
          a variety of academic institutions. However, 50% of those interviewed have at some point
          held an official position in the TEI Consortium. Interview participants were recruited
          from the 2012 TEI Conference attendance list; from the email lists of the Humanist
          Discussion Group, the Digital Medievalist, and the TEI; and by personal invitation from
          the principal researcher’s faculty advisor, Tanya Clement. Participants who expressed
          interest in being interviewed but were unable to do so in person were contacted to arrange
          for remote interviews via Skype.</p>
        <p>Ten of the twenty participants were in tenure-track positions at research and teaching
          institutions across North America and Europe. Of these participants, at least five were
          tenured professors, and at the time of the interview a sixth was undergoing tenure review.
          The remaining ten participants held positions as independent scholars, librarians, and
          designated digital humanities staff. Interestingly, several of these participants
          described their work in terms that has been associated with the
            <soCalled>alt-ac</soCalled> label, though none of them used this term to describe
          themselves (<ref type="bibl" target="#nowviskie10">Nowviskie 2010</ref>). All of the
          participants had experience in the creation of at least one scholarly digital project,
          especially editions of source texts. Most of the participants use or have used the TEI
          Guidelines and have positive opinions about its use as a standard for text encoding. Only
          5% of the participants openly indicated that they did not view the TEI Guidelines as a
          useful community standard for text encoding.</p>
        <p>Participants were asked to share their views on a series of topics centring on the
          evaluation of digital scholarship. Interviewees were allowed to opt out of any questions
          and also to determine the length of the interview. Individual interviews lasted from 10 to
          75 minutes, and were conducted between November 9, 2012, and March 8, 2013. The principal
          researcher requested participants’ permission to record the interview session in order to
          facilitate accuracy in the data and to maintain a conversational style. A document of
          consent was provided in person or electronically to participants, and consent was given to
          record the interview, with two exceptions. Notes were taken by hand during these two
          interviews. There were 10.5 hours of total recorded interview time. Recorded interviews
          were uploaded in mp3 format to a private computer and transcribed into text files.
          Transcribed files totalled 151 pages and were coded and scrubbed of personal or
          identifying information in order to ensure the anonymity of the participants.
          Additionally, each file received an alphabetical designation as the file name. Data were
          extracted and compiled by topic. Audio files were deleted following a final review of the
          transcripts.</p>
      </div>
      <div xml:id="results">
        <head>Results and Discussion</head>
        <p>We asked participants to consider the role of the TEI as an organization in the context
          of the evaluation of digital scholarship. In particular, we sought to discover whether
          participants felt that the organization could provide any contributions to the creation of
          evaluation criteria. The responses were strongly divided and revolved around two points:
            <list rend="ordered inline">
            <item>what participants understood to be the organization’s primary role and function,
              and</item>
            <item>the perceived purposes and goals of the evaluation process.</item>
          </list> The biggest problem participants identified with evaluating text encoding was the
          same one facing the general digital scholarly community as a whole: namely, trying to
          define exactly <emph>what</emph> an evaluation would assess and <emph>why</emph>.</p>
        <div xml:id="factors-complicating">
          <head>Factors Complicating the TEI-C’s Involvement in an Evaluative Context</head>
          <p>Some participants were not in favour of the TEI having a role in the evaluation of
            digital scholarship, stating that the TEI’s involvement in assessment would negatively
            affect the organization’s ability to carry out its core mission. In particular, there
            was concern about whether or not evaluation would interfere with the organization’s
            stated docket of activities and current structure. This concern was especially
            pronounced in the areas of funding when participants considered the division of
            resources. One participant felt that the funding for the organization’s current
            activities would make it difficult to implement evaluations: <cit>
              <quote source="#quoteref1">If they wanted to introduce a process of <gap/> assessment
                  <supplied>that</supplied> will mean diversion of funding from other activities
                that they’re doing <gap/> to do it right and to do it fairly. I don’t think it can
                be done on the backs of volunteers within the TEI, or it won’t be fair enough to
                actually do what people are going to expect it to do, which is stand in for tenure
                and promotion cases <gap/> and that means that they’re probably going to have to do
                some form of cost-recovery <gap/> if they’re not going to divert resources and if
                you want to have it done properly.</quote>
              <ref type="bibl" xml:id="quoteref1" target="#participantO">Participant O</ref>
            </cit>
          </p>
          <p>Participant O suggested that funding is a practical consideration for the TEI-C should
            it request or expect this kind of participation from its members and user community. As
            a non-profit organization, the TEI-C would have to divert funds from its primary
            function to <quote source="#quoteref2">collectively develop and maintain a standard for
              the representation of texts in digital form</quote> (<ref xml:id="quoteref2"
              type="bibl" target="#tei13a">Text Encoding Initiative 2013a</ref>). The TEI-C would
            also have to consider whether it could justify the additional costs and time that would
            be required to do evaluations, and whether there is enough interest among TEI users and
            the general digital community to justify these costs. Thus, the TEI-C’s decision to take
            on an evaluative role might require dedicated revenue streams for this purpose that
            would not tax the organization’s current resources.</p>
          <p>Clearly, the concern over resources was fundamentally related to how participants
            understood the TEI-C’s function as an organization. One participant made the following
            comment: <cit>
              <quote source="#quoteref3">What is the TEI, as it were? You know, it’s a
                not-for-profit organization, there is a council, there is a technical board,<note>To
                  be precise, it’s the TEI Technical Council that guides the <quote
                    source="#quoterefn1">technical direction of the TEI Consortium</quote>. The TEI
                  Board supervises the TEI Consortium, <quote source="#quoterefn1">provides
                    strategic direction and fiscal oversight, organizes the TEI’s main activities,
                    and coordinates fundraising and member recruiting</quote>. (<bibl
                    xml:id="quoterefn1"><title level="a">TEI: Organization</title>, <ptr
                      target="http://www.tei-c.org/About/organization.xml"/></bibl>).</note> but
                there are many, many people in the community who are interested in TEI, use TEI
                encoding, but are <emph>they</emph> the TEI. . . ? So it’s kind of saying <q>Well,
                  the MLA should be in charge of something, <supplied>or</supplied> the MLA should
                  participate</q>, but who is the MLA? A body of people who work in New York and a
                lot of members.</quote>
              <ref type="bibl" xml:id="quoteref3" target="#participantN">Participant N</ref>
            </cit>
          </p>
          <p>Like the TEI, the MLA is an organization designed to allow members to <quote
              source="#quoteref4">share their scholarly findings and teaching experiences with
              colleagues and to discuss trends in the academy</quote> (<ref xml:id="quoteref4"
              type="bibl" target="#mla13a">Modern Languages Association 2013a</ref>). Both
            organizations host an annual convention, publish relevant materials, and maintain a
            style guide. The TEI-C’s equivalent of the latter is the TEI tag set for text encoding.
            Like the MLA, the TEI-C makes suggestions for practitioners, but they cannot enforce
            them. Instead, they combine the experience of members and users to provide assistance to
            others. As noted by Participant N, however, the TEI-C and the MLA are not comprised of
            people who are all part of the same scholarly discipline; the MLA covers different
            specialties within the study of language and literature, while the TEI-C welcomes
            scholars from all fields. Instead, these communities would be more appropriately defined
            as a loose association of users bound by a common interest. What the TEI-C is not,
            however, is a judicial body in the practice of text encoding and markup, even within its
            own community.</p>
          <p>Participants recognized that by assigning an evaluative role to any aspect of the
            TEI-C’s activities, they would potentially promote narrowness in the application of the
            TEI tags and, indeed, in the wider practice of text markup. Textual editing is by nature
            both flexible and formative, and two different editorial methodologies may produce work
            that demonstrates equally interesting perspectives. Consequently, it is not always
            possible to determine what is <soCalled>better</soCalled> about one choice over another.
            The TEI Guidelines attempt to accommodate many of the variations that can occur in
            editing texts. Therefore, there is no absolutely correct way to encode a text beyond
            what will validate for a given set of parameters set up in the ODD file or schema and
            rendered by an XSLT transformation or a similar process. <ref type="bibl"
              xml:id="quoteref5" target="#participantD">Participant D</ref> questioned the need to
            evaluate the application of tags at all: <quote source="#quoteref5"><supplied>one
                specific vision of the TEI tags is</supplied> not a generalized tool that somebody
              else could use unless they were doing exactly the same thing. So in that case, there’s
              no real point in assessing unless you’re wanting to assess me <supplied>and</supplied>
              how good I was at that job.</quote> Based on Participant D’s understanding, a specific
            use of the TEI tags may not be generalizable. Evaluation of a given use of the TEI tags
            may focus on the individual editor and not the more important aspect of the review: the
            product itself. Any attempt to evaluate individual preferences shy of an encoded
            document that does not render would be politically and practically difficult. The TEI
            tags are deliberately flexible to allow for a wide range of applications, and some
            participants did not want to limit this range in any way.</p>
          <p>Practitioners who know the TEI standards best may also have preferred ways of using and
            interpreting the tags. These preferences are partially subjective, and at present, no
            single view of the TEI tags is necessarily <soCalled>right</soCalled> in every
            situation. Some participants added that, should the TEI-C become involved in the
            evaluation process, one interpretation of the TEI tag set might be unfairly promoted:
              <quote source="#quoteref6">if you focus the work of evaluation in a single place, you
              run the risk of having people essentially beg the question of what’s valid TEI by just
              <gap/> pleading essentially their own version by their own interpretation</quote>
              [<ref type="bibl" xml:id="quoteref6" target="#participantQ">Participant Q</ref>]. The
            participant highlights the concern that giving one person or select group of people the
            authority to decide what kind of TEI tags are <soCalled>right</soCalled> could privilege
            one interpretation of the TEI standards over another equally valid interpretation. In
            order to avoid unnecessary rigidity, the TEI-C would therefore need to be very clear in
            determining <emph>what</emph> exactly was being evaluated and what weight this carried
            for the assessment of the work as a whole. One participant succinctly noted that such an
            approach was in direct contrast with the original purpose of the organization’s
            initiative, which was <quote source="#quoteref7">to be a community standard, a <q>this
                is the way we all agreed to do this stuff</q> standard <gap/> not a <q>from on high
                thou shalt</q> standard</quote> [<ref type="bibl" xml:id="quoteref7"
              target="#participantG">Participant G</ref>]. These responses emphasize the difficulty
            in evaluating the use of the TEI tag set. Participants were largely unclear about what
            aspects of the text encoding <emph>could</emph> be evaluated. Possible criteria
            mentioned by participants included the understanding of the individual editor of the TEI
            standards, their demonstrated use of those standards, and the application of the TEI
            tags to further a specific editorial theory of the text.</p>
          <p>Participants also connected the concern over internal orthodoxy in the TEI to a larger
            issue of a text encoding bias in evaluation. In particular, some participants felt that
            the TEI-C’s involvement in evaluation would begin to limit what could be considered
            legitimate text-encoding practices. In the words of one participant, if the evaluation
            of text encoding was undertaken by the TEI-C, then it was possible that the organization
            would <quote source="#quoteref8">have a sort of monopoly</quote> on how text encoding
            would be evaluated by the digital scholarly community at large [<ref type="bibl"
              xml:id="quoteref8" target="#participantS">Participant S</ref>]. The TEI tags are not
            the only way to encode text, nor do practitioners claim that using TEI tags is the best
            choice in all cases (<ref type="bibl" target="#lavagnino06">Lavagnino 2006</ref>). Any
            organization may be seen as having a clear stake in judging its own materials. <ref
              type="bibl" xml:id="quoteref9" target="#participantR">Participant R</ref> noted that
            while <quote source="#quoteref9">there are people who are practitioners, familiar with
              various kinds of guidelines <supplied>they</supplied> also aren’t making those
              guidelines at the same time</quote>. The difficulty for participants appears to be in
            trying to determine how the TEI-C could judge itself fairly without potential bias. In
            other words, who watches the evaluators?</p>
          <p>There was also a mention of the concomitant danger of valuing text encoding over other
            facets of the scholarly product. <ref type="bibl" xml:id="quoteref10"
              target="#participantP">Participant P</ref> cautioned that there is typically more
            involved in a digital work than simply text encoding, and evaluation should take this
            into account: <cit>
              <quote source="#quoteref10">Ideally the TEI <supplied>tagset</supplied> is just one
                component of a successful digital project. That there are other things layered on
                top of that, you know, topic modeling, information visualizations, GIS stuff and so
                on, so having the TEI as the home for this is putting too much attention on one
                aspect of a project when you have all these other technologies involved that may be
                just as important as the TEI.</quote>
            </cit>
          </p>
          <p>Digital projects, particularly those that require scholarly digital editing, frequently
            use text encoding and may choose the TEI tags to accomplish this encoding. However, the
            TEI tags are not the only <soCalled>digital</soCalled> aspect of a digital scholarly
            endeavour, and they may not even be the most important or interesting component to
            assess: <cit>
              <quote source="#quoteref11">It’s not 100% clear to me that you can’t do good work that
                isn’t TEI based. And so I would be a little bit nervous that you don’t end up as an
                orthodoxy agency, and especially given that <gap/> the really really interesting
                stuff right now seems to be geospatial and semantic, and <gap/> also
                interoperability, so stuff with JSON and things like that, and I think it might be
                wrong to just choose markup <supplied>as an evaluation metric</supplied>.</quote>
              <ref type="bibl" xml:id="quoteref11" target="#participantQ">Participant Q</ref>
            </cit>
          </p>
          <p>The point here is a relevant one: why focus on text encoding at the expense of other
            factors, especially if the text encoding is not the most interesting or innovative
            aspect of the work? The use of the TEI tags is not inherently indicative of a rigorous
            scholarly methodology. Therefore, some participants argued that the quality of the
            markup should not be considered a reflection of the material’s overall scholarly
            quality.</p>
          <p>Some participants also believed that the TEI-C would not be able to provide evaluations
            that would carry weight in specific academic disciplines. As one participant explained,
              <quote source="#quoteref12">Assessment is never neutral. It usually has some form of
              practice or method or technique, and it has stakeholders. It’s done by somebody, to
              somebody, for somebody</quote> [<ref type="bibl" xml:id="quoteref12"
              target="#participantO">Participant O</ref>]. It would therefore be necessary to
            identify the purpose of an evaluation in order to determine if the TEI-C was the
            appropriate group to participate. For some participants, this was precisely the reason
            why the TEI-C should not be an evaluative body: the organization was not designed as a
            peer-review system, and it does not carry the same academic weight among other
            peer-reviewed scholarship. The perceived limitation in the TEI’s evaluative focus means
            that evaluations by the TEI-C would be of limited use to persons seeking tenure or other
            forms of scholarly advancement in traditional departments.</p>
          <p>Participants reasoned that other groups, specifically NINES and its sister
            organizations, would be more appropriate forums to evaluate digital scholarship. These
            groups are more readily identified as scholarly peer-review bodies because they were
              <emph>designed</emph> to review scholarship. According to its website, NINES
            identifies as a <quote source="#quoteref13">scholarly organization</quote> with three
            primary goals: <list rend="inline ordered">
              <item><quote source="#quoteref13">to serve as a peer-reviewing body for digital
                  work</quote> in a specific time period (1770–1920) and in a specific area (British
                and American),</item>
              <item><quote source="#quoteref13">to support scholars’ priorities and best practices
                  in the creation of digital research materials</quote>, and</item>
              <item><quote source="#quoteref13">to develop software tools</quote> to promote these
                activities.</item>
            </list><note><bibl xml:id="quoteref13"><orgName>NINES (Networked Infrastructure for
                  Nineteenth-Century Electronic Scholarship)</orgName>, <title level="a">What is
                  NINES?</title>, accessed March 13, 2013, <ptr target="http://www.nines.org/about/"
                />.</bibl></note> The key point is that NINES calls itself a scholarly organization
            and is comprised of scholars working in a specific field defined by spatial and temporal
            criteria who use or create digital tools to facilitate their studies. Participants
            believed that a review by NINES was more likely to be accepted by academic committees as
            evidence of scholarly value because the members of the editorial boards, as well as the
            scholars solicited for reviews, are recognized experts in the field that they are
            reviewing. In contrast, <ref type="bibl" xml:id="quoteref14" target="#participantP"
              >Participant P</ref> explained that the TEI-C is not a peer-review system, but rather
            a community interested in a specific topic, that of text encoding: <quote
              source="#quoteref14">There are different functions for different types of bodies
              <gap/> the TEI is really good at maintaining the standard and pushing that out to
              users and so on, and the reviewing aspects are better handled by groups like
              NINES.</quote> Another participant confirmed this perspective: <cit>
              <quote source="#quoteref15">TEI is not, or cannot, I should say,
                  <supplied>provide</supplied> field-specific scholarly review. Because the TEI is
                fantastic <gap/>
                <supplied>but</supplied> if TEI were to give their stamp of approval to my project,
                and if I were to submit it to a committee for promotion, they wouldn’t know what to
                make of it, because they’re not in the field. I mean, it’s in the field of digital
                studies <gap/> but evaluating scholarly relevance or pedagogical relevance is really
                a completely different story. So I would hope that these field-specific or
                era-specific literary humanities oriented review sites would actually solve
                  <supplied>the reviewing</supplied> problem.</quote>
              <ref type="bibl" xml:id="quoteref15" target="#participantS">Participant S</ref>
            </cit>
          </p>
          <p>While many scholars are involved in the TEI community, the TEI-C’s declared goals and
            activities are centered on text encoding, not necessarily on singular areas of
            scholarship. Consequently, some participants in traditional academic jobs saw the
            TEI-C’s participation in scholarly reviewing as only partially beneficial.</p>
          <p>For some participants, this perspective on the TEI-C’s capacity to review digital
            scholarship highlighted the divide between traditional and non-traditional scholars.
              <ref type="bibl" xml:id="quoteref16" target="#participantP">Participant P</ref>
            identified this problem in terms of the discrepancy between the role of the TEI-C and
            the role of peer-review groups like NINES in offering an evaluation of digital
            scholarship: <cit>
              <quote source="#quoteref16"><gap/> There are many people who are excellent, really
                productive members of the TEI community and on the Board and Council who aren’t
                traditional, who aren’t professors. And I don’t like to categorize people in those
                ways, but when it comes to something like tenure and promotion, you’re going to have
                people who will put people into those sorts of categories. I think you want the
                reviewing done by bodies that are made up predominantly of people in tenure or
                tenure-track positions to get over those biases. If you could have three members
                from the TEI council who were doing a review of a project for someone’s tenure, and
                they could be computer programmer, and a librarian, and a IT support person, all
                great scholars and TEI experts, but that might not be convincing to a more
                traditional person on a tenure and promotion committee, who wants those reviewers to
                be more traditional scholars. And that’s the problem, I think, and I think that
                different people in digital humanities are working to legitimize the roles and
                qualifications of these alt-academic positions. But it’s still a problem for people
                going up for tenure and promotion.</quote>
            </cit>
          </p>
          <p>This statement has hit on many of the concerns of the digital community: its
            legitimacy, its relationship to the traditional academy, and the place of
            non–tenure-track scholars. For this study, the most important point identified by
            Participant P is that more value is still inherently attached to a review from a
            peer-review group comprised of traditional academics than one that has been done by
            alternative academics or persons working in fields other than the project-specific one.
            Again, the TEI-C was not designed to be a peer-review body for an academic field.
            Therefore, these participants believed that it would be difficult for the TEI-C to
            perform evaluations without further work being done, as <ref type="bibl"
              xml:id="quoteref17" target="#participantP">Participant P</ref> advocates, to <quote
              source="#quoteref17">legitimize the roles</quote> or otherwise establish that its
            members were able to demonstrate subject knowledge in addition to text-encoding
            expertise.</p>
        </div>
        <div xml:id="factors-favoring">
          <head>Factors Favouring the TEI-C’s Involvement in an Evaluative Context</head>
          <p>Despite these concerns, some participants maintained that there were several important
            reasons to have the TEI-C involved in evaluation. Indeed, some participants who had
            originally expressed objections to the possibility of the TEI community’s involvement
            also noted that the idea warranted further consideration. The main points given in
            favour of evaluations by the TEI-C were as follows: <list rend="inline ordered">
              <item>that the TEI tags could be considered part of the editorial methodology that
                contributes to the scholarship of a project, and are therefore, by necessity,
                evaluable;</item>
              <item>that the organization has a declared responsibility as a <q>resource to
                  scholars</q> to provide assistance if requested in this area; and</item>
              <item>that by making the effort to review such projects, the organization would
                provide an environment for further dialogue on both the use and future directions of
                the tag set, as well as the development of evaluation criteria.</item>
            </list></p>
          <p>Participants who were in favour of having the TEI-C involved in evaluation of digital
            scholarship connected the use of tags with a project’s editorial methodology. Editorial
            decisions about how to encode the text affect the scholarly quality of the project. The
            connection to the overall vision of the project led participants to reason that the text
            encoding should be considered part of the project’s scholarship and evaluated as such: <cit>
              <quote source="#quoteref18"><gap/> the act of encoding itself is an act of
                scholarship. Right? You wind up dealing closely with the text and making editorial
                decisions that not only in and of itself is sort of good for your health, but is
                adding to the world of scholarship, producing new knowledge in a sense. You are
                providing your own analysis, and your analysis, while maybe not described in prose
                the way it would be in a monograph or a journal, becomes implicit in what you do
                <gap/> it itself is a sort of work<gap/><supplied>and</supplied> this is what you
                would want to be evaluating. </quote>
              <ref type="bibl" xml:id="quoteref18" target="#participantM">Participant M</ref>
            </cit>
          </p>
          <p>Participant M noted that there is a correlation between editing, markup, and
            scholarship, or the <quote source="#quoteref19">theory of digital text</quote> (<ref
              type="bibl" xml:id="quoteref19" target="#fiormonte10">Fiormonte, Martiradonna, and
              Schmidt 2010</ref>). The theory and its application to a text, as well as the
            consistency of that application, is reflected in the product. The text-encoding and
            tagging choices are therefore related to the entire editorial methodology of a scholarly
            work: <cit>
              <quote source="#quoteref20">I think that <supplied>where</supplied> tagging and text,
                the marking of a text, fit between editorial practice and writing an essay, or a
                book, comes down to the level of granularity, I think, that you tag. Because in
                tagging, that’s one of the main questions<gap/>
                <supplied>so</supplied> the decisions that you have to do as to how much
                granularity, to deal with the text, is certainly, at least as scholarly as trying to
                figure out what kind of edition to write. And so it’s in that process of deciding
                the edition, in the process of justifying an edition, in the process of figuring out
                the details that will go into the textual apparatus in an edition, which are the
                most scholarly parts of an actual edition text.</quote>
              <ref type="bibl" xml:id="quoteref20" target="#participantS">Participant S</ref>
            </cit>
          </p>
          <p>According to this response, evaluating text encoding depends on the depth of tagging
            (that is, the <quote source="#quoteref20">granularity</quote>) that an editor uses to
            approach the material. When an editor marks up the text in a detailed, methodical way,
            the text encoding becomes both an implicit and explicit part of their theory of the
            text. Participant responses suggest that the theory of the text, at the very least, is
            scholarship. The problem therefore is not whether text encoding can <emph>be</emph>
            scholarship, but rather how the creators of the project make such an argument explicit
            to reviewers.</p>
          <p>Some participants generally felt that if a project utilized TEI tags, the text-encoding
            choices should be considered in any fair and holistic evaluation. One participant
            compared the text encoding of a digital project with the editorial methods of a print
            edition: <cit>
              <quote source="#quoteref21">I think if you are evaluating the scholarly value of the
                digital project whose underlying data is in TEI, you really do need to look at that
                TEI. In the same way as if you were evaluating a letterpress edition, you would
                certainly be looking very carefully at the editorial methods section. You’d be
                looking at the transcription principles <gap/> to see that the conventions were
                applied consistently <gap/> if you weren’t using that as a reviewer <gap/> you’d be
                leaving out half of what makes it a scholarly edition. And I think that’s true of
                anybody who is claiming that they are making use of TEI to code for archival
                purposes. I mean, if it’s very simple content and you’re really just coding
                paragraphs and lines that might not apply. But if you’re doing anything more
                sophisticated to capture things like textual variants and manuscript witnesses, or
                semantic or linguistic features of the text, then you <gap/> should be getting
                credit for the work you’ve done, and also if it hasn’t been done well, then that
                should be part of the evaluation.</quote>
              <ref type="bibl" xml:id="quoteref21" target="#participantL">Participant L</ref>
            </cit>
          </p>
          <p>Like Participant S’s statement about the granularity of encoding, Participant L asserts
            that there is room for evaluation of text encoding when it comes to <quote
              source="#quoteref21">capturing</quote> unique textual information. The comparison with
            traditional editorial print methods highlights the problematic position of editorial
            theory and practice and the value afforded these activities in academia. Critical
            editing has been unfairly treated as an inferior type of scholarship (<ref type="bibl"
              target="#greetham97">Greetham 1997</ref>), and the scholarly legitimacy afforded to
            the activity of editing and producing critical texts depends on the purpose of the
            evaluation. If participants promoted text encoding as scholarship by virtue of its role
            in editorial theory, then they were more likely to say that the text encoding should
            also be evaluated for scholarly credit and that the TEI-C was the appropriate group to
            do this.</p>
          <p>Several participants argued that the TEI-C should be involved in project assessment in
            the capacity of advocate. Those participants who identified the TEI-C as a potential
            evaluative body felt that the organization as a whole could help scholars both improve
            their projects and legitimize their scholarship to the wider community. Not
            surprisingly, support for the place of the TEI-C in legitimizing scholarship was
            predominantly expressed by participants who were less experienced with the TEI tags,
            whose work fell outside large and well-supported areas of scholarship (such as American
            or English literature), who were junior tenure-track scholars, or who were in
            alternative academic posts. In the words of one participant, there needs to be <quote
              source="#quoteref22">a lot more work on the part of the scholar <gap/> to educate
              people about digital humanities scholarship</quote>, especially with regards to the
            expectations and possibilities of digital tools and methods [<ref type="bibl"
              xml:id="quoteref22" target="#participantP">Participant P</ref>]. In other words,
            scholars need assistance to plead their case, and those who need such assistance would
            like the TEI-C to provide it. As <ref type="bibl" xml:id="quoteref23"
              target="#participantO">Participant O</ref> stated, <quote source="#quoteref23"
              >wherever you stand on whether or not there’s scholarship <supplied>in a
                project</supplied>, it is still the case that we have people who are arguing that it
              is, and that therefore the TEI should provide guidelines for
                <supplied>evaluating</supplied> this</quote>. In other words, the TEI-C could help
            to provide standards for evaluating text-encoded materials that others could use to
            perform fair reviews. These reviews would be useful in reaching out not only to the
            non-digital community, many of whom still do not recognize text encoding and other
            digital methods as legitimate scholarship, but also to other evaluative bodies. For
            example, <ref type="bibl" xml:id="quoteref24" target="#participantH">Participant H</ref>
            said that <quote source="#quoteref24">If <supplied>the funding bodies</supplied> knew
              the TEI and the quality of the encoding that is possible in this way <gap/> in order
              to have an idea of the real amount of work <supplied>they would</supplied> better
              understand our achievements.</quote>
            <ref type="bibl" xml:id="quoteref25" target="#participantR">Participant R</ref> agreed
            with this perspective and explained that <quote source="#quoteref25">to make digital
              scholarship evaluable, part of what you need to do is talk about it a lot, explain it
              a lot, and in a sense, publicize it</quote>. These scholars drew a connection between
            the need to legitimize digital scholarship and the advocacy role of the TEI-C.</p>
          <p>The suggested form for the TEI-C’s advocacy was as a formative consultant. Although the
            TEI-C already does a significant amount of outreach, providing formative reviews was
            seen as a resource for those with beginning to intermediate knowledge of the TEI tags.
            Several of the participants who are junior scholars said that the complicated nature of
            the TEI tags and the length of time required to become an expert in using them made it
            prohibitive for them to use the tag set with greater proficiency: <quote
              source="#quoteref26">I feel that for someone like me who can’t practice TEI all the
              time because I have other scholarly demands, I think that that becomes hard
                <supplied>to improve my use of the TEI tags</supplied></quote> [<ref type="bibl"
              xml:id="quoteref26" target="#participantR">Participant R</ref>]. As expressed here, an
            insufficient knowledge of the Guidelines limits the scholar’s ability to use them to
            best reflect their editorial methodology. In turn, they need the formative assessment to
            help them with later evaluations: <quote source="#quoteref27">I think that <gap/> I
              would want someone who was looking at the TEI to understand what the intentions were
              in order to kind of judge the scholarly aspect of it</quote> [<ref type="bibl"
              xml:id="quoteref27" target="#participantR">Participant R</ref>]. Participant R wanted
            a formative assessment to improve their ability to correctly apply the tag set at a more
            sophisticated level, which in turn would make their argument for scholarship more
            legitimate in a later evaluation. As <ref type="bibl" xml:id="quoteref28"
              target="#participantM">Participant M</ref> said, the <quote source="#quoteref28"
              >primary place <supplied>of the TEI-C</supplied> is to serve the needs of scholars who
              are producing digital editions</quote>. Scholars who want to demonstrate that their
            text encoding reflects scholarship require a mechanism by which they can make their
            argument legitimate to evaluators. <ref type="bibl" xml:id="quoteref29"
              target="#participantT">Participant T</ref> explained that the value of the TEI-C stems
            from its ability to <quote source="#quoteref29">expose <gap/>
              <supplied>and</supplied> publicize the process of editing</quote> to others; that is,
            to demonstrate how editorial theory and methodology incorporate the TEI tag set to
            produce scholarship.</p>
        </div>
        <div xml:id="participation">
          <head>Forms of Participation: Potential Avenues for the TEI-C’s Involvement in
            Evaluation</head>
          <p>Regardless of how participants felt about the place of the TEI-C in the review process,
            all participants were asked to consider what form such participation might take. In
            general, the majority of participants felt that the organization should provide a
            reference document as an evaluation resource. As <ref type="bibl" xml:id="quoteref30"
              target="#participantI">Participant I</ref> explained, <quote source="#quoteref30">We
              should be proactive in suggesting guidelines for evaluation because so many tenure
              committees and evaluation committees don’t know where to start.</quote> Users of the
            TEI tag set cover all levels of proficiency; some are experts. In contrast, many
            evaluative bodies do not have knowledge of text encoding (of any form, not just the TEI
            tag set) or know how to evaluate it. As such, the documents would assist reviewers by
            promoting a better understanding of what an assessment of text encoding might look like
            among the more traditional and less technically savvy review bodies. <ref type="bibl"
              xml:id="quoteref31" target="#participantS">Participant S</ref> explained that there is
            a <quote source="#quoteref31">need for actual expert reviewers out there, or at least
              some sort of firewall that you can submit something to and have it get a stamp of
              approval, that not only does meet best practices for a digital edition which is a
              technical evaluation, but it also has some scholarly merit, or at least utility for
              the field</quote>. Another participant expressed a similar opinion, going so far as to
            suggest that there should be additional documentation to assist in the creation of
            evaluation criteria that would facilitate such reviews: <cit>
              <quote source="#quoteref32">I think the TEI would be better off first of all maybe
                commissioning guidelines for assessment. So saying, <q>this is how we would assess
                  it if you were a chair, or someone on a tenure committee, or whatever it is, this
                  is <gap/> what we recommend you do as part of an assessment</q>. Sort of describe
                commission and the creation of a best-practices document. And then share that best
                practices document with the community.</quote>
              <ref type="bibl" xml:id="quoteref32" target="#participantO">Participant O</ref>
            </cit>
          </p>
          <p>Other participants suggested that the TEI-C provide a list of the names of people who
            could assist with early and intermediate assessments. The TEI-C would, in this sense,
            not be taking the place of the peer-review body, but particular members could answer
            questions with respect to the editorial decisions and use of the TEI tags in a given
            situation. As one participant explained, <quote source="#quoteref33">If <gap/> you have
              a project and you want to make sure that your project is set up, the
                TEI<supplied>-C</supplied> is <gap/> a mechanism by which experts are put in touch
              with projects that need advice</quote> [<ref type="bibl" xml:id="quoteref33"
              target="#participantQ">Participant Q</ref>]. Such formative assessment and consulting
            may benefit both the TEI-C and the material under review. Reviewing digital scholarship
            early in the development and planning process as well as in res medias is potentially
            more cost effective. Also, receiving an outside perspective may help scholars to avoid
            common mistakes in their infrastructure and editorial decisions: <cit>
              <quote source="#quoteref34">It should become a best practice to weave into
                  <supplied>the project budget</supplied> some funding to bring someone up to
                consult, to get some sort of outside view, and so that’s a form of assessment that
                the TEI<supplied>-C</supplied> could help with.<gap/> the TEI might want to provide
                recommendations or ideas about this type of formative assessment for projects.
                Because these projects—earlier in the project, they soak up money. A good outside
                consultant can save you money<gap/></quote>
              <ref type="bibl" xml:id="quoteref34" target="#participantO">Participant O</ref>
            </cit>
          </p>
          <p>Not only would a consultation potentially save money, but it would also allow the TEI-C
            to help promote best practices and innovation in the use of text encoding and its
            intersection with other tools. One of the criteria given for evaluation was whether the
            scholarship contributed additional knowledge that would lead to improvement of the tools
            that it used. Thus, these activities may also help the TEI-C identify future
            improvements as more people continue to use, learn, teach, and refine the TEI Guidelines
            through the evaluation of digital scholarship. Consultation and review could also
            benefit project leaders in that they would be forced to consider their methodology and
            begin documenting their editorial decisions earlier. As demonstrated in the previous
            discussion, such assistance was exactly what several of the junior scholars and
            participants outside of large fields of scholarship had stated as a primary reason why
            they wanted the TEI-C to be involved in the evaluation process.</p>
          <p>Several participants suggested that the <title level="j">JTEI</title> could provide an
            appropriate forum to highlight reviews of the TEI tag set and its use in digital
            scholarship. The online availability and lack of access restriction was particularly
            appealing for participants. Using the <title level="j">JTEI</title> as a forum for
            review would also meet the stated goals of the journal to <quote source="#quoteref35"
              >disseminate as widely as possible information about the TEI and its applications to
              scholarship</quote> and to provide <quote source="#quoteref35">a forum for <gap/>
              discussion of <gap/> the role of technological standards in the digital
              humanities</quote>.<note><bibl xml:id="quoteref35"><title level="j">Journal of the
                  Text Encoding Initiative</title> home page, accessed March 21, 2014, <ptr
                  target="http://journal.tei-c.org/journal/index"/>.</bibl></note> Currently there
            is no dedicated project review section. If the <title level="j">JTEI</title> was to
            include a section that provided a forum for discussing scholarship evaluation, it could
            publish and commission reviews of completed and ongoing work. As one participant noted,
            the <title level="j">JTEI</title> could <quote source="#quoteref36">Make the review
              process itself useful to people <gap/> that’s where I would recommend the TEI Journal.
              It should get into reviewing. If they had a reviews column, then people who did
                <supplied>the reviews</supplied> could rewrite their reviews and submit them and get
              it published, just like a book review</quote> [<ref type="bibl" xml:id="quoteref36"
              target="#participantO">Participant O</ref>]. The <title level="j">JTEI</title> could
            decide whether or not to provide short reviews and links, or <quote source="#quoteref37"
              >more critical pieces that also deal with some other factors <gap/> like new uses of
              P5 <gap/>
              <supplied>to give</supplied> people the space to be more thoughtful</quote> [<ref
              type="bibl" xml:id="quoteref37" target="#participantN">Participant N</ref>]. By
            providing reviews of digital scholarship, the <title level="j">JTEI</title> would
            function as a kind of <quote source="#quoteref38">vetting</quote> space, a place that
            will not only <quote source="#quoteref38">get people up to speed from the initial
              understanding of the TEI</quote> but also show the more experienced members of
            discipline-based communities how to expand the possibilities of the use of TEI tags in
            scholarly work [<ref type="bibl" xml:id="quoteref38" target="#participantR">Participant
              R</ref>]. Certainly, some participants saw the <title level="j">JTEI</title> as the
            ideal platform for disseminating evaluations primarily because the journal functions
            more like a traditional print-based mechanism.</p>
        </div>
      </div>
      <div xml:id="future">
        <head>Future Directions</head>
        <p>Despite the fact that participant perspectives on the TEI community’s involvement in
          evaluating digital scholarship varied widely, there are a number of important conclusions.
          The first is that most of the participants indicated that a part (in this case, the
          evaluation of text encoding) could not serve as an evaluation of the whole. Second,
          participants by-and-large believe that the TEI-C is at present not equipped to evaluate
          digital scholarship in the same way as NINES and similar groups because its infrastructure
          is not designed as a field-specific peer-review body. Third, some participants noted that
          the TEI-C would critique scholarly materials according to its own approach to encoding,
          but there is no one way to apply the TEI tag set. Thus, there is concern that the TEI-C
          would be prone to bias if the organization attempted to review the philosophy and
          execution of encoded scholarly materials.</p>
        <p>However, there were also a number of compelling reasons given for why the TEI-C and the
          user community are strategically placed to make valuable contributions to the evaluation
          of text encoded digital scholarship. It would be a considerable asset for the scholarly
          community if the TEI-C supplemented the activities of other evaluative groups and provided
          materials and examples for the assessment of text encoding. In many cases, these groups
          may not have persons experienced in the application of the TEI tag set, and thus would
          benefit from input from experienced members of the TEI user community. Ideally, the next
          step would be to commission case studies to test and demonstrate how these collaborations
          would work in practice. The intent is that these case studies would foster additional
          dialogue within the user community and among dedicated peer-review groups such as NINES on
          the ways in which the TEI-C might best contribute. Another area where the TEI-C may be
          able to benefit the community is in providing evaluative assistance to scholars at crucial
          points in project development. Such assistance might help resolve expensive and
          time-intensive problems earlier in the development process. Again, case studies would be a
          beneficial avenue to explore further in this regard. Other evaluative bodies may also
          benefit from this aspect of review because there will be a record of the suggestions given
          on a project during the consultation, thus providing a context for the final form that the
          project takes. Finally, the results of this study suggest that exploring avenues of review
          within the context of the <title level="j">JTEI</title> would be a promising next step. We
          envision something along the lines of a dedicated project reviews section, though the
          exact form that this would take is still under consideration. Although there are no easy
          answers in establishing criteria to evaluate digital scholarship, participant responses
          suggest that assessment of a text encoding philosophy would still be most appropriately
          left to those who have experience in the development and application of tag sets. With
          regards to the TEI, scholars that have developed and use the Guidelines are needed to
          provide evaluative assistance to others, and may in turn add to the pedagogical resources
          requested for use by the larger community.</p>
      </div>
    </body>
    <back>
      <div type="bibliography" xml:id="biblio">
        <listBibl>
          <bibl xml:id="anderson11"><author>Anderson, Steve</author>, and <author>Tara
              McPherson</author>. <date>2011</date>. <title level="a">Engaging Digital Scholarship:
              Thoughts on Evaluating Multimedia Scholarship</title>. <title level="j"
              >Profession</title>
            <biblScope unit="issue">2011</biblScope>: <biblScope unit="page">136–51</biblScope>.
              doi:<idno type="doi">10.1632/prof.2011.2011.1.136</idno>.</bibl>
          <bibl xml:id="burgess11"><author>Burgess, Helen J.</author>, and <author>Jeanne
              Hamming</author>. <date>2011</date>. <title level="a">New Media in the Academy: Labor
              and the Production of Knowledge in Scholarly Multimedia</title>. <title level="j"
              >Digital Humanities Quarterly</title>
            <biblScope unit="volume">5</biblScope>(<biblScope unit="issue">3</biblScope>). <ptr
              target="http://www.digitalhumanities.org/dhq/vol/5/3/000102/000102.html"/>.</bibl>
          <bibl xml:id="cohen12"><author>Cohen, Daniel J.</author>, and <author>Joan Fragaszy
              Troyano</author>. <date>2012</date>. <title level="a">Closing the Evaluation
              Gap</title>. <title level="j">Journal of Digital Humanities</title>
            <biblScope unit="volume">1</biblScope>(<biblScope unit="issue">4</biblScope>):
              <biblScope unit="page">i–ii</biblScope>. <ptr
              target="http://journalofdigitalhumanities.org/1-4/"/>.</bibl>
          <bibl xml:id="crane06"><author>Crane, Gregory</author>, <author>David Bamman</author>,
              <author>Lisa Cerrato</author>, <author>Alison Jones</author>, <author>David
              Mimno</author>, <author>Adrian Packel</author>, <author>David Sculley</author>, and
              <author>Gabriel Weaver</author>. <date>2006</date>. <title level="a">Beyond Digital
              Incunabula: Modeling the Next Generation of Digital Libraries</title>. <title
              level="m">Research and Advanced Technology for Digital Libraries (ECDL 2006), Lecture
              Notes in Computer Science 4172</title>, edited by <editor>Julio Gonzalo</editor>,
              <editor>Costantino Thanos</editor>, <editor>M. Felisa Verdejo</editor>, and
              <editor>Rafael C. Carrasco</editor> (<pubPlace>Berlin</pubPlace> and
              <pubPlace>Heidelberg</pubPlace>: <publisher>Springer Verlag</publisher>), <biblScope
              unit="page">353–66</biblScope>. doi:<idno type="doi"
            >10.1007/11863878_30</idno>.</bibl>
          <bibl xml:id="cummings07"><author>Cummings, James</author>. <date>2007</date>. <title
              level="a">The Text Encoding Initiative and the Study of Literature</title>. In <title
              level="m">A Companion to Digital Literary Studies</title>, edited by <editor>Ray
              Siemens</editor> and <editor>Susan Schreibman</editor>, <biblScope>451–76</biblScope>.
              <pubPlace>Oxford</pubPlace>: <publisher>Blackwell Publishing</publisher>.</bibl>
          <bibl xml:id="curran10"><author>Curran, Stuart</author>. <date>2010</date>. <title
              level="a">Different Demands, Different Priorities: Electronic and Print
              Editions</title>. <title level="j">Literature Compass</title>
            <biblScope unit="volume">7</biblScope>(<biblScope unit="issue">2</biblScope>):
              <biblScope unit="page">82–88</biblScope>. doi:<idno type="idno"
              >10.1111/j.1741-4113.2009.00679.x</idno>.</bibl>
          <bibl xml:id="flanders09"><author>Flanders, Julia</author>. <date>2009</date>. <title
              level="a">The Productive Unease of 21st-Century Digital Scholarship</title>. <title
              level="j">Digital Humanities Quarterly</title>
            <biblScope unit="volume">3</biblScope>(<biblScope unit="issue">3</biblScope>). <ptr
              target="http://www.digitalhumanities.org/dhq/vol/3/3/000055/000055.html"/>.</bibl>
          <bibl xml:id="fiormonte10"><author>Fiormonte, Domenico</author>, <author>Valentina
              Martiradonna</author>, and <author>Desmond Schmidt</author>. <date>2010</date>. <title
              level="a">Digital Encoding as a Hermeneutic and Semiotic Act: The Case of Valerio
              Magrelli</title>. <title level="j">Digital Humanities Quarterly</title>
            <biblScope unit="volume">4</biblScope>(<biblScope unit="issue">1</biblScope>). <ptr
              target="http://www.digitalhumanities.org/dhq/vol/4/1/000082/000082.html"/>.</bibl>
          <bibl xml:id="greetham97"><author>Greetham, David C.</author>
            <date>1997</date>. <title level="a">The Resistance to Philology</title>. In <title
              level="m">The Margins of the Text</title>, edited by <editor>D. C. Greetham</editor>,
              <biblScope unit="page">9–24</biblScope>. <pubPlace>Ann Arbor</pubPlace>,
              <pubPlace>Michigan</pubPlace>: <publisher>University of Michigan
            Press</publisher>.</bibl>
          <bibl xml:id="lavagnino06"><author>Lavagnino, John</author>. <date>2006</date>. <title
              level="a">When Not to Use TEI</title>. In <title level="m">Electronic Textual
              Editing</title>, edited by <editor>Lou Burnard</editor>, <editor>Katherine O’Brien
              O’Keeffe</editor>, and <editor>John Unsworth</editor>, <biblScope unit="page"
              >334–48</biblScope>. <pubPlace>New York</pubPlace>: <publisher>Modern Language
              Association of America</publisher>.</bibl>
          <bibl xml:id="mandell10"><author>Mandell, Laura</author>. <date>2010</date>. <title
              level="a">Special Issue: <q>Scholarly Editing in the Twenty-First Century</q>—A
              Conclusion</title>. <title level="j">Literature Compass</title>
            <biblScope unit="volume">7</biblScope>(<biblScope unit="issue">2</biblScope>):
              <biblScope unit="page">120–33</biblScope>. doi:<idno type="doi"
              >10.1111/j.1741-4113.2009.00684.x</idno>.</bibl>
          <bibl xml:id="mcgann01"><author>McGann, Jerome</author>. <date>2001</date>. <title
              level="m">Radiant Textuality: Literature after the World Wide Web</title>.
              <pubPlace>New York</pubPlace>: <publisher>Palgrave</publisher>.</bibl>
          <bibl xml:id="mla13a"><orgName>Modern Language Association</orgName>. <date>2013a</date>.
              <title level="a">About the MLA</title>. Last modified June 5, 2012. <ptr
              target="http://www.mla.org/about"/>.</bibl>
          <bibl xml:id="mla13b"><orgName>Modern Language Association</orgName>. <date>2013b</date>.
              <title level="a">Guidelines for Evaluating Work in Digital Humanities and Digital
              Media</title>. Last modified December 20, 2013. <ptr
              target="https://www.mla.org/guidelines_evaluation_digital"/>.</bibl>
          <!-- both NINES references have been duplicated in footnotes -->
          <!--           
          <bibl xml:id="ninesnes12"><orgName>NINES/NEH Summer Institutes</orgName>. <date>2012</date>. <title level="a">Evaluating Digital Scholarship</title>. <series>NINES/NEH Summer Institutes: 2011–2012</series>. Accessed December 29, 2012. <ptr target="http://institutes.nines.org/"/>.</bibl>
          <bibl xml:id="nines12"><orgName>NINES</orgName>. <date>2012</date>. <title level="a">What is NINES?</title> Accessed March 13, 2013. <ptr target="http://www.nines.org/about/"/>.</bibl>
-->
          <bibl xml:id="nowviskie10"><author>Nowviskie, Bethany</author>. <date>2010</date>. <title
              level="a">#Alt-Ac: Alternate Academic Careers for Humanities Scholars</title>.
            Accessed March 23, 2013. <ptr target="http://nowviskie.org/2010/alt-ac/"/>.</bibl>
          <bibl xml:id="presner12"><author>Presner, Todd</author>. <date>2012</date>. <title
              level="a">How to Evaluate Digital Scholarship</title>. <title level="j">Journal of
              Digital Humanities</title>
            <biblScope unit="volume">1</biblScope>(<biblScope unit="issue">4</biblScope>):
              <biblScope unit="page">36–39</biblScope>. <ptr
              target="http://journalofdigitalhumanities.org/1-4/how-to-evaluate-digital-scholarship-by-todd-presner/"
            />.</bibl>
          <bibl xml:id="purdy10"><author>Purdy, James P.</author>, and <author>Joyce R.
              Walker</author>. <date>2010</date>. <title level="a">Valuing Digital Scholarship:
              Exploring the Changing Realities of Intellectual Work</title>. <title level="j"
              >Profession</title>
            <biblScope unit="issue">2010</biblScope>: <biblScope unit="page">177–95</biblScope>.
              doi:<idno type="doi">10.1632/prof.2010.2010.1.177</idno>.</bibl>
          <bibl xml:id="renear04"><author>Renear, Alan</author>. <date>2004</date>. <title level="a"
              >Text Encoding</title>. In <title level="m">A Companion to Digital Humanities</title>,
            edited by <editor>Susan Schreibman</editor>, <editor>Ray Siemens</editor>, and
              <editor>John Unsworth</editor>, <biblScope unit="page">218–39</biblScope>.
              <pubPlace>Oxford</pubPlace>: <publisher>Blackwell Publishing</publisher>.</bibl>
          <bibl xml:id="rockwell11"><author>Rockwell, Geoffrey</author>. <date>2011</date>. <title
              level="a">On the Evaluation of Digital Media as Scholarship</title>. <title level="j"
              >Profession</title>
            <biblScope unit="issue">2011</biblScope>: <biblScope unit="page">152–68</biblScope>.
              doi:<idno type="doi">10.1632/prof.2011.2011.1.152</idno>.</bibl>
          <bibl xml:id="schreibman11"><author>Schreibman, Susan</author>, <author>Laura
              Mandell</author>, and <author>Stephen Olsen</author>. <date>2011</date>. <title
              level="a">Evaluating Digital Scholarship: Introduction</title>. <title level="j"
              >Profession</title>
            <biblScope unit="issue">2011</biblScope>: <biblScope unit="page">123–35</biblScope>.
              doi:<idno type="doi">10.1632/prof.2011.2011.1.123</idno>.</bibl>
          <bibl xml:id="msmq94"><author>Sperberg-McQueen, C. M.</author>
            <date>1994</date>. <title level="a">Textual Criticism and the Text Encoding
              Initiative</title>. Paper presented at the annual Convention of the Modern Language
            Association, San Diego, California, December. <ptr
              target="http://www.tei-c.org/Vault/XX/mla94.html"/>.</bibl>
          <bibl xml:id="tanselle06"><author>Tanselle, G. Thomas</author>. <date>2006</date>.
            Foreword to <title level="m">Electronic Textual Editing</title>, edited by <editor>Lou
              Burnard</editor>, <editor>Katherine O’Brien O’Keeffe</editor>, and <editor>John
              Unsworth</editor>, <biblScope unit="page">1–6</biblScope>. <pubPlace>New
              York</pubPlace>: <publisher>Modern Language Association of America</publisher>.</bibl>
          <bibl xml:id="tei13a"><orgName>Text Encoding Initiative</orgName>. <date>2013a</date>.
              <title level="m">TEI: Text Encoding Initiative</title>. Accessed March 17, 2013. <ptr
              target="http://www.tei-c.org/index.xml"/>.</bibl>
          <bibl xml:id="tei13b"><orgName>Text Encoding Initiative</orgName>. <date>2013b</date>.
              <title level="a">Projects Using the TEI</title>. Accessed April 9, 2013. <ptr
              target="http://www.tei-c.org/Activities/Projects/"/></bibl>
          <bibl xml:id="unsworth97"><author>Unsworth, John</author>. <date>1997</date>. <title
              level="a">Documenting the Reinvention of Text: The Importance of Failure</title>.
              <title level="j">Journal of Electronic Publishing</title>
            <biblScope unit="volume">3</biblScope>(<biblScope unit="issue">2</biblScope>). doi:
              <idno type="doi">10.3998/3336451.0003.201</idno>.</bibl>
          <bibl xml:id="wgephs10"><orgName>Working Group on Evaluating Public History
              Scholarship</orgName>, <date>2010</date>. <title level="a">Tenure, Promotion, and the
              Publicly Engaged Academic Historian</title>. <title level="j">Journal of Digital
              Humanities</title>
            <biblScope unit="volume">1</biblScope>(<biblScope unit="issue">4</biblScope>):
              <biblScope unit="page">98</biblScope>. <ptr
              target="http://journalofdigitalhumanities.org/1-4/tenure-promotion-and-the-publicly-engaged-historian/"
            />.</bibl>
        </listBibl>
      </div>
      <div type="appendix" xml:id="appendix">
        <head>Interview Questions</head>
        <list rend="ordered">
          <item>Should the TEI-C have a role in the evaluation of digital scholarship? Please
            explain.</item>
          <item>What form should contributions to the discussion of the evaluation of digital
            scholarship from the TEI-C take?</item>
          <item>Is text encoding a scholarly activity? Why or why not?</item>
          <item>When should a TEI tagged work be evaluated? What are the benefits of formative
            reviews?</item>
          <item>How could we evaluate text encoding in digital scholarship? As a digital tool? As
            part of the larger editorial methodology?</item>
          <item>Who would review a TEI tagged project and what criteria would they use?</item>
        </list>
      </div>
    </back>
  </text>
</TEI>
<?oxy_options track_changes="on"?>
