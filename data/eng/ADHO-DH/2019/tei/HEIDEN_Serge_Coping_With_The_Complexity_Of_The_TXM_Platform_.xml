<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title type="full">
                    <title type="main">Coping With The Complexity Of The TXM Platform Annotation Services With A Unified TEI Encoding Framework</title>
                    <title type="sub"/>
                </title>
                <author>
                    <persName>
                        <surname>Heiden</surname>
                        <forename>Serge</forename>
                    </persName>
                    <affiliation>ENS de Lyon, France</affiliation>
                    <email>slh@ens-lyon.fr</email>
                </author>
            </titleStmt>
            <editionStmt>
                <edition>
                    <date>2019-04-26T16:12:36.814730624</date>
                </edition>
            </editionStmt>
            <publicationStmt>
                <publisher>Name, Institution</publisher>
                <address>
                    <addrLine>Street</addrLine>
                    <addrLine>City</addrLine>
                    <addrLine>Country</addrLine>
                    <addrLine>Name</addrLine>
                </address>
            </publicationStmt>
            <sourceDesc>
                <p>Converted from an OASIS Open Document</p>
            </sourceDesc>
        </fileDesc>
        <encodingDesc>
            <appInfo>
                <application ident="DHCONVALIDATOR" version="1.22">
                    <label>DHConvalidator</label>
                </application>
            </appInfo>
        </encodingDesc>
        <profileDesc>
            <textClass>
                <keywords scheme="ConfTool" n="category">
                    <term>Paper</term>
                </keywords>
                <keywords scheme="ConfTool" n="subcategory">
                    <term>Long Paper</term>
                </keywords>
                <keywords scheme="ConfTool" n="keywords">
                    <term>digital text encoding</term>
                    <term>annotation</term>
                    <term>XML</term>
                    <term>TEI</term>
                    <term>textometry</term>
                    <term>TXM</term>
                    <term>digital hermeneutics</term>
                </keywords>
                <keywords scheme="ConfTool" n="topics">
                    <term>corpus and text analysis</term>
                    <term>text encoding and markup languages</term>
                    <term>natural language processing</term>
                    <term>standards and interoperability</term>
                    <term>English</term>
                    <term>computer science and informatics</term>
                    <term>digital humanities (history</term>
                    <term>theory and methodology)</term>
                </keywords>
            </textClass>
        </profileDesc>
    </teiHeader>
    <text>
        <body>
            <div type="div1" rend="DH-Heading1">
                <head>Introduction</head>
                <p>TXM is a software platform offering textual corpora analysis tools and services. It is delivered as a standard desktop application for Windows, Mac and Linux and as a web portal server application (Heiden, 2010), &lt;
                    <ptr target="http://textometrie.ens-lyon.fr/?lang=en"/>&gt;.
                </p>
                <p>TXM provides a consistent set of analysis tools combining qualitative (or close reading) tools such as word frequency lists, concordancing or text edition hypertextual navigation with synthetic quantitative (or distant reading) tools such as factorial analysis, clustering, keywords or co-occurrence statistical analysis.</p>
                <p>To work on texts, the platform first imports the corpus sources to create a rich XML-TEI based internal pivot representation via the following general workflow:</p>
                <list type="unordered">
                    <item>
                        <p>first the “base text” of each text is established: this operation implements “digital philology” principles and consists of decoding information in the various formats of the source documents to decide primarily where are the text limits, possible internal textual structures boundaries and the words of the text.</p>
                        <p>To do this, TXM can analyze and represent three main types of corpora:</p>
                        <list type="unordered">
                            <item>corpora of 
                                <hi rend="bold">written texts</hi>, possibly including paginated editions including display side-by-side of the transcription and the images of facsimiles;
                            </item>
                            <item>
                                <hi rend="bold">record transcriptions</hi> corpora, possibly time synchronized at the word or at the speech turn level with the audio or video source to provide playback;
                            </item>
                            <item>and parallel 
                                <hi rend="bold">multilingual</hi> corpora aligned at the level of textual structures such as sentences or paragraphs.
                            </item>
                        </list>
                        <p>The result of this operation is represented in a pivot XML format especially designed for TXM called “XML-TEI TXM” extending the standard encoding recommendations of the Text Encoding Initiative consortium (TEI Consortium, 2017);</p>
                    </item>
                    <item>then, natural language processing (NLP) tools are optionally applied to the base text to automatically add linguistic information like sentence boundaries, grammatical categories (pos = part of speech) and lemma of words by eg TreeTagger (Schmid, 1994). As NLP tools generally don’t take XML format as input, the pivot representation is first converted to plain text for NLP processing and results are injected back into the XML-TEI TXM representation;</item>
                    <item>finally a specialized representation of the texts is built into TXM for efficient execution of its different tools (by indexing for search engines or by rendering in HTML 5+CSS+Javascript for text editions navigation).</item>
                </list>
                <p>From a methodological point of view:</p>
                <list type="unordered">
                    <item>the XML tags of the initial XML-TEI TXM representation in a) can be seen as 
                        <hi rend="bold">manual annotations</hi> added to the base text (or raw text), typically philologically edited with the help of specialized XML editors (like Oxygen XML Editor
                        <note xml:id="ftn0" place="foot" n="1">
                            <ref target="https://www.oxygenxml.com/">https://www.oxygenxml.com</ref>
                        </note>) outside of TXM when the source is XML native, or as 
                        <hi rend="bold">automatic annotations</hi> added by TXM when converting the sources from other digital formats (like TXT, DOC, etc.) into XML-TEI TXM.
                    </item>
                    <item>NLP tools processing results in step b) can be seen as 
                        <hi rend="bold">automatic annotations</hi> added to the initial XML-TEI TXM representation of texts built in work step a);
                    </item>
                    <item>All TXM tools can then be applied indiscriminately to all types of annotations through a unified textual corpus data model regardless of their origin (automatic or manual).</item>
                </list>
                <p>Thus, so far TXM has implemented a traditional digital philology workflow combining an initial “text source encoding and annotation” step to a following “application of analysis tools on annotated texts” step. The text analysis tools use text annotations (for example word pos or some internal textual structure) to offer their services and produce their results (for example the frequency index of all infinitive verbs found in a section). The workflow is unidirectional and the whole of it must be passed through again completely if any annotation needs to be corrected. To add or correct annotations, the user has to edit the sources or the annotations outside of TXM. For example word properties can be exported from the XML-TEI TXM representation in a file in tabulated format, edited in a spreadsheet and injected back into the texts before re-import into TXM
                    <note xml:id="ftn1" place="foot" n="2"> see for example this tutorial based on TXM macros: 
                        <ptr target="https://groupes.renater.fr/wiki/txm-users/public/tutoriel_correction_mots"/>.
                    </note>.
                </p>
                <p>This paper introduces new services developed in TXM to annotate directly texts from within the results view of specific tools for a better integration of philological and analytical work. Indeed, results views are great places to be aware of annotation errors or annotation needs, and to access what needs to be corrected or annotated.</p>
            </div>
            <div type="div1" rend="DH-Heading1">
                <head>Interactive annotation services in TXM</head>
                <p>The three new annotation services concern both adding and correcting information, and all the annotations edited are meant for further exploitation by usual TXM tools.</p>
                <div type="div2" rend="DH-Heading2">
                    <head>Concordance based SyMoGIH entities annotation</head>
                    <p>The first service, developed in partnership with the LARHRA research laboratory in history
                        <note xml:id="ftn2" place="foot" n="3">
                            <ref target="http://larhra.ish-lyon.cnrs.fr/">
                                <hi rend="color(#00000a)">http://larhra.ish-lyon.cnrs.fr</hi>
                            </ref>
                        </note>, is based on the annotation of concordance pivots: any sequence of words composing the pivots can be annotated with any semantic category
                        <note xml:id="ftn3" place="foot" n="4"> pivotscan also optionally be annotated with simple keywords or with key-value pairs, managed by TXM in a local repository.</note> of the SyMoGIH
                        <note xml:id="ftn4" place="foot" n="5">
                            <ptr target="http://symogih.org/?lang=en"/>
                        </note> historical knowledge base (Beretta, 2015). In this architecture, the SyMoGIH platform hosts the ontology of historic facts and knowledge, and TXM concordances provide the user interface to link identifiers of those data to text spans for further analysis.
                    </p>
                    <p>As an illustration, see figure 1 the annotation of the “Faculté de droit d’Aix” entity (of id CoAc13562) in unverified OCRed texts of the “Bulletin administratif de l'Instruction publique" corpus
                        <note xml:id="ftn5" place="foot" n="6"> see the Bibliothèque historique de l'éducation (BHE) project: 
                            <ptr target="http://www.persee.fr/collection/bhe"/>
                        </note>.
                    </p>
                    <p>
                        <figure>
                            <graphic url="Pictures/151ac82748a0252ad587c4d7c2ddaf8c.png"/>
                        </figure>Figure 1. TXM screenshot of a Concordance of a “Faculté de droit d’Aix” word sequence pattern to annotate (top) and of browsing SyMoGIH semantic categories to find the CoAc13562 identifier to use for the annotation (bottom).
                    </p>
                    <p>TXM internal management of those annotations is equivalent to a re-import of the current pivot representation with the new annotations. After re-import (after saving annotations) the new annotations are available for all TXM tools to work on like any original “annotation” of the texts (with internal textual structures and their properties).</p>
                </div>
                <div type="div2" rend="DH-Heading2">
                    <head>Concordance based word properties annotation</head>
                    <p>The second service is based on the annotation of words of concordance pivots: a word present in the pivots
                        <note xml:id="ftn6" place="foot" n="7"> in TXM, pivots of concordances can be composed of a sequence of words.</note> of a concordance can be annotated with any property. The primary goal of that service is to annotate and correct pos and lemma properties of words, but it can help to annotate any property at the single word level.
                    </p>
                    <p>As an illustration, see figure 2 the correction of the “pos” property of some “vers.” words used in biblical references in Hobbes works lemmatized by Morphadorner (Burns, 2013).</p>
                    <p>
                        <figure>
                            <graphic url="Pictures/ae36d338091efb092474db989800a55f.png"/>
                        </figure> Figure 2. TXM screenshot of a Concordance to set the “pos” property to the “n-ab” value of two occurrences of the "vers." word, selected by their concordance line.
                    </p>
                    <p>TXM internal management of those annotations is equivalent to a re-import of the current pivot representation with new annotations encoded in XML-TEI TXM at the word level.</p>
                </div>
                <div type="div2" rend="DH-Heading2">
                    <head>Full text URS annotation in text edition</head>
                    <p>The third annotation service is based on manual annotation of sequence of words inside text editions with elements of a Unit-Relation-Schema (URS) annotation model (Widlöcher &amp; Mathet, 2009). URS type annotations are designed to encode complex discourse entities like co-reference chains in texts (Schnedecker et al., 2017).</p>
                    <p>As an illustration, see figure 3 the annotation of the “ses loix” sequence of words with a URS unit of type MENTION, having its grammatical category to the value “GN.POS” and its referent to the value “les lois de la divinité”, in the first chapter of the 1755 edition of 
                        <hi rend="italic">De l'esprit des lois</hi> by Montesquieu.
                    </p>
                    <p>
                        <figure>
                            <graphic url="Pictures/ef5c032c541cc70a35eef277589c24fc.png"/>
                        </figure>Figure 3. TXM screenshot displaying the first page of an edition of 
                        <hi rend="italic">De l'esprit des lois</hi> highlighting in light yellow all URS units of type MENTION and in bold the unit currently selected (top window), and displaying the current unit properties value input form (bottom window): CATEGORY property at value “GN.POS”...
                    </p>
                    <p>TXM import/export management services represent those annotations as XML-TEI stand-off annotations anchored to the word elements of the XML-TEI TXM representation of texts (Grobol et al., 2018).</p>
                </div>
            </div>
            <div type="div1" rend="DH-Heading1">
                <head>Discussion</head>
                <p>By using a common XML-TEI TXM pivot representation for internal management of corpora for all the annotation services, TXM unifies transcription, encoding and annotation activities in a single framework. In this framework, annotations can represent manual (user), semi-automatic (machine+user) or automatic (machine) interpretation results used further for analysis and interpretation work. The reflexive nature of the resulting text analysis workflow is schematized in figure 4. Texts are first digitized by OCR, transcribed or converted from digital formats. They are then possibly philologically corrected and established through XML-TEI manual encoding. Then automatically processed by NLP tools while being imported into TXM to produce the TXM internal corpus model. Corpus analysis is then assisted by TXM tools applied to the corpus model. The pivot representation that gathers all annotations produced by annotation tools is figured as the node labeled « Pivot rep. » and the interpretation workflow itself is figured as a digital hermeneutic circle.</p>
                <p>
                    <figure>
                        <graphic url="Pictures/858bcdfe893849dfa7d513de0534df57.png"/>
                    </figure>Figure 4. Digital hermeneutic circle integration into TXM.
                </p>
                <p>Legend</p>
                <table rend="frame" xml:id="Tableau1">
                    <row>
                        <cell rend="bold">blue box:</cell>
                        <cell>manual annotation activity</cell>
                        <cell rend="bold">black box:</cell>
                        <cell>tool</cell>
                    </row>
                    <row>
                        <cell rend="bold">red box:</cell>
                        <cell>automatic annotation activity</cell>
                        <cell rend="bold">green box:</cell>
                        <cell>TXM corpus data model</cell>
                    </row>
                    <row>
                        <cell rend="bold">purple disk:</cell>
                        <cell>data representation</cell>
                        <cell rend="bold">black arrow:</cell>
                        <cell>activity</cell>
                    </row>
                    <row>
                        <cell rend="bold">green arrow:</cell>
                        <cell>annotation equivalence</cell>
                        <cell/>
                        <cell/>
                    </row>
                </table>
            </div>
            <div type="div1" rend="DH-Heading1">
                <head>Conclusion</head>
                <p>All the new annotation services integrated into TXM are building a comprehensive annotation-based digital text corpora analysis platform. From an epistemological point of view, the integration in TEI of the different annotation models and tools into the platform helps its users to better define and trace what comes from the source corpus they analyze and what comes from their own or from others interpretation work.</p>
                <p>This work was funded by the ANR and the DFG under grant numbers 
                    <ref target="https://anr.fr/en/funded-projects-and-impact/funded-projects/project/funded/project/anr-15-ce38-0008">ANR-15-CE38-0008</ref> (DEMOCRAT project) and 
                    <ref target="https://anr.fr/en/funded-projects-and-impact/funded-projects/project/funded/project/anr-14-fral-0006/?tx_anrprojects_funded%5Bcontroller%5D=Funded&amp;cHash=1ebeb099b4581a2a1703678c053a92c3">ANR-14-FRAL-0006</ref> (PaLaFra project).
                </p>
            </div>
        </body>
        <back>
            <div type="bibliogr">
                <listBibl>
                    <head>Bibliography</head>
                    <bibl>
                        <hi rend="bold">Beretta, F.</hi> (2015). Publishing and sharing historical data on the semantic web : the SyMoGIH project – symogih.org. Presented at the Workshop: 
                        <hi rend="italic">Semantic Web Applications in the Humanities</hi>. Retrieved from https://halshs.archives-ouvertes.fr/halshs-01136533.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Burns, P. R.</hi> (2013). MorphAdorner v2: A Java Library for the Morphological Adornment of English Language Texts. Evanston, IL. Northwestern University.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Grobol, L., Landragin, F. </hi>
                        <hi rend="bold">and</hi>
                        <hi rend="bold"> Heiden, S.</hi> (2018). XML-TEI-URS: using a TEI format for annotated linguistic resources. 
                        <hi rend="italic">CLARIN Annual Conference 2018</hi>. Pisa, Italy https://hal.archives-ouvertes.fr/hal-01827563.
                    </bibl>
                    <bibl>
                        <hi rend="bold">Heiden, S.</hi> (2010). The TXM Platform: Building Open-Source Textual Analysis Software Compatible with the TEI Encoding Scheme. In Otoguro, R., Ishikawa, K., Umemoto, H., Yoshimoto, K. and Harada, Y. (eds), 
                        <hi rend="italic">24th Pacific Asia Conference on Language, Information and Computation – PACLIC24</hi>. Sendai: Institute for Digital Enhancement of Cognitive Development, pp. 389-98. &lt;https://halshs.archives-ouvertes.fr/halshs-00549764/en&gt; (accessed 15 April 2019).
                    </bibl>
                    <bibl>
                        <hi rend="bold">Schmid, H.</hi> (1994). Probabilistic Part-Of-Speech Tagging Using Decision Trees. In 
                        <hi rend="italic">Proceedings of the International Conference on New Methods in Language Processing</hi> (Vol. 12).
                    </bibl>
                    <bibl>
                        <hi rend="bold">Schnedecker, C., Glikman, J., </hi>
                        <hi rend="bold">and</hi>
                        <hi rend="bold"> Landragin, F.</hi> (2017). Les chaînes de référence : annotation, application et questions théoriques. 
                        <hi rend="italic">Langue française</hi>, (195), 5–16. https://doi.org/10.3917/lf.195.0005
                    </bibl>
                    <bibl>
                        <hi rend="bold">TEI Consortium. </hi>(2017). TEI P5: Guidelines for Electronic Text Encoding and Interchange. TEI Consortium. Retrieved from http://www.tei-c.org/Guidelines/P5
                    </bibl>
                    <bibl>
                        <hi rend="bold">Widlöcher, A., </hi>
                        <hi rend="bold">and</hi>
                        <hi rend="bold"> Mathet, Y.</hi> (2009). La plate-forme Glozz: environnement d’annotation et d’exploration de corpus. In 
                        <hi rend="italic">Actes de la 16e Conférence Traitement Automatique des Langues Naturelles (TALN’09), session posters</hi> (p. 10). Senlis, France, France. Retrieved from https://hal.archives-ouvertes.fr/hal-01011969
                    </bibl>
                </listBibl>
            </div>
        </back>
    </text>
</TEI>
