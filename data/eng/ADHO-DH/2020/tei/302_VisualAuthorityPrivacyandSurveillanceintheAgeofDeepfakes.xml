<?xml version="1.0" encoding="UTF-8"?><TEI xmlns="http://www.tei-c.org/ns/1.0"><teiHeader><fileDesc><titleStmt><title type="full"><title type="main">Visual Authority, Privacy, and Surveillance in the Age of Deepfakes</title><title type="sub"/></title></titleStmt><author><persName><surname>Arnold</surname><forename>Taylor</forename></persName><affiliation>University of Richmond, United States of America</affiliation><email>tarnold2@richmond.edu</email></author><editionStmt><edition><date>43881</date></edition></editionStmt><publicationStmt><publisher>Name, Institution</publisher><address><addrLine>Street</addrLine><addrLine>City</addrLine><addrLine>Country</addrLine><addrLine>Name</addrLine></address></publicationStmt><sourceDesc><p>Converted from an OASIS Open Document</p></sourceDesc></fileDesc><encodingDesc><appInfo><application ident="DHCONVALIDATOR" version="1.22"><label>DHConvalidator</label></application></appInfo></encodingDesc><profileDesc><textClass><keywords scheme="ConfTool" n="category"><term>Paper</term></keywords><keywords scheme="ConfTool" n="subcategory"><term>Short Presentation</term></keywords><keywords scheme="ConfTool" n="keywords"><term>critical data studies; software studies; algorithmic bias; surveillance; visual culture</term></keywords><keywords scheme="ConfTool" n="topics"><term>Global</term><term>English</term><term>Contemporary</term><term>artificial intelligence and machine learning</term><term>digital access, privacy, and ethics analysis</term><term>Computer science</term><term>Media studies</term></keywords></textClass></profileDesc></teiHeader><text><body><p>In this paper I present a study of the impact of deepfake technologies in digital modes of communication. I illustrate that deepfakes make novel use of photographic documents as tools for the violation of individual privacy and in doing so offer a fundamentally different challenge to concepts of visual authority. Digital surveillance and &#8220;big data&#8221; systems monitor and record the observed actions and behaviours of people. Algorithmic methods extend surveillance to predictions of behaviours that people may possibly, in the future engage in. I situate deepfakes as a further violation of privacy applied to actions and behaviours that have not and never will occur. By establishing deep-learning based forgeries as an extension of existing tools of digital surveillance, I aim to provide a framework for the critical analysis of a new digital technology that is well positioned to become ubiquitous in the very near future.</p></body></text></TEI>