<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/yoann/Work/Grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.4-SNAPSHOT" ident="GROBID" when="2019-06-05T06:24+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MemoryGraph: Digital Critique of Old Photographs Using a Mobile App that Enhances the Interpretation of Landscape</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asanobou</forename><surname>Kitamoto</surname></persName>
							<email>kitamoto@nii.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Informatics</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MemoryGraph: Digital Critique of Old Photographs Using a Mobile App that Enhances the Interpretation of Landscape</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>MemoryGraph is a medium to record memories as the augmentation of a photograph, which is a medium to record photons. MemoryGraph is a new photographic technique that creates a layer of "memories" (or more precisely, time-series photographs) which are taken by the same composition at different times. Photographs of the same composition can be taken by traditional cameras, but this requires substantial effort, because matching a printed photograph with the current landscape requires mental rotation <ref type="bibr">(Shepard et al., 1971</ref>), a psychologically demanding task. MemoryGraph simplifies this task through direct overlay of a photograph and the current landscape on a camera viewfinder with adjustable transparency. We demonstrate that this simple idea opens up new possibilities for the critical interpretation of photographs in the context of digital critique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Methods</head><p>MemoryGraph focuses on the spatio-temporal relationship between photographs and the real world. This field of interest has given rise to many methods similar to MemoryGraph. For this reason, we begin with a comparison between MemoryGraph and these related methods in order to characterize MemoryGraph's unique properties.</p><p>First, it is necessary to compare MemoryGraph with time-lapse animation, which is also a time-series image of the same composition. The fundamental difference between timelapse animation and MemoryGraph is in time scale and device dependence. Time lapse animation deals with high frequency observations of seconds to minutes using the same location-fized camera, while MemoryGraph deals with low frequency observations over a period of days to years. These observations may potentially use different cameras that are not fixed at the location. In short, MemoryGraph is a tool to realize fixed point observation at any place for any time interval.</p><p>Secondly, we contrast MemoryGraph with augmented reality (AR), which focuses on the alignment of the real space and the virtual space so that a photograph can be seen as an overlay on the real space through a camera viewfinder. On the contrary, MemoryGraph focuses on the overlay of a photograph on a camera viewfinder as a graphic reference to illustrate the composition of a further action (namely, taking a photograph). This key contrast suggests fundamentally different roles between augmented reality and MemoryGraph. Augmented reality is a tool for exhibition, in the sense that alignment is controlled by a tool, while the user is allowed to be a passive visitor who experiences an environment prepared by someone else. Quite the opposite, MemoryGraph is a tool for participation: the "visitor" controls the alignment, and the user should be an active explorer who searches for the best match between photograph and real-life landscape. In short, MemoryGraph is a tool for actions, such as participatory annotation.</p><p>Our final comparison discusses photo-sharing services dedicated to old photographs. For example, Historypin <ref type="bibr">(Shift, 2010</ref>) is designed to share photographs of the past using a map interface, while an advanced system might use a street-view interface to place photographs in 3D. Both tools aim to link photographs to the real world, however, their methods of achieving this goal do not rely on ventures into the "real world" to "place" the photographs. Photo sharing services depend on "arm-chair" annotators, but MemoryGraph depends on "field" annotators who visit a real place to take another photograph. In short, MemoryGraph is a tool to motivate people to move in the real world.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposed Method</head><p>MemoryGraph is designed as a mobile app for two reasons. First, the idea of "graphic reference" overlay on a camera viewfinder cannot be implemented on traditional cameras that do not expose API (application programming interface). By re-purposing the viewfinder of a smart phone, MemoryGraph can extend the grid-based reference of a traditional camera viewfinder to a graphic reference such as an old photograph. Secondly, in order employ MemoryGraph as a field work tool, the use of a mobile phone is the best choice for mobility and also for real-time information sharing with the server.</p><p>The task of the user is to find the best match between a graphic reference and the real world using an opaque viewfinder with adjustable transparency. Direct comparison between two scenes not only reduces the burden of mental rotation for the user, but also makes the search enjoyable: the movement of the user gives real-time visual feedback that suggests how "good" the move is. This gamification effect motivates users to search for better matching, and promotes photographic crowd-sourcing for participatory annotation.</p><p>The outcome of this task is two types of data. One is a photograph that records the current landscape, and another is the metadata of the photograph such as latitude, longitude, and direction observed by sensors in a mobile phone. Metadata may be enhanced later to add a title, and description (among other things), and users can upload metadata and photographs to the server for sharing. The uploaded data can then be used for scholarly research, because the GPS coordinates and the temporally different views of the landscape are valuable resources for understanding the landscape changes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The MemoryGraph (CODH, 2016) app is available for free on Google Play, but an iOS version has not yet been released. The predecessor app, MemoryHunt <ref type="bibr">(Kitamoto, 2015)</ref>, has been used for both the study of cultural landscapes and the monitoring of disaster recovery <ref type="bibr">(DSR, 2014)</ref>.</p><p>To study cultural landscapes, we held several workshops with both scholars and laypersons who tried the app in the field. An example is shown in <ref type="figure" target="#fig_0">Figure 1</ref>, where the reference image was a photograph of Imperial Palace Moat in Tokyo. The photograph was easy to interpret, but the actual place was difficult to find. <ref type="figure" target="#fig_1">Figure 2</ref> shows how participants walked along the moat to find the best match. At each place, participants took the photograph that they believed to be the best match, but the best solution of <ref type="figure" target="#fig_0">Figure 1</ref> was found after many trials of all the participants.  For the second purpose, we held workshops at Kobe in Japan, which was severely damaged by the earthquake in 1995, and Aceh in Indonesia, which was severely damaged by the tsunami in 2004, to understand how the city recovered from the disaster. The app was enjoyed by local people in two countries, and some children were involved more actively than adults due to the gamification effect.</p><p>MemoryGraph can be generalized in several ways. First, it can be generalized from landscape to object: for example, time-series photographs of the same person at different places. Second, it can be generalized to cross-media reference: for example, taking the same composition at a "sacred place" of pop-culture work inspired by the real landscape.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion on Digital Critique</head><p>Digital critique, or what has been referred to in other words as digital criticism <ref type="bibr">(Kitamoto, 2016)</ref> or data criticism <ref type="bibr">(Kitamoto, 2014)</ref>, was proposed by the author as a framework for digital scholarship in the humanities. It has been applied to the criticism of non-textural sources such as maps and photographs with the intent of using them as evidence for historical studies. Although the digital humanities are often considered quantitative or metric humanities, digital critique focuses on the digital creation and management of humanities knowledge. Several types of digital tools have been designed for the critical interpretation of textual and non-textural sources, including success stories such as the identification of Silk Road ruins, or the characterization of mistakes in the renovation of old Beijing maps ( <ref type="bibr">Kitamoto et al., 2014</ref>) ( <ref type="bibr">Kitamoto et al., 2016)</ref>. We claim that MemoryGraph is another digital critique tool that asks the following research questions in order to use a photographic source as historical evidence.</p><p>The first research question asks what the variance and invariance is in the target landscape over time. Invariance is often found as artificial features such as roads and monuments, or natural features such as a mountain ridge, but in other cases, the identification of invariance requires training of the user in terms of interpretive performance on the historical landscape.</p><p>Secondly, we ask how historical evidences can be best integrated across different sources, such as old maps, old photographs and historical databases. Invariance found through the app is a hint to links different sources over time, and this contributes to expanding our understanding by integrating knowledge from different sources.</p><p>Our final research question asks why the photograph was taken in this setting. This is because the best match is theoretically achieved by the same physical posture between the original photographer and the user <ref type="bibr">(Kitamoto, 2015)</ref>. This means that as a user tries to find the best match using the app, a user can re-experience the original photographer who took the photograph in the same posture. The physical overlay of the user and the photographer may lead to research questions investigating the emotion or the way of thinking of the original photographer at the time. This has potential to give birth to new interpretation of photographs from the physical or emotional perspective.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Comparison of two photographs of the same composition. "A view from Miyakezaka to the ministry of justice" taken around 1911 and the current landscape. Courtesy of National Diet Library.</figDesc><graphic url="image-2.png" coords="2,324.06,127.50,70.80,59.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Participants walked along the moat to find the best match, and their trials are marked by icons. The final solution of Figure 1 was obtained at the north end of the moat.</figDesc><graphic url="image-1.png" coords="2,338.22,255.66,188.16,179.76" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The project was partially supported by JSPS Kakenhi Center Grant Number 16H02920 and by Center for Integrated Area Studies (CIAS), Kyoto University. The core contributor to the app is Mr. Tomohiro Ikezaki.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bibliography</head><p>Center for Open Data in the Humanities (CODH) <ref type="bibr">(2016)</ref>. "MemoryGraph." https://mp.ex.nii.ac.jp/mg/, (accessed on April 6, 2017). Digital Silk Road Project (DSR) <ref type="bibr">(2014)</ref>. </p></div>			</div>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
