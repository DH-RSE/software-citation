<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/yoann/Work/Grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.4-SNAPSHOT" ident="GROBID" when="2019-06-05T06:28+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generative Model For Latent Reasons For Modifications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lassner</surname></persName>
							<email>davidlassner@mailbox.tu-berlin.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Germany</roleName><forename type="first">T</forename><forename type="middle">U</forename><surname>Berlin</surname></persName>
						</author>
						<title level="a" type="main">Generative Model For Latent Reasons For Modifications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem</head><p>The idea that writing makes its way from the authors first draft manuscript to the intended reader without any detours or modifications is often inaccurate and oversimplified. In general, the author or a close person performs corrections and stylistic modifications in subsequent iterations. Additionally, there may be an editor or even an official censor who perform censorship of too private or too extreme parts of the document. The different versions of a document generated by these correction layers often become intransparent in printed versions of the document, while manuscripts are more likely to display traces of how the document has been modified to its current state. The digital scholarly edition "Letters and texts. Intellectual Berlin around 1800" (Baillot, 2016, IB in the following) combines genetic edition and entity annotation. The corpus encompasses literary and scholarly testimonies by a group of people, who influenced the intellectual Berlin between Enlightenment and Romanticism. The genetic encoding gives precise information regarding deletions and additions in the manuscript text. However, the reason for these modifications is not encoded. Three main domains for reasons why to modify such a document as a letter in the intellectual context of the time around 1800 have been identified:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Correction of mistakes 2. Stylistic modification 3. Moral censorship based on the topic</head><p>This paper proposes an unsupervised machine learning approach, which assigns the according reason to every modification. The proposed method focuses on dealing with stylistic modifications and moral censorships. I am aiming to increase the accessibility to manuscripts, by providing a structure for the modifications and to assist in evaluation of certain modifications. Furthermore the proposed method may be applied on different editorial problems, which I will discuss in the Outlook section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>As brought up in the Problem section, the proposed method focuses on stylistic and moral censorship reasons, based on the assumption that these two types of reasons relate to the topic of the modification. I convey a generative topic model, that is based on Latent Dirichlet Allocation <ref type="bibr">(D. Blei, Ng, &amp; Jordan, 2003)</ref> and is able to take into account the structural information of modifications. There exists a wide range of topic models that customize LDA and many of these take into account additional structural information. To replace the Bag-of-words approach by introducing structural information about the word order is a major field of LDA research <ref type="bibr">(Gruber, Rosen- Zvi, &amp; Weiss, 2007;</ref><ref type="bibr">Wallach, 2006</ref>). Moreover there exists a lot of research on topic hierarchies (D. M. Blei, <ref type="bibr">Griffiths, &amp; Jordan, 2010;</ref><ref type="bibr">Paisley, Wang, Blei, &amp; Jordan, 2015)</ref>. LDA has also been modified to work with graph-structured documents <ref type="bibr">(Xuan, Lu, Zhang, &amp; Luo, 2015)</ref>. However I am not aware of any literature that shows how to model modification reasons in a corpus of natural language. <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the conceptual functioning of the method from left to right. As input on the left, a collection of documents is given. The documents have parts marked as modified. The generative model in the center infers reasons by taking into account all text, inside and outside the modifications. Every reason may stand for a stylistic, or a certain moral censorship reason (e.g. political, religious). On the right side, the model outputs a reason-modification assignment. In addition to the LDA latent variables, I introduce a topic-reason variable γ, a word-reason-modification tendency λ and a token-reason assignment r. The complete model in plate notation is shown in <ref type="figure" target="#fig_1">Figure 2</ref>. c (observed) models whether a token has been modified. For every topic, γ holds a distribution over reasons, which may cause a modification. For most modifications this distribution should be sparse, for example if a censor crosses out a sentence that discusses the financial situation of the author, the the topic and the reason for censorship would be identical. On the contrary a stylistic modification wouldn't always have one or two clear corresponding topics. For every token and every reason, λ holds a distribution over two states, namely whether the token tends to be modified for this reason. There may be token, that are representative for a topic, but they nonetheless do not tend to be modified. The categorical variable r represents the reason assignment at that position.</p><p>The latent variables can be iteratively approximated using Variational Inference <ref type="bibr">(Bishop, 2006;</ref><ref type="bibr">Zhao, 2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intermediate results</head><p>In this section, evaluation methods on toy data are discussed and characteristics of the IB data set, as well as preparation steps and first intermediate results are presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Toy data</head><p>To evaluate the characteristics of this method, experiments with artificial toy data can be performed. The generative model described above can be employed for inference as well as for generating artificial documents with modifications. A typical experiment to evaluate a generative model is conceived as follows:</p><p>1. Initialize the latent variables of the model randomly 2. Generate documents with modifications 3. Re-initialize the latent variables 4. Try to infer the latent variables from the generated documents <ref type="figure">Figure 3</ref>: Experiment with 585 generated corpora varying the size from 10.000 to 90.000 token and performing inference for z, r, θ und γ, leaving the remaining model parameters fixed</p><p>I have performed a series of experiments to investigate the sensitivity of the model to corpus size. As expected, the accuracy of the model increases with an increasing amount of data. <ref type="figure">Figure 3</ref> shows a decreasing distance between the true value and the expected one, when increasing the size of the data set. The accuracy does also largely depend on the sparsity of the concentration factors, which means that in order to predict the minimal size a real data set should have, one has to come up with according prior concentration factors for the Dirichlet variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IB data set</head><p>To apply this method on the IB data set, some preprocessing steps are necessary. Apart from standard natural language preprocessing, one has to filter out all corrections of mistakes. <ref type="table">Table 1</ref> shows the change of data set characteristics that are caused by the pre-processing. A lot of modifications have been considered to be corrections of mistakes and thus have been filtered out.</p><p>The visualization in <ref type="figure" target="#fig_2">Figure 4</ref> reveals a great variety in the structure of the modifications. The figure shows the state of all tokens of two letters from the IB data set. The upper letter contains a lot of small changes, where often a green (added part) and red (deleted part) occur as a combination. The letter below contains a lot of longer deleted parts, concluding, that the letter above contains corrections of mistakes, whereby the lower contains modifications related to the topic. The size of the modifications seems to be a criterion to distinguish between corrections and topic related modifications. The distribution over the length of modifications however, reveals, that a lot of the modifications in the data set are small, thus likely to be corrections of mistakes ( <ref type="figure">Figure 5</ref>). The first preliminary experiments have been carried out with a binary setup: The model should distinguish between a) one particular moral censorship reason and b) everything else. To do so, prior knowledge about the topics has been introduced to the model in form of a keyword.</p><p>For example the topic sickness has been introduced to the model by the keyword "Krankheit". The first results on this look very promising, as they reveal a precision = 1 and a recall = 0,67.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Outlook</head><p>In the near future, I will undertake further experiments with the IB data set. To do so, I will incrementally increase the number of modification reasons. The results will be made accessible as part of the IB corpus, making the permeability between editorial and algorithmic work more visible and accessible to all interested DH communities for reuse.</p><p>In a further step, I would like to look into different applications of this method. A promising idea would be, to look into different editions of the same text and consider each difference as a modification.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The generative model in the center receives input documents with modifications. It outputs reasons for modification and a reason assignment to each modification</figDesc><graphic url="image-1.png" coords="1,316.86,502.86,241.44,92.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Plate notation of the model. The left four circled variables represent LDA, the right ones the modification part</figDesc><graphic url="image-3.png" coords="2,54.30,158.46,241.44,156.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Above dark grey divider: Letter 4, Chamisso to de La Foye contains small corrections. Below: Letter 14, Dorothea Tieck to Uechtritz contains larger modifications. Deletions (red), additions (green)</figDesc><graphic url="image-5.png" coords="3,54.30,84.54,241.44,68.40" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
